{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN 기반 다중분류 모델 구현\n",
    "- 데이터셋 : iris.csv\n",
    "- Feature : 4개 Sepal_Length, Sepal_Width, Petal_Length, Petal_Width\n",
    "- Target : 1개 Variety\n",
    "- 학습-방법 : 지도학습 > 분류 > 다중분류 (클래스 3개)\n",
    "- 알고리즘 : 인공신경망(ANN) => MLP, DNN : 은닉층이 많은 구성\n",
    "- 프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 관련 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchinfo import summary\n",
    "\n",
    "# Data 관련 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch V. 2.4.1\n",
      "Pandas V. 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크 => 사용자 정의 함수로 구현하기\n",
    "print(f'Pytorch V. {torch.__version__}')\n",
    "print(f'Pandas V. {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "DATA_FILE='../data/iris.csv'\n",
    "\n",
    "# CSV => DataFrame\n",
    "irisDF=pd.read_csv(DATA_FILE)\n",
    "\n",
    "# 데이터 확인\n",
    "irisDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 변경 => 정수화, 클래스 3개\n",
    "irisDF['variety'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels => {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=dict(zip(irisDF['variety'].unique().tolist(),range(3)))\n",
    "print(f'labels => {labels}')\n",
    "\n",
    "irisDF['variety']=irisDF['variety'].replace(labels)\n",
    "irisDF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의<hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론 목적 \n",
    "- 클래스이름 : IrisMCFModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개변수 : 층별 입출력 개수 고정하기때문에 필요 없음\n",
    "- 속성필드 : \n",
    "- 기능역할 : __init__() : 모델 구조, forward() : 순방향 학습 <= 오버라이딩\n",
    "- 클래스구조\n",
    "    * 입력층 : 입력  4개(피처)  출력 10개(퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개        출력 5개(퍼셉트론/뉴런 5개 존재)\n",
    "    * 출력층 : 입력  5개        출력 1개(퍼셉트론/뉴런 1개 존재 : 2진분류)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스형태 => nn.MESLoss, nn.ReLU => __init__() 메서드\n",
    "    * 함수형태 => torch.nn.fuctional 아래에 => forward() 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisMCFModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer=nn.Linear(4,10)\n",
    "        self.hd_layer=nn.Linear(10,5)\n",
    "        self.out_layer=nn.Linear(5,3) # 다중분류 'Setosa', 'Versicolor', 'Virginica' \n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, x):\n",
    "        y=F.relu(self.in_layer(x))\n",
    "        y=F.relu(self.hd_layer(y))\n",
    "        return self.out_layer(y) # 5개의 숫자 값 => 다중분류 : 손실함수 CrossEntrpyLoss가 내부에서 softmax 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisMCFModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hd_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model=IrisMCFModel()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "IrisMCFModel                             [1000, 3]                 --\n",
       "├─Linear: 1-1                            [1000, 10]                50\n",
       "├─Linear: 1-2                            [1000, 5]                 55\n",
       "├─Linear: 1-3                            [1000, 3]                 18\n",
       "==========================================================================================\n",
       "Total params: 123\n",
       "Trainable params: 123\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.12\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.14\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(1000,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의<hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐개수 : 4개\n",
    "- 타겟개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드\n",
    "    * __init__(self) : 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __len__(self) : 데이터의 개수 반환\n",
    "    * __getitem__(self, index) : 특정 인덱스의 피쳐와 타겟 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 넘파이를 텐서로\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3-1] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐, 타겟 추출\n",
    "featureDF, targetDF=irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1:]]\n",
    "print(f'featureDF => {featureDF.shape}, targetDF => {targetDF.shape}')\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n",
    "- 학습 횟수 : EPOCH <= 처음부터 끝까지 학습하는 단위\n",
    "- 배치 크기 : BATCH_SIZE <= 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE <= 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학습률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 진행 관련 설정\n",
    "EPOCH=1000\n",
    "BATCH_SIZE=10\n",
    "BATCH_CNT=irisDF.shape[0]/BATCH_SIZE\n",
    "DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화 (+ 손실함수, 성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 4) (38, 4) (28, 4)\n",
      "(84, 1) (38, 1) (28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스\n",
    "model=IrisMCFModel()\n",
    "\n",
    "# 데이터셋 인스턴스\n",
    "\n",
    "# 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_test, y_train, y_test=train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'{X_train.shape} {X_test.shape} {X_val.shape}')\n",
    "print(f'{y_train.shape} {y_test.shape} {y_val.shape}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터로드 인스턴스\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W, b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 다중분류 CrossEntropyLoss\n",
    "#                            예측값은 선형식 결과값으로 전달 => AF 처리 X\n",
    "crossLoss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDL), trainDL.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000]\n",
      "- [TRAIN] LOSS : 0.6826515913009643 [SCORE] : 0.016161616643269858\n",
      "[1/1000]\n",
      "- [VAL] LOSS : 1.1232460737228394 [SCORE] : 0.13364055752754211\n",
      "[2/1000]\n",
      "- [TRAIN] LOSS : 0.6653861045837403 [SCORE] : 0.020336700975894927\n",
      "[2/1000]\n",
      "- [VAL] LOSS : 1.097093105316162 [SCORE] : 0.09876543283462524\n",
      "[3/1000]\n",
      "- [TRAIN] LOSS : 0.651424503326416 [SCORE] : 0.041994549830754596\n",
      "[3/1000]\n",
      "- [VAL] LOSS : 1.0741965770721436 [SCORE] : 0.07017543911933899\n",
      "[4/1000]\n",
      "- [TRAIN] LOSS : 0.6404554526011149 [SCORE] : 0.07651114463806152\n",
      "[4/1000]\n",
      "- [VAL] LOSS : 1.0550514459609985 [SCORE] : 0.1547619104385376\n",
      "[5/1000]\n",
      "- [TRAIN] LOSS : 0.6327900171279908 [SCORE] : 0.14986371695995332\n",
      "[5/1000]\n",
      "- [VAL] LOSS : 1.0410023927688599 [SCORE] : 0.29386845231056213\n",
      "[6/1000]\n",
      "- [TRAIN] LOSS : 0.6254903078079224 [SCORE] : 0.23383394678433736\n",
      "[6/1000]\n",
      "- [VAL] LOSS : 1.0287301540374756 [SCORE] : 0.4393407702445984\n",
      "[7/1000]\n",
      "- [TRAIN] LOSS : 0.617437473932902 [SCORE] : 0.3639410038789113\n",
      "[7/1000]\n",
      "- [VAL] LOSS : 1.016190528869629 [SCORE] : 0.5397935509681702\n",
      "[8/1000]\n",
      "- [TRAIN] LOSS : 0.6086166858673095 [SCORE] : 0.3638736645380656\n",
      "[8/1000]\n",
      "- [VAL] LOSS : 0.998551070690155 [SCORE] : 0.6113360524177551\n",
      "[9/1000]\n",
      "- [TRAIN] LOSS : 0.5998034119606018 [SCORE] : 0.45429348945617676\n",
      "[9/1000]\n",
      "- [VAL] LOSS : 0.9794397354125977 [SCORE] : 0.6113360524177551\n",
      "[10/1000]\n",
      "- [TRAIN] LOSS : 0.591636045773824 [SCORE] : 0.4522462805112203\n",
      "[10/1000]\n",
      "- [VAL] LOSS : 0.9612902998924255 [SCORE] : 0.6113360524177551\n",
      "[11/1000]\n",
      "- [TRAIN] LOSS : 0.583878739674886 [SCORE] : 0.4522462805112203\n",
      "[11/1000]\n",
      "- [VAL] LOSS : 0.9435412287712097 [SCORE] : 0.6113360524177551\n",
      "[12/1000]\n",
      "- [TRAIN] LOSS : 0.5758582433064778 [SCORE] : 0.4522462805112203\n",
      "[12/1000]\n",
      "- [VAL] LOSS : 0.9255315661430359 [SCORE] : 0.6113360524177551\n",
      "[13/1000]\n",
      "- [TRAIN] LOSS : 0.5675795356432597 [SCORE] : 0.4522462805112203\n",
      "[13/1000]\n",
      "- [VAL] LOSS : 0.9070898294448853 [SCORE] : 0.6113360524177551\n",
      "[14/1000]\n",
      "- [TRAIN] LOSS : 0.5590883453687032 [SCORE] : 0.4522462805112203\n",
      "[14/1000]\n",
      "- [VAL] LOSS : 0.8882876634597778 [SCORE] : 0.6113360524177551\n",
      "[15/1000]\n",
      "- [TRAIN] LOSS : 0.550316059589386 [SCORE] : 0.4155267079671224\n",
      "[15/1000]\n",
      "- [VAL] LOSS : 0.8686628937721252 [SCORE] : 0.6113360524177551\n",
      "[16/1000]\n",
      "- [TRAIN] LOSS : 0.5414562781651815 [SCORE] : 0.44177008867263795\n",
      "[16/1000]\n",
      "- [VAL] LOSS : 0.8488312363624573 [SCORE] : 0.6113360524177551\n",
      "[17/1000]\n",
      "- [TRAIN] LOSS : 0.5325064182281494 [SCORE] : 0.4245743234952291\n",
      "[17/1000]\n",
      "- [VAL] LOSS : 0.828491747379303 [SCORE] : 0.6113360524177551\n",
      "[18/1000]\n",
      "- [TRAIN] LOSS : 0.5236092766125997 [SCORE] : 0.4245743234952291\n",
      "[18/1000]\n",
      "- [VAL] LOSS : 0.8086641430854797 [SCORE] : 0.6113360524177551\n",
      "[19/1000]\n",
      "- [TRAIN] LOSS : 0.5147484223047892 [SCORE] : 0.43505051533381145\n",
      "[19/1000]\n",
      "- [VAL] LOSS : 0.7903334498405457 [SCORE] : 0.6113360524177551\n",
      "[20/1000]\n",
      "- [TRAIN] LOSS : 0.5058342019716898 [SCORE] : 0.43505051533381145\n",
      "[20/1000]\n",
      "- [VAL] LOSS : 0.7732301354408264 [SCORE] : 0.6113360524177551\n",
      "[21/1000]\n",
      "- [TRAIN] LOSS : 0.49676191409428916 [SCORE] : 0.43505051533381145\n",
      "[21/1000]\n",
      "- [VAL] LOSS : 0.756452202796936 [SCORE] : 0.6113360524177551\n",
      "[22/1000]\n",
      "- [TRAIN] LOSS : 0.48782700300216675 [SCORE] : 0.4245743234952291\n",
      "[22/1000]\n",
      "- [VAL] LOSS : 0.7390023469924927 [SCORE] : 0.6113360524177551\n",
      "[23/1000]\n",
      "- [TRAIN] LOSS : 0.4790289282798767 [SCORE] : 0.43505051533381145\n",
      "[23/1000]\n",
      "- [VAL] LOSS : 0.7213345766067505 [SCORE] : 0.6113360524177551\n",
      "[24/1000]\n",
      "- [TRAIN] LOSS : 0.4708476384480794 [SCORE] : 0.4155267079671224\n",
      "[24/1000]\n",
      "- [VAL] LOSS : 0.7056549191474915 [SCORE] : 0.5555555820465088\n",
      "[25/1000]\n",
      "- [TRAIN] LOSS : 0.46269692182540895 [SCORE] : 0.4155267079671224\n",
      "[25/1000]\n",
      "- [VAL] LOSS : 0.6896575689315796 [SCORE] : 0.5555555820465088\n",
      "[26/1000]\n",
      "- [TRAIN] LOSS : 0.4552732149759928 [SCORE] : 0.4155267079671224\n",
      "[26/1000]\n",
      "- [VAL] LOSS : 0.6757517457008362 [SCORE] : 0.5555555820465088\n",
      "[27/1000]\n",
      "- [TRAIN] LOSS : 0.4479723374048869 [SCORE] : 0.40817628304163617\n",
      "[27/1000]\n",
      "- [VAL] LOSS : 0.6617621779441833 [SCORE] : 0.5555555820465088\n",
      "[28/1000]\n",
      "- [TRAIN] LOSS : 0.4410349329312642 [SCORE] : 0.40817628304163617\n",
      "[28/1000]\n",
      "- [VAL] LOSS : 0.6491260528564453 [SCORE] : 0.5555555820465088\n",
      "[29/1000]\n",
      "- [TRAIN] LOSS : 0.43470195134480794 [SCORE] : 0.40817628304163617\n",
      "[29/1000]\n",
      "- [VAL] LOSS : 0.6388241052627563 [SCORE] : 0.5555555820465088\n",
      "[30/1000]\n",
      "- [TRAIN] LOSS : 0.42820915778477986 [SCORE] : 0.40817628304163617\n",
      "[30/1000]\n",
      "- [VAL] LOSS : 0.6277891993522644 [SCORE] : 0.5555555820465088\n",
      "[31/1000]\n",
      "- [TRAIN] LOSS : 0.42209929625193277 [SCORE] : 0.40817628304163617\n",
      "[31/1000]\n",
      "- [VAL] LOSS : 0.6170297265052795 [SCORE] : 0.5555555820465088\n",
      "[32/1000]\n",
      "- [TRAIN] LOSS : 0.416290811697642 [SCORE] : 0.40817628304163617\n",
      "[32/1000]\n",
      "- [VAL] LOSS : 0.6065658926963806 [SCORE] : 0.5555555820465088\n",
      "[33/1000]\n",
      "- [TRAIN] LOSS : 0.4108054598172506 [SCORE] : 0.4155267079671224\n",
      "[33/1000]\n",
      "- [VAL] LOSS : 0.5965843796730042 [SCORE] : 0.6113360524177551\n",
      "[34/1000]\n",
      "- [TRAIN] LOSS : 0.40586503346761066 [SCORE] : 0.4155267079671224\n",
      "[34/1000]\n",
      "- [VAL] LOSS : 0.5885582566261292 [SCORE] : 0.6113360524177551\n",
      "[35/1000]\n",
      "- [TRAIN] LOSS : 0.400796111424764 [SCORE] : 0.4155267079671224\n",
      "[35/1000]\n",
      "- [VAL] LOSS : 0.5807029008865356 [SCORE] : 0.6113360524177551\n",
      "[36/1000]\n",
      "- [TRAIN] LOSS : 0.39597802559534706 [SCORE] : 0.44309284289677936\n",
      "[36/1000]\n",
      "- [VAL] LOSS : 0.5734125971794128 [SCORE] : 0.6113360524177551\n",
      "[37/1000]\n",
      "- [TRAIN] LOSS : 0.39139994581540427 [SCORE] : 0.4507118900616964\n",
      "[37/1000]\n",
      "- [VAL] LOSS : 0.5663401484489441 [SCORE] : 0.6113360524177551\n",
      "[38/1000]\n",
      "- [TRAIN] LOSS : 0.3866022805372874 [SCORE] : 0.48356902996699014\n",
      "[38/1000]\n",
      "- [VAL] LOSS : 0.5576533079147339 [SCORE] : 0.75\n",
      "[39/1000]\n",
      "- [TRAIN] LOSS : 0.3823316156864166 [SCORE] : 0.48948533535003663\n",
      "[39/1000]\n",
      "- [VAL] LOSS : 0.5501896739006042 [SCORE] : 0.75\n",
      "[40/1000]\n",
      "- [TRAIN] LOSS : 0.3782200217247009 [SCORE] : 0.4946801424026489\n",
      "[40/1000]\n",
      "- [VAL] LOSS : 0.544058620929718 [SCORE] : 0.75\n",
      "[41/1000]\n",
      "- [TRAIN] LOSS : 0.37411027948061626 [SCORE] : 0.502222228050232\n",
      "[41/1000]\n",
      "- [VAL] LOSS : 0.5379449725151062 [SCORE] : 0.7908496856689453\n",
      "[42/1000]\n",
      "- [TRAIN] LOSS : 0.3696447749932607 [SCORE] : 0.5150793711344401\n",
      "[42/1000]\n",
      "- [VAL] LOSS : 0.5298827290534973 [SCORE] : 0.8306878805160522\n",
      "[43/1000]\n",
      "- [TRAIN] LOSS : 0.3659077823162079 [SCORE] : 0.5269312222798666\n",
      "[43/1000]\n",
      "- [VAL] LOSS : 0.5235432386398315 [SCORE] : 0.8306878805160522\n",
      "[44/1000]\n",
      "- [TRAIN] LOSS : 0.3620271265506744 [SCORE] : 0.5269312222798666\n",
      "[44/1000]\n",
      "- [VAL] LOSS : 0.5179861187934875 [SCORE] : 0.8306878805160522\n",
      "[45/1000]\n",
      "- [TRAIN] LOSS : 0.35785457690556843 [SCORE] : 0.5269312222798666\n",
      "[45/1000]\n",
      "- [VAL] LOSS : 0.5109578371047974 [SCORE] : 0.8704453706741333\n",
      "[46/1000]\n",
      "- [TRAIN] LOSS : 0.35407694776852927 [SCORE] : 0.5269312222798666\n",
      "[46/1000]\n",
      "- [VAL] LOSS : 0.504881739616394 [SCORE] : 0.8704453706741333\n",
      "[47/1000]\n",
      "- [TRAIN] LOSS : 0.34996522068977354 [SCORE] : 0.5349735498428345\n",
      "[47/1000]\n",
      "- [VAL] LOSS : 0.49778059124946594 [SCORE] : 0.8704453706741333\n",
      "[48/1000]\n",
      "- [TRAIN] LOSS : 0.3462296505769094 [SCORE] : 0.5349735498428345\n",
      "[48/1000]\n",
      "- [VAL] LOSS : 0.4918444752693176 [SCORE] : 0.8704453706741333\n",
      "[49/1000]\n",
      "- [TRAIN] LOSS : 0.3420765042304993 [SCORE] : 0.5331216971079509\n",
      "[49/1000]\n",
      "- [VAL] LOSS : 0.4848284423351288 [SCORE] : 0.8704453706741333\n",
      "[50/1000]\n",
      "- [TRAIN] LOSS : 0.3380075434843699 [SCORE] : 0.5451226592063904\n",
      "[50/1000]\n",
      "- [VAL] LOSS : 0.47751790285110474 [SCORE] : 0.9111111164093018\n",
      "[51/1000]\n",
      "- [TRAIN] LOSS : 0.3342040777206421 [SCORE] : 0.551912784576416\n",
      "[51/1000]\n",
      "- [VAL] LOSS : 0.4716987609863281 [SCORE] : 0.9111111164093018\n",
      "[52/1000]\n",
      "- [TRAIN] LOSS : 0.3297764619191488 [SCORE] : 0.551912784576416\n",
      "[52/1000]\n",
      "- [VAL] LOSS : 0.46379953622817993 [SCORE] : 0.9111111164093018\n",
      "[53/1000]\n",
      "- [TRAIN] LOSS : 0.3254978160063426 [SCORE] : 0.5462690472602845\n",
      "[53/1000]\n",
      "- [VAL] LOSS : 0.4560793340206146 [SCORE] : 0.9538239240646362\n",
      "[54/1000]\n",
      "- [TRAIN] LOSS : 0.3212752262751261 [SCORE] : 0.5462690472602845\n",
      "[54/1000]\n",
      "- [VAL] LOSS : 0.4488648772239685 [SCORE] : 0.9538239240646362\n",
      "[55/1000]\n",
      "- [TRAIN] LOSS : 0.3167160948117574 [SCORE] : 0.556851057211558\n",
      "[55/1000]\n",
      "- [VAL] LOSS : 0.4412074685096741 [SCORE] : 0.9538239240646362\n",
      "[56/1000]\n",
      "- [TRAIN] LOSS : 0.31213392217954 [SCORE] : 0.564470104376475\n",
      "[56/1000]\n",
      "- [VAL] LOSS : 0.4331152141094208 [SCORE] : 0.9538239240646362\n",
      "[57/1000]\n",
      "- [TRAIN] LOSS : 0.3075170675913493 [SCORE] : 0.564470104376475\n",
      "[57/1000]\n",
      "- [VAL] LOSS : 0.4250619411468506 [SCORE] : 0.9538239240646362\n",
      "[58/1000]\n",
      "- [TRAIN] LOSS : 0.30278380314509074 [SCORE] : 0.564470104376475\n",
      "[58/1000]\n",
      "- [VAL] LOSS : 0.41699641942977905 [SCORE] : 0.9538239240646362\n",
      "[59/1000]\n",
      "- [TRAIN] LOSS : 0.29793458580970766 [SCORE] : 0.5696649074554443\n",
      "[59/1000]\n",
      "- [VAL] LOSS : 0.40911349654197693 [SCORE] : 0.9538239240646362\n",
      "[60/1000]\n",
      "- [TRAIN] LOSS : 0.29281297922134397 [SCORE] : 0.5696649074554443\n",
      "[60/1000]\n",
      "- [VAL] LOSS : 0.4011480510234833 [SCORE] : 0.9538239240646362\n",
      "[61/1000]\n",
      "- [TRAIN] LOSS : 0.2874611099561056 [SCORE] : 0.5696649074554443\n",
      "[61/1000]\n",
      "- [VAL] LOSS : 0.392508327960968 [SCORE] : 0.9538239240646362\n",
      "[62/1000]\n",
      "- [TRAIN] LOSS : 0.2820020536581675 [SCORE] : 0.5696649074554443\n",
      "[62/1000]\n",
      "- [VAL] LOSS : 0.38396164774894714 [SCORE] : 0.9538239240646362\n",
      "[63/1000]\n",
      "- [TRAIN] LOSS : 0.27635637919108075 [SCORE] : 0.5696649074554443\n",
      "[63/1000]\n",
      "- [VAL] LOSS : 0.37517741322517395 [SCORE] : 0.9538239240646362\n",
      "[64/1000]\n",
      "- [TRAIN] LOSS : 0.27015867829322815 [SCORE] : 0.5696649074554443\n",
      "[64/1000]\n",
      "- [VAL] LOSS : 0.36400270462036133 [SCORE] : 0.9538239240646362\n",
      "[65/1000]\n",
      "- [TRAIN] LOSS : 0.2642460862795512 [SCORE] : 0.5696649074554443\n",
      "[65/1000]\n",
      "- [VAL] LOSS : 0.35364142060279846 [SCORE] : 0.9538239240646362\n",
      "[66/1000]\n",
      "- [TRAIN] LOSS : 0.2582516928513845 [SCORE] : 0.5696649074554443\n",
      "[66/1000]\n",
      "- [VAL] LOSS : 0.344180166721344 [SCORE] : 0.9538239240646362\n",
      "[67/1000]\n",
      "- [TRAIN] LOSS : 0.2518904407819112 [SCORE] : 0.5696649074554443\n",
      "[67/1000]\n",
      "- [VAL] LOSS : 0.33322039246559143 [SCORE] : 0.9538239240646362\n",
      "[68/1000]\n",
      "- [TRAIN] LOSS : 0.2452889660994212 [SCORE] : 0.5696649074554443\n",
      "[68/1000]\n",
      "- [VAL] LOSS : 0.3209814727306366 [SCORE] : 0.9538239240646362\n",
      "[69/1000]\n",
      "- [TRAIN] LOSS : 0.23908379077911376 [SCORE] : 0.5696649074554443\n",
      "[69/1000]\n",
      "- [VAL] LOSS : 0.3101200461387634 [SCORE] : 0.9538239240646362\n",
      "[70/1000]\n",
      "- [TRAIN] LOSS : 0.23273108005523682 [SCORE] : 0.5696649074554443\n",
      "[70/1000]\n",
      "- [VAL] LOSS : 0.2997276484966278 [SCORE] : 0.9538239240646362\n",
      "[71/1000]\n",
      "- [TRAIN] LOSS : 0.22639660636583964 [SCORE] : 0.5696649074554443\n",
      "[71/1000]\n",
      "- [VAL] LOSS : 0.28965431451797485 [SCORE] : 0.9538239240646362\n",
      "[72/1000]\n",
      "- [TRAIN] LOSS : 0.22011127372582753 [SCORE] : 0.5696649074554443\n",
      "[72/1000]\n",
      "- [VAL] LOSS : 0.2801767885684967 [SCORE] : 0.9538239240646362\n",
      "[73/1000]\n",
      "- [TRAIN] LOSS : 0.21379955212275187 [SCORE] : 0.5696649074554443\n",
      "[73/1000]\n",
      "- [VAL] LOSS : 0.2714250981807709 [SCORE] : 0.9538239240646362\n",
      "[74/1000]\n",
      "- [TRAIN] LOSS : 0.2072974979877472 [SCORE] : 0.5696649074554443\n",
      "[74/1000]\n",
      "- [VAL] LOSS : 0.2621815502643585 [SCORE] : 0.9538239240646362\n",
      "[75/1000]\n",
      "- [TRAIN] LOSS : 0.20088464518388113 [SCORE] : 0.5696649074554443\n",
      "[75/1000]\n",
      "- [VAL] LOSS : 0.2526857852935791 [SCORE] : 0.9538239240646362\n",
      "[76/1000]\n",
      "- [TRAIN] LOSS : 0.19462804396947225 [SCORE] : 0.5696649074554443\n",
      "[76/1000]\n",
      "- [VAL] LOSS : 0.24420110881328583 [SCORE] : 0.9538239240646362\n",
      "[77/1000]\n",
      "- [TRAIN] LOSS : 0.1883298138777415 [SCORE] : 0.5696649074554443\n",
      "[77/1000]\n",
      "- [VAL] LOSS : 0.23512236773967743 [SCORE] : 1.0\n",
      "[78/1000]\n",
      "- [TRAIN] LOSS : 0.1824464241663615 [SCORE] : 0.5696649074554443\n",
      "[78/1000]\n",
      "- [VAL] LOSS : 0.22699323296546936 [SCORE] : 1.0\n",
      "[79/1000]\n",
      "- [TRAIN] LOSS : 0.17671916087468464 [SCORE] : 0.5696649074554443\n",
      "[79/1000]\n",
      "- [VAL] LOSS : 0.21913652122020721 [SCORE] : 1.0\n",
      "[80/1000]\n",
      "- [TRAIN] LOSS : 0.17082560956478118 [SCORE] : 0.5696649074554443\n",
      "[80/1000]\n",
      "- [VAL] LOSS : 0.209580659866333 [SCORE] : 1.0\n",
      "[81/1000]\n",
      "- [TRAIN] LOSS : 0.1661302149295807 [SCORE] : 0.5696649074554443\n",
      "[81/1000]\n",
      "- [VAL] LOSS : 0.2034514993429184 [SCORE] : 1.0\n",
      "[82/1000]\n",
      "- [TRAIN] LOSS : 0.16084107458591462 [SCORE] : 0.5696649074554443\n",
      "[82/1000]\n",
      "- [VAL] LOSS : 0.19593413174152374 [SCORE] : 1.0\n",
      "[83/1000]\n",
      "- [TRAIN] LOSS : 0.1560884932676951 [SCORE] : 0.5696649074554443\n",
      "[83/1000]\n",
      "- [VAL] LOSS : 0.18907928466796875 [SCORE] : 1.0\n",
      "[84/1000]\n",
      "- [TRAIN] LOSS : 0.15162012875080108 [SCORE] : 0.5696649074554443\n",
      "[84/1000]\n",
      "- [VAL] LOSS : 0.18318533897399902 [SCORE] : 1.0\n",
      "[85/1000]\n",
      "- [TRAIN] LOSS : 0.14726120134194692 [SCORE] : 0.5696649074554443\n",
      "[85/1000]\n",
      "- [VAL] LOSS : 0.17753155529499054 [SCORE] : 1.0\n",
      "[86/1000]\n",
      "- [TRAIN] LOSS : 0.1430313244462013 [SCORE] : 0.5696649074554443\n",
      "[86/1000]\n",
      "- [VAL] LOSS : 0.1715625673532486 [SCORE] : 1.0\n",
      "[87/1000]\n",
      "- [TRAIN] LOSS : 0.13904469509919484 [SCORE] : 0.5696649074554443\n",
      "[87/1000]\n",
      "- [VAL] LOSS : 0.16535039246082306 [SCORE] : 1.0\n",
      "[88/1000]\n",
      "- [TRAIN] LOSS : 0.13554010192553204 [SCORE] : 0.5696649074554443\n",
      "[88/1000]\n",
      "- [VAL] LOSS : 0.16047382354736328 [SCORE] : 1.0\n",
      "[89/1000]\n",
      "- [TRAIN] LOSS : 0.13207064668337504 [SCORE] : 0.5696649074554443\n",
      "[89/1000]\n",
      "- [VAL] LOSS : 0.15580341219902039 [SCORE] : 1.0\n",
      "[90/1000]\n",
      "- [TRAIN] LOSS : 0.12878874739011129 [SCORE] : 0.5696649074554443\n",
      "[90/1000]\n",
      "- [VAL] LOSS : 0.15130972862243652 [SCORE] : 1.0\n",
      "[91/1000]\n",
      "- [TRAIN] LOSS : 0.12568852951129278 [SCORE] : 0.5696649074554443\n",
      "[91/1000]\n",
      "- [VAL] LOSS : 0.14695987105369568 [SCORE] : 1.0\n",
      "[92/1000]\n",
      "- [TRAIN] LOSS : 0.12277318984270096 [SCORE] : 0.5696649074554443\n",
      "[92/1000]\n",
      "- [VAL] LOSS : 0.14281423389911652 [SCORE] : 1.0\n",
      "[93/1000]\n",
      "- [TRAIN] LOSS : 0.12008339414993922 [SCORE] : 0.5696649074554443\n",
      "[93/1000]\n",
      "- [VAL] LOSS : 0.13925497233867645 [SCORE] : 1.0\n",
      "[94/1000]\n",
      "- [TRAIN] LOSS : 0.11747088730335235 [SCORE] : 0.5696649074554443\n",
      "[94/1000]\n",
      "- [VAL] LOSS : 0.13584968447685242 [SCORE] : 1.0\n",
      "[95/1000]\n",
      "- [TRAIN] LOSS : 0.11497954825560251 [SCORE] : 0.5696649074554443\n",
      "[95/1000]\n",
      "- [VAL] LOSS : 0.13242724537849426 [SCORE] : 1.0\n",
      "[96/1000]\n",
      "- [TRAIN] LOSS : 0.1126813660065333 [SCORE] : 0.5696649074554443\n",
      "[96/1000]\n",
      "- [VAL] LOSS : 0.12937867641448975 [SCORE] : 1.0\n",
      "[97/1000]\n",
      "- [TRAIN] LOSS : 0.11046156684557597 [SCORE] : 0.5696649074554443\n",
      "[97/1000]\n",
      "- [VAL] LOSS : 0.12641818821430206 [SCORE] : 1.0\n",
      "[98/1000]\n",
      "- [TRAIN] LOSS : 0.10835529267787933 [SCORE] : 0.5696649074554443\n",
      "[98/1000]\n",
      "- [VAL] LOSS : 0.12348282337188721 [SCORE] : 1.0\n",
      "[99/1000]\n",
      "- [TRAIN] LOSS : 0.10639467189709345 [SCORE] : 0.5696649074554443\n",
      "[99/1000]\n",
      "- [VAL] LOSS : 0.12080361694097519 [SCORE] : 1.0\n",
      "[100/1000]\n",
      "- [TRAIN] LOSS : 0.10452663451433182 [SCORE] : 0.5696649074554443\n",
      "[100/1000]\n",
      "- [VAL] LOSS : 0.11831251531839371 [SCORE] : 1.0\n",
      "[101/1000]\n",
      "- [TRAIN] LOSS : 0.10273890793323517 [SCORE] : 0.5696649074554443\n",
      "[101/1000]\n",
      "- [VAL] LOSS : 0.11589891463518143 [SCORE] : 1.0\n",
      "[102/1000]\n",
      "- [TRAIN] LOSS : 0.10104444374640782 [SCORE] : 0.5696649074554443\n",
      "[102/1000]\n",
      "- [VAL] LOSS : 0.11357975751161575 [SCORE] : 1.0\n",
      "[103/1000]\n",
      "- [TRAIN] LOSS : 0.09942214116454125 [SCORE] : 0.5696649074554443\n",
      "[103/1000]\n",
      "- [VAL] LOSS : 0.11125367879867554 [SCORE] : 1.0\n",
      "[104/1000]\n",
      "- [TRAIN] LOSS : 0.09792093535264333 [SCORE] : 0.5696649074554443\n",
      "[104/1000]\n",
      "- [VAL] LOSS : 0.10916688293218613 [SCORE] : 1.0\n",
      "[105/1000]\n",
      "- [TRAIN] LOSS : 0.0964840625723203 [SCORE] : 0.5696649074554443\n",
      "[105/1000]\n",
      "- [VAL] LOSS : 0.10724613815546036 [SCORE] : 1.0\n",
      "[106/1000]\n",
      "- [TRAIN] LOSS : 0.09509787037968635 [SCORE] : 0.5696649074554443\n",
      "[106/1000]\n",
      "- [VAL] LOSS : 0.10536421090364456 [SCORE] : 1.0\n",
      "[107/1000]\n",
      "- [TRAIN] LOSS : 0.09378023445606232 [SCORE] : 0.5696649074554443\n",
      "[107/1000]\n",
      "- [VAL] LOSS : 0.10354071855545044 [SCORE] : 1.0\n",
      "[108/1000]\n",
      "- [TRAIN] LOSS : 0.09253308499852816 [SCORE] : 0.5696649074554443\n",
      "[108/1000]\n",
      "- [VAL] LOSS : 0.10181983560323715 [SCORE] : 1.0\n",
      "[109/1000]\n",
      "- [TRAIN] LOSS : 0.09134182011087735 [SCORE] : 0.5696649074554443\n",
      "[109/1000]\n",
      "- [VAL] LOSS : 0.10018441826105118 [SCORE] : 1.0\n",
      "[110/1000]\n",
      "- [TRAIN] LOSS : 0.09020139450828234 [SCORE] : 0.5696649074554443\n",
      "[110/1000]\n",
      "- [VAL] LOSS : 0.0986122414469719 [SCORE] : 1.0\n",
      "[111/1000]\n",
      "- [TRAIN] LOSS : 0.08911385784546534 [SCORE] : 0.5696649074554443\n",
      "[111/1000]\n",
      "- [VAL] LOSS : 0.0971033051609993 [SCORE] : 1.0\n",
      "[112/1000]\n",
      "- [TRAIN] LOSS : 0.08807045966386795 [SCORE] : 0.5696649074554443\n",
      "[112/1000]\n",
      "- [VAL] LOSS : 0.09563406556844711 [SCORE] : 1.0\n",
      "[113/1000]\n",
      "- [TRAIN] LOSS : 0.08708129823207855 [SCORE] : 0.5696649074554443\n",
      "[113/1000]\n",
      "- [VAL] LOSS : 0.09425357729196548 [SCORE] : 1.0\n",
      "[114/1000]\n",
      "- [TRAIN] LOSS : 0.08613197728991509 [SCORE] : 0.5696649074554443\n",
      "[114/1000]\n",
      "- [VAL] LOSS : 0.09294024854898453 [SCORE] : 1.0\n",
      "[115/1000]\n",
      "- [TRAIN] LOSS : 0.08521969815095266 [SCORE] : 0.5696649074554443\n",
      "[115/1000]\n",
      "- [VAL] LOSS : 0.09167017787694931 [SCORE] : 1.0\n",
      "[116/1000]\n",
      "- [TRAIN] LOSS : 0.08434686437249184 [SCORE] : 0.5696649074554443\n",
      "[116/1000]\n",
      "- [VAL] LOSS : 0.090446837246418 [SCORE] : 1.0\n",
      "[117/1000]\n",
      "- [TRAIN] LOSS : 0.08351101527611414 [SCORE] : 0.5696649074554443\n",
      "[117/1000]\n",
      "- [VAL] LOSS : 0.08927323669195175 [SCORE] : 1.0\n",
      "[118/1000]\n",
      "- [TRAIN] LOSS : 0.0827078640460968 [SCORE] : 0.5696649074554443\n",
      "[118/1000]\n",
      "- [VAL] LOSS : 0.08814500272274017 [SCORE] : 1.0\n",
      "[119/1000]\n",
      "- [TRAIN] LOSS : 0.08193591783444086 [SCORE] : 0.5696649074554443\n",
      "[119/1000]\n",
      "- [VAL] LOSS : 0.08705878257751465 [SCORE] : 1.0\n",
      "[120/1000]\n",
      "- [TRAIN] LOSS : 0.08119635855158171 [SCORE] : 0.5696649074554443\n",
      "[120/1000]\n",
      "- [VAL] LOSS : 0.08601437509059906 [SCORE] : 1.0\n",
      "[121/1000]\n",
      "- [TRAIN] LOSS : 0.08048508887489637 [SCORE] : 0.5696649074554443\n",
      "[121/1000]\n",
      "- [VAL] LOSS : 0.08500802516937256 [SCORE] : 1.0\n",
      "[122/1000]\n",
      "- [TRAIN] LOSS : 0.07980084369579951 [SCORE] : 0.5696649074554443\n",
      "[122/1000]\n",
      "- [VAL] LOSS : 0.08403758704662323 [SCORE] : 1.0\n",
      "[123/1000]\n",
      "- [TRAIN] LOSS : 0.0791424922645092 [SCORE] : 0.5696649074554443\n",
      "[123/1000]\n",
      "- [VAL] LOSS : 0.08310157805681229 [SCORE] : 1.0\n",
      "[124/1000]\n",
      "- [TRAIN] LOSS : 0.07850869620839755 [SCORE] : 0.5696649074554443\n",
      "[124/1000]\n",
      "- [VAL] LOSS : 0.08219826221466064 [SCORE] : 1.0\n",
      "[125/1000]\n",
      "- [TRAIN] LOSS : 0.07789743828276793 [SCORE] : 0.5696649074554443\n",
      "[125/1000]\n",
      "- [VAL] LOSS : 0.08132608979940414 [SCORE] : 1.0\n",
      "[126/1000]\n",
      "- [TRAIN] LOSS : 0.07730983619888623 [SCORE] : 0.5696649074554443\n",
      "[126/1000]\n",
      "- [VAL] LOSS : 0.08048469573259354 [SCORE] : 1.0\n",
      "[127/1000]\n",
      "- [TRAIN] LOSS : 0.07674263703326384 [SCORE] : 0.5696649074554443\n",
      "[127/1000]\n",
      "- [VAL] LOSS : 0.07967083156108856 [SCORE] : 1.0\n",
      "[128/1000]\n",
      "- [TRAIN] LOSS : 0.07619559690356255 [SCORE] : 0.5696649074554443\n",
      "[128/1000]\n",
      "- [VAL] LOSS : 0.07888317108154297 [SCORE] : 1.0\n",
      "[129/1000]\n",
      "- [TRAIN] LOSS : 0.07566662741204103 [SCORE] : 0.5696649074554443\n",
      "[129/1000]\n",
      "- [VAL] LOSS : 0.07812131941318512 [SCORE] : 1.0\n",
      "[130/1000]\n",
      "- [TRAIN] LOSS : 0.07515675860146681 [SCORE] : 0.5696649074554443\n",
      "[130/1000]\n",
      "- [VAL] LOSS : 0.07738510519266129 [SCORE] : 1.0\n",
      "[131/1000]\n",
      "- [TRAIN] LOSS : 0.07466495918730895 [SCORE] : 0.5696649074554443\n",
      "[131/1000]\n",
      "- [VAL] LOSS : 0.0766725167632103 [SCORE] : 1.0\n",
      "[132/1000]\n",
      "- [TRAIN] LOSS : 0.07418862779935201 [SCORE] : 0.5696649074554443\n",
      "[132/1000]\n",
      "- [VAL] LOSS : 0.07597818225622177 [SCORE] : 1.0\n",
      "[133/1000]\n",
      "- [TRAIN] LOSS : 0.07372823779781659 [SCORE] : 0.5696649074554443\n",
      "[133/1000]\n",
      "- [VAL] LOSS : 0.07530760765075684 [SCORE] : 1.0\n",
      "[134/1000]\n",
      "- [TRAIN] LOSS : 0.07328412868082523 [SCORE] : 0.5696649074554443\n",
      "[134/1000]\n",
      "- [VAL] LOSS : 0.0746598020195961 [SCORE] : 1.0\n",
      "[135/1000]\n",
      "- [TRAIN] LOSS : 0.07285263240337372 [SCORE] : 0.5696649074554443\n",
      "[135/1000]\n",
      "- [VAL] LOSS : 0.07403043657541275 [SCORE] : 1.0\n",
      "[136/1000]\n",
      "- [TRAIN] LOSS : 0.07243557820717493 [SCORE] : 0.5696649074554443\n",
      "[136/1000]\n",
      "- [VAL] LOSS : 0.07341917604207993 [SCORE] : 1.0\n",
      "[137/1000]\n",
      "- [TRAIN] LOSS : 0.07203245523075262 [SCORE] : 0.5696649074554443\n",
      "[137/1000]\n",
      "- [VAL] LOSS : 0.07282613962888718 [SCORE] : 1.0\n",
      "[138/1000]\n",
      "- [TRAIN] LOSS : 0.07164155915379525 [SCORE] : 0.5696649074554443\n",
      "[138/1000]\n",
      "- [VAL] LOSS : 0.0722496286034584 [SCORE] : 1.0\n",
      "[139/1000]\n",
      "- [TRAIN] LOSS : 0.07126173761983713 [SCORE] : 0.5696649074554443\n",
      "[139/1000]\n",
      "- [VAL] LOSS : 0.07168934494256973 [SCORE] : 1.0\n",
      "[140/1000]\n",
      "- [TRAIN] LOSS : 0.07089399496714274 [SCORE] : 0.5696649074554443\n",
      "[140/1000]\n",
      "- [VAL] LOSS : 0.07114540040493011 [SCORE] : 1.0\n",
      "[141/1000]\n",
      "- [TRAIN] LOSS : 0.07053756378591061 [SCORE] : 0.5696649074554443\n",
      "[141/1000]\n",
      "- [VAL] LOSS : 0.0706169381737709 [SCORE] : 1.0\n",
      "[142/1000]\n",
      "- [TRAIN] LOSS : 0.07019233455260594 [SCORE] : 0.5696649074554443\n",
      "[142/1000]\n",
      "- [VAL] LOSS : 0.07010264694690704 [SCORE] : 1.0\n",
      "[143/1000]\n",
      "- [TRAIN] LOSS : 0.06985601708292961 [SCORE] : 0.5696649074554443\n",
      "[143/1000]\n",
      "- [VAL] LOSS : 0.06960126012563705 [SCORE] : 1.0\n",
      "[144/1000]\n",
      "- [TRAIN] LOSS : 0.06953002773225307 [SCORE] : 0.5696649074554443\n",
      "[144/1000]\n",
      "- [VAL] LOSS : 0.06911356747150421 [SCORE] : 1.0\n",
      "[145/1000]\n",
      "- [TRAIN] LOSS : 0.06921437196433544 [SCORE] : 0.5696649074554443\n",
      "[145/1000]\n",
      "- [VAL] LOSS : 0.06863953918218613 [SCORE] : 1.0\n",
      "[146/1000]\n",
      "- [TRAIN] LOSS : 0.06890637663503488 [SCORE] : 0.5696649074554443\n",
      "[146/1000]\n",
      "- [VAL] LOSS : 0.06817791610956192 [SCORE] : 1.0\n",
      "[147/1000]\n",
      "- [TRAIN] LOSS : 0.06860732895632585 [SCORE] : 0.5696649074554443\n",
      "[147/1000]\n",
      "- [VAL] LOSS : 0.06772807985544205 [SCORE] : 1.0\n",
      "[148/1000]\n",
      "- [TRAIN] LOSS : 0.06831676575044791 [SCORE] : 0.5696649074554443\n",
      "[148/1000]\n",
      "- [VAL] LOSS : 0.06728968024253845 [SCORE] : 1.0\n",
      "[149/1000]\n",
      "- [TRAIN] LOSS : 0.06803828477859497 [SCORE] : 0.5696649074554443\n",
      "[149/1000]\n",
      "- [VAL] LOSS : 0.06688015908002853 [SCORE] : 1.0\n",
      "[150/1000]\n",
      "- [TRAIN] LOSS : 0.06775887534022332 [SCORE] : 0.5696649074554443\n",
      "[150/1000]\n",
      "- [VAL] LOSS : 0.06646128743886948 [SCORE] : 1.0\n",
      "[151/1000]\n",
      "- [TRAIN] LOSS : 0.06748862390716871 [SCORE] : 0.5696649074554443\n",
      "[151/1000]\n",
      "- [VAL] LOSS : 0.06603323668241501 [SCORE] : 1.0\n",
      "[152/1000]\n",
      "- [TRAIN] LOSS : 0.06723171559472879 [SCORE] : 0.5696649074554443\n",
      "[152/1000]\n",
      "- [VAL] LOSS : 0.06563283503055573 [SCORE] : 1.0\n",
      "[153/1000]\n",
      "- [TRAIN] LOSS : 0.06698019728064537 [SCORE] : 0.5696649074554443\n",
      "[153/1000]\n",
      "- [VAL] LOSS : 0.06525348126888275 [SCORE] : 1.0\n",
      "[154/1000]\n",
      "- [TRAIN] LOSS : 0.06673622367282708 [SCORE] : 0.5696649074554443\n",
      "[154/1000]\n",
      "- [VAL] LOSS : 0.06489472091197968 [SCORE] : 1.0\n",
      "[155/1000]\n",
      "- [TRAIN] LOSS : 0.06649025951822599 [SCORE] : 0.5696649074554443\n",
      "[155/1000]\n",
      "- [VAL] LOSS : 0.0645226314663887 [SCORE] : 1.0\n",
      "[156/1000]\n",
      "- [TRAIN] LOSS : 0.06625401054819426 [SCORE] : 0.5696649074554443\n",
      "[156/1000]\n",
      "- [VAL] LOSS : 0.06414224952459335 [SCORE] : 1.0\n",
      "[157/1000]\n",
      "- [TRAIN] LOSS : 0.06603251099586487 [SCORE] : 0.5696649074554443\n",
      "[157/1000]\n",
      "- [VAL] LOSS : 0.06380165368318558 [SCORE] : 1.0\n",
      "[158/1000]\n",
      "- [TRAIN] LOSS : 0.06580732688307762 [SCORE] : 0.5696649074554443\n",
      "[158/1000]\n",
      "- [VAL] LOSS : 0.06346383690834045 [SCORE] : 1.0\n",
      "[159/1000]\n",
      "- [TRAIN] LOSS : 0.06558747266729673 [SCORE] : 0.5696649074554443\n",
      "[159/1000]\n",
      "- [VAL] LOSS : 0.06311353296041489 [SCORE] : 1.0\n",
      "[160/1000]\n",
      "- [TRAIN] LOSS : 0.06538096728424231 [SCORE] : 0.5696649074554443\n",
      "[160/1000]\n",
      "- [VAL] LOSS : 0.06279285252094269 [SCORE] : 1.0\n",
      "[161/1000]\n",
      "- [TRAIN] LOSS : 0.06517203046629826 [SCORE] : 0.5696649074554443\n",
      "[161/1000]\n",
      "- [VAL] LOSS : 0.06247492879629135 [SCORE] : 1.0\n",
      "[162/1000]\n",
      "- [TRAIN] LOSS : 0.06497141302873691 [SCORE] : 0.5696649074554443\n",
      "[162/1000]\n",
      "- [VAL] LOSS : 0.062160901725292206 [SCORE] : 1.0\n",
      "[163/1000]\n",
      "- [TRAIN] LOSS : 0.06477256597330174 [SCORE] : 0.5696649074554443\n",
      "[163/1000]\n",
      "- [VAL] LOSS : 0.061848241835832596 [SCORE] : 1.0\n",
      "[164/1000]\n",
      "- [TRAIN] LOSS : 0.0645800984154145 [SCORE] : 0.5696649074554443\n",
      "[164/1000]\n",
      "- [VAL] LOSS : 0.06153574213385582 [SCORE] : 1.0\n",
      "[165/1000]\n",
      "- [TRAIN] LOSS : 0.06439772595961889 [SCORE] : 0.5696649074554443\n",
      "[165/1000]\n",
      "- [VAL] LOSS : 0.061252422630786896 [SCORE] : 1.0\n",
      "[166/1000]\n",
      "- [TRAIN] LOSS : 0.06421448873976866 [SCORE] : 0.5696649074554443\n",
      "[166/1000]\n",
      "- [VAL] LOSS : 0.06097972393035889 [SCORE] : 1.0\n",
      "[167/1000]\n",
      "- [TRAIN] LOSS : 0.06402955421557029 [SCORE] : 0.5696649074554443\n",
      "[167/1000]\n",
      "- [VAL] LOSS : 0.06068393960595131 [SCORE] : 1.0\n",
      "[168/1000]\n",
      "- [TRAIN] LOSS : 0.06385457211484512 [SCORE] : 0.5696649074554443\n",
      "[168/1000]\n",
      "- [VAL] LOSS : 0.06038786098361015 [SCORE] : 1.0\n",
      "[169/1000]\n",
      "- [TRAIN] LOSS : 0.06369019107272228 [SCORE] : 0.5696649074554443\n",
      "[169/1000]\n",
      "- [VAL] LOSS : 0.060127679258584976 [SCORE] : 1.0\n",
      "[170/1000]\n",
      "- [TRAIN] LOSS : 0.06352352034300565 [SCORE] : 0.5696649074554443\n",
      "[170/1000]\n",
      "- [VAL] LOSS : 0.05988020449876785 [SCORE] : 1.0\n",
      "[171/1000]\n",
      "- [TRAIN] LOSS : 0.06335405788073938 [SCORE] : 0.5696649074554443\n",
      "[171/1000]\n",
      "- [VAL] LOSS : 0.05960870534181595 [SCORE] : 1.0\n",
      "[172/1000]\n",
      "- [TRAIN] LOSS : 0.06319373088578382 [SCORE] : 0.5696649074554443\n",
      "[172/1000]\n",
      "- [VAL] LOSS : 0.05933406576514244 [SCORE] : 1.0\n",
      "[173/1000]\n",
      "- [TRAIN] LOSS : 0.06304367327441772 [SCORE] : 0.5696649074554443\n",
      "[173/1000]\n",
      "- [VAL] LOSS : 0.05909256264567375 [SCORE] : 1.0\n",
      "[174/1000]\n",
      "- [TRAIN] LOSS : 0.06289148132006327 [SCORE] : 0.5696649074554443\n",
      "[174/1000]\n",
      "- [VAL] LOSS : 0.05886431410908699 [SCORE] : 1.0\n",
      "[175/1000]\n",
      "- [TRAIN] LOSS : 0.0627362322062254 [SCORE] : 0.5696649074554443\n",
      "[175/1000]\n",
      "- [VAL] LOSS : 0.05861414223909378 [SCORE] : 1.0\n",
      "[176/1000]\n",
      "- [TRAIN] LOSS : 0.06259175253411134 [SCORE] : 0.5696649074554443\n",
      "[176/1000]\n",
      "- [VAL] LOSS : 0.05837040767073631 [SCORE] : 1.0\n",
      "[177/1000]\n",
      "- [TRAIN] LOSS : 0.06244850469132265 [SCORE] : 0.5696649074554443\n",
      "[177/1000]\n",
      "- [VAL] LOSS : 0.05813726410269737 [SCORE] : 1.0\n",
      "[178/1000]\n",
      "- [TRAIN] LOSS : 0.06231037583202124 [SCORE] : 0.5696649074554443\n",
      "[178/1000]\n",
      "- [VAL] LOSS : 0.05791408568620682 [SCORE] : 1.0\n",
      "[179/1000]\n",
      "- [TRAIN] LOSS : 0.06217322175701459 [SCORE] : 0.5696649074554443\n",
      "[179/1000]\n",
      "- [VAL] LOSS : 0.057699110358953476 [SCORE] : 1.0\n",
      "[180/1000]\n",
      "- [TRAIN] LOSS : 0.0620347465078036 [SCORE] : 0.5696649074554443\n",
      "[180/1000]\n",
      "- [VAL] LOSS : 0.05747084692120552 [SCORE] : 1.0\n",
      "[181/1000]\n",
      "- [TRAIN] LOSS : 0.061905187306304774 [SCORE] : 0.5696649074554443\n",
      "[181/1000]\n",
      "- [VAL] LOSS : 0.05725160986185074 [SCORE] : 1.0\n",
      "[182/1000]\n",
      "- [TRAIN] LOSS : 0.06177570925404628 [SCORE] : 0.5696649074554443\n",
      "[182/1000]\n",
      "- [VAL] LOSS : 0.05704007297754288 [SCORE] : 1.0\n",
      "[183/1000]\n",
      "- [TRAIN] LOSS : 0.061650882661342624 [SCORE] : 0.5696649074554443\n",
      "[183/1000]\n",
      "- [VAL] LOSS : 0.05683587118983269 [SCORE] : 1.0\n",
      "[184/1000]\n",
      "- [TRAIN] LOSS : 0.06152711771428585 [SCORE] : 0.5696649074554443\n",
      "[184/1000]\n",
      "- [VAL] LOSS : 0.05663927271962166 [SCORE] : 1.0\n",
      "[185/1000]\n",
      "- [TRAIN] LOSS : 0.06140199657529592 [SCORE] : 0.5696649074554443\n",
      "[185/1000]\n",
      "- [VAL] LOSS : 0.056431110948324203 [SCORE] : 1.0\n",
      "[186/1000]\n",
      "- [TRAIN] LOSS : 0.061284887790679934 [SCORE] : 0.5696649074554443\n",
      "[186/1000]\n",
      "- [VAL] LOSS : 0.056231193244457245 [SCORE] : 1.0\n",
      "[187/1000]\n",
      "- [TRAIN] LOSS : 0.0611697136114041 [SCORE] : 0.5696649074554443\n",
      "[187/1000]\n",
      "- [VAL] LOSS : 0.056046199053525925 [SCORE] : 1.0\n",
      "[188/1000]\n",
      "- [TRAIN] LOSS : 0.061052014119923115 [SCORE] : 0.5696649074554443\n",
      "[188/1000]\n",
      "- [VAL] LOSS : 0.05585245043039322 [SCORE] : 1.0\n",
      "[189/1000]\n",
      "- [TRAIN] LOSS : 0.06094107838968436 [SCORE] : 0.5696649074554443\n",
      "[189/1000]\n",
      "- [VAL] LOSS : 0.05566354840993881 [SCORE] : 1.0\n",
      "[190/1000]\n",
      "- [TRAIN] LOSS : 0.060832136186460654 [SCORE] : 0.5696649074554443\n",
      "[190/1000]\n",
      "- [VAL] LOSS : 0.05548685044050217 [SCORE] : 1.0\n",
      "[191/1000]\n",
      "- [TRAIN] LOSS : 0.06072107640405496 [SCORE] : 0.5696649074554443\n",
      "[191/1000]\n",
      "- [VAL] LOSS : 0.05530219525098801 [SCORE] : 1.0\n",
      "[192/1000]\n",
      "- [TRAIN] LOSS : 0.06061647099753221 [SCORE] : 0.5696649074554443\n",
      "[192/1000]\n",
      "- [VAL] LOSS : 0.05512275546789169 [SCORE] : 1.0\n",
      "[193/1000]\n",
      "- [TRAIN] LOSS : 0.06051348882416884 [SCORE] : 0.5696649074554443\n",
      "[193/1000]\n",
      "- [VAL] LOSS : 0.05495482683181763 [SCORE] : 1.0\n",
      "[194/1000]\n",
      "- [TRAIN] LOSS : 0.060408447496593 [SCORE] : 0.5696649074554443\n",
      "[194/1000]\n",
      "- [VAL] LOSS : 0.054779134690761566 [SCORE] : 1.0\n",
      "[195/1000]\n",
      "- [TRAIN] LOSS : 0.06030948745707671 [SCORE] : 0.5696649074554443\n",
      "[195/1000]\n",
      "- [VAL] LOSS : 0.054608218371868134 [SCORE] : 1.0\n",
      "[196/1000]\n",
      "- [TRAIN] LOSS : 0.06021209303289652 [SCORE] : 0.5696649074554443\n",
      "[196/1000]\n",
      "- [VAL] LOSS : 0.05444828420877457 [SCORE] : 1.0\n",
      "[197/1000]\n",
      "- [TRAIN] LOSS : 0.060112590963641806 [SCORE] : 0.5696649074554443\n",
      "[197/1000]\n",
      "- [VAL] LOSS : 0.05428082495927811 [SCORE] : 1.0\n",
      "[198/1000]\n",
      "- [TRAIN] LOSS : 0.06001889202743769 [SCORE] : 0.5696649074554443\n",
      "[198/1000]\n",
      "- [VAL] LOSS : 0.05411795154213905 [SCORE] : 1.0\n",
      "[199/1000]\n",
      "- [TRAIN] LOSS : 0.059926617331802844 [SCORE] : 0.5696649074554443\n",
      "[199/1000]\n",
      "- [VAL] LOSS : 0.053965307772159576 [SCORE] : 1.0\n",
      "[200/1000]\n",
      "- [TRAIN] LOSS : 0.05983404206732909 [SCORE] : 0.5696649074554443\n",
      "[200/1000]\n",
      "- [VAL] LOSS : 0.05381203442811966 [SCORE] : 1.0\n",
      "[201/1000]\n",
      "- [TRAIN] LOSS : 0.05974119038631519 [SCORE] : 0.5696649074554443\n",
      "[201/1000]\n",
      "- [VAL] LOSS : 0.05364932864904404 [SCORE] : 1.0\n",
      "[202/1000]\n",
      "- [TRAIN] LOSS : 0.05965486435840527 [SCORE] : 0.5696649074554443\n",
      "[202/1000]\n",
      "- [VAL] LOSS : 0.0534956194460392 [SCORE] : 1.0\n",
      "[203/1000]\n",
      "- [TRAIN] LOSS : 0.05956907315800587 [SCORE] : 0.5696649074554443\n",
      "[203/1000]\n",
      "- [VAL] LOSS : 0.053352128714323044 [SCORE] : 1.0\n",
      "[204/1000]\n",
      "- [TRAIN] LOSS : 0.059481171704828736 [SCORE] : 0.5696649074554443\n",
      "[204/1000]\n",
      "- [VAL] LOSS : 0.053202301263809204 [SCORE] : 1.0\n",
      "[205/1000]\n",
      "- [TRAIN] LOSS : 0.059398292936384676 [SCORE] : 0.5696649074554443\n",
      "[205/1000]\n",
      "- [VAL] LOSS : 0.05305572226643562 [SCORE] : 1.0\n",
      "[206/1000]\n",
      "- [TRAIN] LOSS : 0.05931648351252079 [SCORE] : 0.5696649074554443\n",
      "[206/1000]\n",
      "- [VAL] LOSS : 0.05291692167520523 [SCORE] : 1.0\n",
      "[207/1000]\n",
      "- [TRAIN] LOSS : 0.05923446311304967 [SCORE] : 0.5696649074554443\n",
      "[207/1000]\n",
      "- [VAL] LOSS : 0.05277756229043007 [SCORE] : 1.0\n",
      "[208/1000]\n",
      "- [TRAIN] LOSS : 0.059154202416539195 [SCORE] : 0.5696649074554443\n",
      "[208/1000]\n",
      "- [VAL] LOSS : 0.05263803154230118 [SCORE] : 1.0\n",
      "[209/1000]\n",
      "- [TRAIN] LOSS : 0.059075621577600636 [SCORE] : 0.5696649074554443\n",
      "[209/1000]\n",
      "- [VAL] LOSS : 0.0525004044175148 [SCORE] : 1.0\n",
      "[210/1000]\n",
      "- [TRAIN] LOSS : 0.058998268594344455 [SCORE] : 0.5696649074554443\n",
      "[210/1000]\n",
      "- [VAL] LOSS : 0.052364248782396317 [SCORE] : 1.0\n",
      "[211/1000]\n",
      "- [TRAIN] LOSS : 0.05892232917249203 [SCORE] : 0.5696649074554443\n",
      "[211/1000]\n",
      "- [VAL] LOSS : 0.052230749279260635 [SCORE] : 1.0\n",
      "[212/1000]\n",
      "- [TRAIN] LOSS : 0.05884784559408824 [SCORE] : 0.5696649074554443\n",
      "[212/1000]\n",
      "- [VAL] LOSS : 0.05210033431649208 [SCORE] : 1.0\n",
      "[213/1000]\n",
      "- [TRAIN] LOSS : 0.05877424236387015 [SCORE] : 0.5696649074554443\n",
      "[213/1000]\n",
      "- [VAL] LOSS : 0.0519719123840332 [SCORE] : 1.0\n",
      "[214/1000]\n",
      "- [TRAIN] LOSS : 0.05870155431330204 [SCORE] : 0.5696649074554443\n",
      "[214/1000]\n",
      "- [VAL] LOSS : 0.05184390768408775 [SCORE] : 1.0\n",
      "[215/1000]\n",
      "- [TRAIN] LOSS : 0.05863019302487373 [SCORE] : 0.5696649074554443\n",
      "[215/1000]\n",
      "- [VAL] LOSS : 0.0517173632979393 [SCORE] : 1.0\n",
      "[216/1000]\n",
      "- [TRAIN] LOSS : 0.058560271933674815 [SCORE] : 0.5696649074554443\n",
      "[216/1000]\n",
      "- [VAL] LOSS : 0.05159374698996544 [SCORE] : 1.0\n",
      "[217/1000]\n",
      "- [TRAIN] LOSS : 0.05849102772772312 [SCORE] : 0.5696649074554443\n",
      "[217/1000]\n",
      "- [VAL] LOSS : 0.05147089436650276 [SCORE] : 1.0\n",
      "[218/1000]\n",
      "- [TRAIN] LOSS : 0.05842300715545813 [SCORE] : 0.5696649074554443\n",
      "[218/1000]\n",
      "- [VAL] LOSS : 0.05134948715567589 [SCORE] : 1.0\n",
      "[219/1000]\n",
      "- [TRAIN] LOSS : 0.058356343085567156 [SCORE] : 0.5696649074554443\n",
      "[219/1000]\n",
      "- [VAL] LOSS : 0.051230914890766144 [SCORE] : 1.0\n",
      "[220/1000]\n",
      "- [TRAIN] LOSS : 0.05829022461548448 [SCORE] : 0.5696649074554443\n",
      "[220/1000]\n",
      "- [VAL] LOSS : 0.051113177090883255 [SCORE] : 1.0\n",
      "[221/1000]\n",
      "- [TRAIN] LOSS : 0.05822545246531566 [SCORE] : 0.5696649074554443\n",
      "[221/1000]\n",
      "- [VAL] LOSS : 0.05099768564105034 [SCORE] : 1.0\n",
      "[222/1000]\n",
      "- [TRAIN] LOSS : 0.05816138001779715 [SCORE] : 0.5696649074554443\n",
      "[222/1000]\n",
      "- [VAL] LOSS : 0.050883032381534576 [SCORE] : 1.0\n",
      "[223/1000]\n",
      "- [TRAIN] LOSS : 0.058098330969611804 [SCORE] : 0.5696649074554443\n",
      "[223/1000]\n",
      "- [VAL] LOSS : 0.05076952651143074 [SCORE] : 1.0\n",
      "[224/1000]\n",
      "- [TRAIN] LOSS : 0.05803626558432976 [SCORE] : 0.5696649074554443\n",
      "[224/1000]\n",
      "- [VAL] LOSS : 0.050657499581575394 [SCORE] : 1.0\n",
      "[225/1000]\n",
      "- [TRAIN] LOSS : 0.05797540238127112 [SCORE] : 0.5696649074554443\n",
      "[225/1000]\n",
      "- [VAL] LOSS : 0.05054790526628494 [SCORE] : 1.0\n",
      "[226/1000]\n",
      "- [TRAIN] LOSS : 0.057914961501955985 [SCORE] : 0.5696649074554443\n",
      "[226/1000]\n",
      "- [VAL] LOSS : 0.05043894797563553 [SCORE] : 1.0\n",
      "[227/1000]\n",
      "- [TRAIN] LOSS : 0.05785577349985639 [SCORE] : 0.5696649074554443\n",
      "[227/1000]\n",
      "- [VAL] LOSS : 0.050332147628068924 [SCORE] : 1.0\n",
      "[228/1000]\n",
      "- [TRAIN] LOSS : 0.05779715503255526 [SCORE] : 0.5696649074554443\n",
      "[228/1000]\n",
      "- [VAL] LOSS : 0.05022572726011276 [SCORE] : 1.0\n",
      "[229/1000]\n",
      "- [TRAIN] LOSS : 0.0577394250780344 [SCORE] : 0.5696649074554443\n",
      "[229/1000]\n",
      "- [VAL] LOSS : 0.05012050271034241 [SCORE] : 1.0\n",
      "[230/1000]\n",
      "- [TRAIN] LOSS : 0.05768279346326987 [SCORE] : 0.5696649074554443\n",
      "[230/1000]\n",
      "- [VAL] LOSS : 0.05001760646700859 [SCORE] : 1.0\n",
      "[231/1000]\n",
      "- [TRAIN] LOSS : 0.057626631235082944 [SCORE] : 0.5696649074554443\n",
      "[231/1000]\n",
      "- [VAL] LOSS : 0.04991506412625313 [SCORE] : 1.0\n",
      "[232/1000]\n",
      "- [TRAIN] LOSS : 0.05757134833062689 [SCORE] : 0.5696649074554443\n",
      "[232/1000]\n",
      "- [VAL] LOSS : 0.049813587218523026 [SCORE] : 1.0\n",
      "[233/1000]\n",
      "- [TRAIN] LOSS : 0.05751718338578939 [SCORE] : 0.5696649074554443\n",
      "[233/1000]\n",
      "- [VAL] LOSS : 0.049714453518390656 [SCORE] : 1.0\n",
      "[234/1000]\n",
      "- [TRAIN] LOSS : 0.05746327253679435 [SCORE] : 0.5696649074554443\n",
      "[234/1000]\n",
      "- [VAL] LOSS : 0.04961564019322395 [SCORE] : 1.0\n",
      "[235/1000]\n",
      "- [TRAIN] LOSS : 0.05741049209609628 [SCORE] : 0.5696649074554443\n",
      "[235/1000]\n",
      "- [VAL] LOSS : 0.04951872304081917 [SCORE] : 1.0\n",
      "[236/1000]\n",
      "- [TRAIN] LOSS : 0.0573581193263332 [SCORE] : 0.5696649074554443\n",
      "[236/1000]\n",
      "- [VAL] LOSS : 0.049422167241573334 [SCORE] : 1.0\n",
      "[237/1000]\n",
      "- [TRAIN] LOSS : 0.05730652716010809 [SCORE] : 0.5696649074554443\n",
      "[237/1000]\n",
      "- [VAL] LOSS : 0.04932645335793495 [SCORE] : 1.0\n",
      "[238/1000]\n",
      "- [TRAIN] LOSS : 0.05725602541739742 [SCORE] : 0.5696649074554443\n",
      "[238/1000]\n",
      "- [VAL] LOSS : 0.04923290014266968 [SCORE] : 1.0\n",
      "[239/1000]\n",
      "- [TRAIN] LOSS : 0.057205905485898254 [SCORE] : 0.5696649074554443\n",
      "[239/1000]\n",
      "- [VAL] LOSS : 0.04914059489965439 [SCORE] : 1.0\n",
      "[240/1000]\n",
      "- [TRAIN] LOSS : 0.05715631550798814 [SCORE] : 0.5696649074554443\n",
      "[240/1000]\n",
      "- [VAL] LOSS : 0.049048446118831635 [SCORE] : 1.0\n",
      "[241/1000]\n",
      "- [TRAIN] LOSS : 0.05710742153848211 [SCORE] : 0.5696649074554443\n",
      "[241/1000]\n",
      "- [VAL] LOSS : 0.04895712062716484 [SCORE] : 1.0\n",
      "[242/1000]\n",
      "- [TRAIN] LOSS : 0.05705955944334467 [SCORE] : 0.5696649074554443\n",
      "[242/1000]\n",
      "- [VAL] LOSS : 0.04886776581406593 [SCORE] : 1.0\n",
      "[243/1000]\n",
      "- [TRAIN] LOSS : 0.057012091887493926 [SCORE] : 0.5696649074554443\n",
      "[243/1000]\n",
      "- [VAL] LOSS : 0.048779670149087906 [SCORE] : 1.0\n",
      "[244/1000]\n",
      "- [TRAIN] LOSS : 0.05696507080768545 [SCORE] : 0.5696649074554443\n",
      "[244/1000]\n",
      "- [VAL] LOSS : 0.048691682517528534 [SCORE] : 1.0\n",
      "[245/1000]\n",
      "- [TRAIN] LOSS : 0.056918695631126566 [SCORE] : 0.5696649074554443\n",
      "[245/1000]\n",
      "- [VAL] LOSS : 0.048604320734739304 [SCORE] : 1.0\n",
      "[246/1000]\n",
      "- [TRAIN] LOSS : 0.05687320505579312 [SCORE] : 0.5696649074554443\n",
      "[246/1000]\n",
      "- [VAL] LOSS : 0.04851875081658363 [SCORE] : 1.0\n",
      "[247/1000]\n",
      "- [TRAIN] LOSS : 0.056828167848289014 [SCORE] : 0.5696649074554443\n",
      "[247/1000]\n",
      "- [VAL] LOSS : 0.04843435436487198 [SCORE] : 1.0\n",
      "[248/1000]\n",
      "- [TRAIN] LOSS : 0.056783512917657694 [SCORE] : 0.5696649074554443\n",
      "[248/1000]\n",
      "- [VAL] LOSS : 0.04835018143057823 [SCORE] : 1.0\n",
      "[249/1000]\n",
      "- [TRAIN] LOSS : 0.05673953148846825 [SCORE] : 0.5696649074554443\n",
      "[249/1000]\n",
      "- [VAL] LOSS : 0.04826663061976433 [SCORE] : 1.0\n",
      "[250/1000]\n",
      "- [TRAIN] LOSS : 0.056696366922309 [SCORE] : 0.5696649074554443\n",
      "[250/1000]\n",
      "- [VAL] LOSS : 0.0481848418712616 [SCORE] : 1.0\n",
      "[251/1000]\n",
      "- [TRAIN] LOSS : 0.05665357243269682 [SCORE] : 0.5696649074554443\n",
      "[251/1000]\n",
      "- [VAL] LOSS : 0.048104073852300644 [SCORE] : 1.0\n",
      "[252/1000]\n",
      "- [TRAIN] LOSS : 0.05661112746844689 [SCORE] : 0.5696649074554443\n",
      "[252/1000]\n",
      "- [VAL] LOSS : 0.04802350327372551 [SCORE] : 1.0\n",
      "[253/1000]\n",
      "- [TRAIN] LOSS : 0.05656945991019408 [SCORE] : 0.5696649074554443\n",
      "[253/1000]\n",
      "- [VAL] LOSS : 0.047944266349077225 [SCORE] : 1.0\n",
      "[254/1000]\n",
      "- [TRAIN] LOSS : 0.05652811685577035 [SCORE] : 0.5696649074554443\n",
      "[254/1000]\n",
      "- [VAL] LOSS : 0.047865428030490875 [SCORE] : 1.0\n",
      "[255/1000]\n",
      "- [TRAIN] LOSS : 0.056487288077672324 [SCORE] : 0.5696649074554443\n",
      "[255/1000]\n",
      "- [VAL] LOSS : 0.047787126153707504 [SCORE] : 1.0\n",
      "[256/1000]\n",
      "- [TRAIN] LOSS : 0.05644725766032934 [SCORE] : 0.5696649074554443\n",
      "[256/1000]\n",
      "- [VAL] LOSS : 0.047710318118333817 [SCORE] : 1.0\n",
      "[257/1000]\n",
      "- [TRAIN] LOSS : 0.0564075299538672 [SCORE] : 0.5696649074554443\n",
      "[257/1000]\n",
      "- [VAL] LOSS : 0.04763456806540489 [SCORE] : 1.0\n",
      "[258/1000]\n",
      "- [TRAIN] LOSS : 0.05636810790747404 [SCORE] : 0.5696649074554443\n",
      "[258/1000]\n",
      "- [VAL] LOSS : 0.047559041529893875 [SCORE] : 1.0\n",
      "[259/1000]\n",
      "- [TRAIN] LOSS : 0.056329240060100955 [SCORE] : 0.5696649074554443\n",
      "[259/1000]\n",
      "- [VAL] LOSS : 0.047484032809734344 [SCORE] : 1.0\n",
      "[260/1000]\n",
      "- [TRAIN] LOSS : 0.05629104310646653 [SCORE] : 0.5696649074554443\n",
      "[260/1000]\n",
      "- [VAL] LOSS : 0.04741039499640465 [SCORE] : 1.0\n",
      "[261/1000]\n",
      "- [TRAIN] LOSS : 0.056253206574668486 [SCORE] : 0.5696649074554443\n",
      "[261/1000]\n",
      "- [VAL] LOSS : 0.04733768105506897 [SCORE] : 1.0\n",
      "[262/1000]\n",
      "- [TRAIN] LOSS : 0.056215632272263366 [SCORE] : 0.5696649074554443\n",
      "[262/1000]\n",
      "- [VAL] LOSS : 0.04726517200469971 [SCORE] : 1.0\n",
      "[263/1000]\n",
      "- [TRAIN] LOSS : 0.05617856495082378 [SCORE] : 0.5696649074554443\n",
      "[263/1000]\n",
      "- [VAL] LOSS : 0.047193121165037155 [SCORE] : 1.0\n",
      "[264/1000]\n",
      "- [TRAIN] LOSS : 0.056142148251334824 [SCORE] : 0.5696649074554443\n",
      "[264/1000]\n",
      "- [VAL] LOSS : 0.04712242633104324 [SCORE] : 1.0\n",
      "[265/1000]\n",
      "- [TRAIN] LOSS : 0.05610591486717264 [SCORE] : 0.5696649074554443\n",
      "[265/1000]\n",
      "- [VAL] LOSS : 0.047052063047885895 [SCORE] : 1.0\n",
      "[266/1000]\n",
      "- [TRAIN] LOSS : 0.05607027693962057 [SCORE] : 0.5696649074554443\n",
      "[266/1000]\n",
      "- [VAL] LOSS : 0.04698279872536659 [SCORE] : 1.0\n",
      "[267/1000]\n",
      "- [TRAIN] LOSS : 0.05603490552554528 [SCORE] : 0.5696649074554443\n",
      "[267/1000]\n",
      "- [VAL] LOSS : 0.046913813799619675 [SCORE] : 1.0\n",
      "[268/1000]\n",
      "- [TRAIN] LOSS : 0.05599989689265688 [SCORE] : 0.5696649074554443\n",
      "[268/1000]\n",
      "- [VAL] LOSS : 0.04684524983167648 [SCORE] : 1.0\n",
      "[269/1000]\n",
      "- [TRAIN] LOSS : 0.05596553261081378 [SCORE] : 0.5696649074554443\n",
      "[269/1000]\n",
      "- [VAL] LOSS : 0.04677797481417656 [SCORE] : 1.0\n",
      "[270/1000]\n",
      "- [TRAIN] LOSS : 0.055931993884344895 [SCORE] : 0.5696649074554443\n",
      "[270/1000]\n",
      "- [VAL] LOSS : 0.04671429470181465 [SCORE] : 1.0\n",
      "[271/1000]\n",
      "- [TRAIN] LOSS : 0.05589790446683764 [SCORE] : 0.5696649074554443\n",
      "[271/1000]\n",
      "- [VAL] LOSS : 0.04665018245577812 [SCORE] : 1.0\n",
      "[272/1000]\n",
      "- [TRAIN] LOSS : 0.05586396573732297 [SCORE] : 0.5696649074554443\n",
      "[272/1000]\n",
      "- [VAL] LOSS : 0.04658404737710953 [SCORE] : 1.0\n",
      "[273/1000]\n",
      "- [TRAIN] LOSS : 0.05583088211715222 [SCORE] : 0.5696649074554443\n",
      "[273/1000]\n",
      "- [VAL] LOSS : 0.046517930924892426 [SCORE] : 1.0\n",
      "[274/1000]\n",
      "- [TRAIN] LOSS : 0.05579854231327772 [SCORE] : 0.5696649074554443\n",
      "[274/1000]\n",
      "- [VAL] LOSS : 0.046453576534986496 [SCORE] : 1.0\n",
      "[275/1000]\n",
      "- [TRAIN] LOSS : 0.055766291140268244 [SCORE] : 0.5696649074554443\n",
      "[275/1000]\n",
      "- [VAL] LOSS : 0.04638995975255966 [SCORE] : 1.0\n",
      "[276/1000]\n",
      "- [TRAIN] LOSS : 0.05573443851123253 [SCORE] : 0.5696649074554443\n",
      "[276/1000]\n",
      "- [VAL] LOSS : 0.04632732644677162 [SCORE] : 1.0\n",
      "[277/1000]\n",
      "- [TRAIN] LOSS : 0.05570274141306678 [SCORE] : 0.5696649074554443\n",
      "[277/1000]\n",
      "- [VAL] LOSS : 0.04626467078924179 [SCORE] : 1.0\n",
      "[278/1000]\n",
      "- [TRAIN] LOSS : 0.055671488400548697 [SCORE] : 0.5696649074554443\n",
      "[278/1000]\n",
      "- [VAL] LOSS : 0.0462023988366127 [SCORE] : 1.0\n",
      "[279/1000]\n",
      "- [TRAIN] LOSS : 0.05564069791386525 [SCORE] : 0.5696649074554443\n",
      "[279/1000]\n",
      "- [VAL] LOSS : 0.04614120349287987 [SCORE] : 1.0\n",
      "[280/1000]\n",
      "- [TRAIN] LOSS : 0.05561010455712676 [SCORE] : 0.5696649074554443\n",
      "[280/1000]\n",
      "- [VAL] LOSS : 0.04608028754591942 [SCORE] : 1.0\n",
      "[281/1000]\n",
      "- [TRAIN] LOSS : 0.05557980264226595 [SCORE] : 0.5696649074554443\n",
      "[281/1000]\n",
      "- [VAL] LOSS : 0.04601981118321419 [SCORE] : 1.0\n",
      "[282/1000]\n",
      "- [TRAIN] LOSS : 0.055549973715096714 [SCORE] : 0.5696649074554443\n",
      "[282/1000]\n",
      "- [VAL] LOSS : 0.04596024379134178 [SCORE] : 1.0\n",
      "[283/1000]\n",
      "- [TRAIN] LOSS : 0.055520323508729534 [SCORE] : 0.5696649074554443\n",
      "[283/1000]\n",
      "- [VAL] LOSS : 0.04590100422501564 [SCORE] : 1.0\n",
      "[284/1000]\n",
      "- [TRAIN] LOSS : 0.055490969121456145 [SCORE] : 0.5696649074554443\n",
      "[284/1000]\n",
      "- [VAL] LOSS : 0.045842092484235764 [SCORE] : 1.0\n",
      "[285/1000]\n",
      "- [TRAIN] LOSS : 0.055462128451714915 [SCORE] : 0.5696649074554443\n",
      "[285/1000]\n",
      "- [VAL] LOSS : 0.04578424617648125 [SCORE] : 1.0\n",
      "[286/1000]\n",
      "- [TRAIN] LOSS : 0.05543332962940137 [SCORE] : 0.5696649074554443\n",
      "[286/1000]\n",
      "- [VAL] LOSS : 0.04572659358382225 [SCORE] : 1.0\n",
      "[287/1000]\n",
      "- [TRAIN] LOSS : 0.05540490485727787 [SCORE] : 0.5696649074554443\n",
      "[287/1000]\n",
      "- [VAL] LOSS : 0.045669231563806534 [SCORE] : 1.0\n",
      "[288/1000]\n",
      "- [TRAIN] LOSS : 0.05537679707631469 [SCORE] : 0.5696649074554443\n",
      "[288/1000]\n",
      "- [VAL] LOSS : 0.045612405985593796 [SCORE] : 1.0\n",
      "[289/1000]\n",
      "- [TRAIN] LOSS : 0.05534912319853902 [SCORE] : 0.5696649074554443\n",
      "[289/1000]\n",
      "- [VAL] LOSS : 0.04555654898285866 [SCORE] : 1.0\n",
      "[290/1000]\n",
      "- [TRAIN] LOSS : 0.05532150346164902 [SCORE] : 0.5696649074554443\n",
      "[290/1000]\n",
      "- [VAL] LOSS : 0.045500870794057846 [SCORE] : 1.0\n",
      "[291/1000]\n",
      "- [TRAIN] LOSS : 0.055294158837447566 [SCORE] : 0.5696649074554443\n",
      "[291/1000]\n",
      "- [VAL] LOSS : 0.045445557683706284 [SCORE] : 1.0\n",
      "[292/1000]\n",
      "- [TRAIN] LOSS : 0.05526731520270308 [SCORE] : 0.5696649074554443\n",
      "[292/1000]\n",
      "- [VAL] LOSS : 0.04539107531309128 [SCORE] : 1.0\n",
      "[293/1000]\n",
      "- [TRAIN] LOSS : 0.055240538778404395 [SCORE] : 0.5696649074554443\n",
      "[293/1000]\n",
      "- [VAL] LOSS : 0.04533686116337776 [SCORE] : 1.0\n",
      "[294/1000]\n",
      "- [TRAIN] LOSS : 0.05521406102925539 [SCORE] : 0.5696649074554443\n",
      "[294/1000]\n",
      "- [VAL] LOSS : 0.045283008366823196 [SCORE] : 1.0\n",
      "[295/1000]\n",
      "- [TRAIN] LOSS : 0.0551878426844875 [SCORE] : 0.5696649074554443\n",
      "[295/1000]\n",
      "- [VAL] LOSS : 0.045229554176330566 [SCORE] : 1.0\n",
      "[296/1000]\n",
      "- [TRAIN] LOSS : 0.05516204660137494 [SCORE] : 0.5696649074554443\n",
      "[296/1000]\n",
      "- [VAL] LOSS : 0.045176949352025986 [SCORE] : 1.0\n",
      "[297/1000]\n",
      "- [TRAIN] LOSS : 0.0551362494006753 [SCORE] : 0.5696649074554443\n",
      "[297/1000]\n",
      "- [VAL] LOSS : 0.04512455314397812 [SCORE] : 1.0\n",
      "[298/1000]\n",
      "- [TRAIN] LOSS : 0.055110794957727194 [SCORE] : 0.5696649074554443\n",
      "[298/1000]\n",
      "- [VAL] LOSS : 0.045072488486766815 [SCORE] : 1.0\n",
      "[299/1000]\n",
      "- [TRAIN] LOSS : 0.05508559355512262 [SCORE] : 0.5696649074554443\n",
      "[299/1000]\n",
      "- [VAL] LOSS : 0.04502074047923088 [SCORE] : 1.0\n",
      "[300/1000]\n",
      "- [TRAIN] LOSS : 0.05506079848855734 [SCORE] : 0.5696649074554443\n",
      "[300/1000]\n",
      "- [VAL] LOSS : 0.0449698306620121 [SCORE] : 1.0\n",
      "[301/1000]\n",
      "- [TRAIN] LOSS : 0.055036017950624225 [SCORE] : 0.5696649074554443\n",
      "[301/1000]\n",
      "- [VAL] LOSS : 0.04491912201046944 [SCORE] : 1.0\n",
      "[302/1000]\n",
      "- [TRAIN] LOSS : 0.05501152320454518 [SCORE] : 0.5696649074554443\n",
      "[302/1000]\n",
      "- [VAL] LOSS : 0.04486878588795662 [SCORE] : 1.0\n",
      "[303/1000]\n",
      "- [TRAIN] LOSS : 0.05498728345458706 [SCORE] : 0.5696649074554443\n",
      "[303/1000]\n",
      "- [VAL] LOSS : 0.04481879994273186 [SCORE] : 1.0\n",
      "[304/1000]\n",
      "- [TRAIN] LOSS : 0.05496338562419017 [SCORE] : 0.5696649074554443\n",
      "[304/1000]\n",
      "- [VAL] LOSS : 0.044769637286663055 [SCORE] : 1.0\n",
      "[305/1000]\n",
      "- [TRAIN] LOSS : 0.054939509058992066 [SCORE] : 0.5696649074554443\n",
      "[305/1000]\n",
      "- [VAL] LOSS : 0.04472056403756142 [SCORE] : 1.0\n",
      "[306/1000]\n",
      "- [TRAIN] LOSS : 0.0549159316966931 [SCORE] : 0.5696649074554443\n",
      "[306/1000]\n",
      "- [VAL] LOSS : 0.04467174783349037 [SCORE] : 1.0\n",
      "[307/1000]\n",
      "- [TRAIN] LOSS : 0.054892604053020475 [SCORE] : 0.5696649074554443\n",
      "[307/1000]\n",
      "- [VAL] LOSS : 0.04462341591715813 [SCORE] : 1.0\n",
      "[308/1000]\n",
      "- [TRAIN] LOSS : 0.054869466243932644 [SCORE] : 0.5696649074554443\n",
      "[308/1000]\n",
      "- [VAL] LOSS : 0.04457544907927513 [SCORE] : 1.0\n",
      "[309/1000]\n",
      "- [TRAIN] LOSS : 0.05484663996224602 [SCORE] : 0.5696649074554443\n",
      "[309/1000]\n",
      "- [VAL] LOSS : 0.044528234750032425 [SCORE] : 1.0\n",
      "[310/1000]\n",
      "- [TRAIN] LOSS : 0.05482389274984598 [SCORE] : 0.5696649074554443\n",
      "[310/1000]\n",
      "- [VAL] LOSS : 0.04448118805885315 [SCORE] : 1.0\n",
      "[311/1000]\n",
      "- [TRAIN] LOSS : 0.054801350956161815 [SCORE] : 0.5696649074554443\n",
      "[311/1000]\n",
      "- [VAL] LOSS : 0.04443427920341492 [SCORE] : 1.0\n",
      "[312/1000]\n",
      "- [TRAIN] LOSS : 0.054779061830292144 [SCORE] : 0.5696649074554443\n",
      "[312/1000]\n",
      "- [VAL] LOSS : 0.04438779503107071 [SCORE] : 1.0\n",
      "[313/1000]\n",
      "- [TRAIN] LOSS : 0.054756955491999784 [SCORE] : 0.5696649074554443\n",
      "[313/1000]\n",
      "- [VAL] LOSS : 0.04434166103601456 [SCORE] : 1.0\n",
      "[314/1000]\n",
      "- [TRAIN] LOSS : 0.05473517403006554 [SCORE] : 0.5696649074554443\n",
      "[314/1000]\n",
      "- [VAL] LOSS : 0.0442962720990181 [SCORE] : 1.0\n",
      "[315/1000]\n",
      "- [TRAIN] LOSS : 0.05471341566493114 [SCORE] : 0.5696649074554443\n",
      "[315/1000]\n",
      "- [VAL] LOSS : 0.04425104707479477 [SCORE] : 1.0\n",
      "[316/1000]\n",
      "- [TRAIN] LOSS : 0.05469186653693517 [SCORE] : 0.5696649074554443\n",
      "[316/1000]\n",
      "- [VAL] LOSS : 0.04420599713921547 [SCORE] : 1.0\n",
      "[317/1000]\n",
      "- [TRAIN] LOSS : 0.05467053279280663 [SCORE] : 0.5696649074554443\n",
      "[317/1000]\n",
      "- [VAL] LOSS : 0.04416128993034363 [SCORE] : 1.0\n",
      "[318/1000]\n",
      "- [TRAIN] LOSS : 0.054649428961177665 [SCORE] : 0.5696649074554443\n",
      "[318/1000]\n",
      "- [VAL] LOSS : 0.04411691799759865 [SCORE] : 1.0\n",
      "[319/1000]\n",
      "- [TRAIN] LOSS : 0.05462847858046492 [SCORE] : 0.5696649074554443\n",
      "[319/1000]\n",
      "- [VAL] LOSS : 0.04407293349504471 [SCORE] : 1.0\n",
      "[320/1000]\n",
      "- [TRAIN] LOSS : 0.054607708907375735 [SCORE] : 0.5696649074554443\n",
      "[320/1000]\n",
      "- [VAL] LOSS : 0.04402922838926315 [SCORE] : 1.0\n",
      "[321/1000]\n",
      "- [TRAIN] LOSS : 0.05458724657073617 [SCORE] : 0.5696649074554443\n",
      "[321/1000]\n",
      "- [VAL] LOSS : 0.04398621246218681 [SCORE] : 1.0\n",
      "[322/1000]\n",
      "- [TRAIN] LOSS : 0.05456676129251718 [SCORE] : 0.5696649074554443\n",
      "[322/1000]\n",
      "- [VAL] LOSS : 0.04394332692027092 [SCORE] : 1.0\n",
      "[323/1000]\n",
      "- [TRAIN] LOSS : 0.05454650968313217 [SCORE] : 0.5696649074554443\n",
      "[323/1000]\n",
      "- [VAL] LOSS : 0.04390062764286995 [SCORE] : 1.0\n",
      "[324/1000]\n",
      "- [TRAIN] LOSS : 0.05452646178503831 [SCORE] : 0.5696649074554443\n",
      "[324/1000]\n",
      "- [VAL] LOSS : 0.04385829344391823 [SCORE] : 1.0\n",
      "[325/1000]\n",
      "- [TRAIN] LOSS : 0.054506579569230475 [SCORE] : 0.5696649074554443\n",
      "[325/1000]\n",
      "- [VAL] LOSS : 0.043816305696964264 [SCORE] : 1.0\n",
      "[326/1000]\n",
      "- [TRAIN] LOSS : 0.05448683298503359 [SCORE] : 0.5696649074554443\n",
      "[326/1000]\n",
      "- [VAL] LOSS : 0.043774522840976715 [SCORE] : 1.0\n",
      "[327/1000]\n",
      "- [TRAIN] LOSS : 0.05446730051189661 [SCORE] : 0.5696649074554443\n",
      "[327/1000]\n",
      "- [VAL] LOSS : 0.043733056634664536 [SCORE] : 1.0\n",
      "[328/1000]\n",
      "- [TRAIN] LOSS : 0.05444790277009209 [SCORE] : 0.5696649074554443\n",
      "[328/1000]\n",
      "- [VAL] LOSS : 0.043691907078027725 [SCORE] : 1.0\n",
      "[329/1000]\n",
      "- [TRAIN] LOSS : 0.054428762601067625 [SCORE] : 0.5696649074554443\n",
      "[329/1000]\n",
      "- [VAL] LOSS : 0.043651364743709564 [SCORE] : 1.0\n",
      "[330/1000]\n",
      "- [TRAIN] LOSS : 0.054409676045179364 [SCORE] : 0.5696649074554443\n",
      "[330/1000]\n",
      "- [VAL] LOSS : 0.04361095651984215 [SCORE] : 1.0\n",
      "[331/1000]\n",
      "- [TRAIN] LOSS : 0.05439075945566098 [SCORE] : 0.5696649074554443\n",
      "[331/1000]\n",
      "- [VAL] LOSS : 0.04357079416513443 [SCORE] : 1.0\n",
      "[332/1000]\n",
      "- [TRAIN] LOSS : 0.05437198144694169 [SCORE] : 0.5696649074554443\n",
      "[332/1000]\n",
      "- [VAL] LOSS : 0.04353086277842522 [SCORE] : 1.0\n",
      "[333/1000]\n",
      "- [TRAIN] LOSS : 0.05435337439800302 [SCORE] : 0.5696649074554443\n",
      "[333/1000]\n",
      "- [VAL] LOSS : 0.04349120333790779 [SCORE] : 1.0\n",
      "[334/1000]\n",
      "- [TRAIN] LOSS : 0.05433490667492151 [SCORE] : 0.5696649074554443\n",
      "[334/1000]\n",
      "- [VAL] LOSS : 0.043451812118291855 [SCORE] : 1.0\n",
      "[335/1000]\n",
      "- [TRAIN] LOSS : 0.05431661186739802 [SCORE] : 0.5696649074554443\n",
      "[335/1000]\n",
      "- [VAL] LOSS : 0.04341268911957741 [SCORE] : 1.0\n",
      "[336/1000]\n",
      "- [TRAIN] LOSS : 0.054298464798678954 [SCORE] : 0.5696649074554443\n",
      "[336/1000]\n",
      "- [VAL] LOSS : 0.04337390884757042 [SCORE] : 1.0\n",
      "[337/1000]\n",
      "- [TRAIN] LOSS : 0.05428046608964602 [SCORE] : 0.5696649074554443\n",
      "[337/1000]\n",
      "- [VAL] LOSS : 0.043335359543561935 [SCORE] : 1.0\n",
      "[338/1000]\n",
      "- [TRAIN] LOSS : 0.05426263548433781 [SCORE] : 0.5696649074554443\n",
      "[338/1000]\n",
      "- [VAL] LOSS : 0.04329710826277733 [SCORE] : 1.0\n",
      "[339/1000]\n",
      "- [TRAIN] LOSS : 0.05424487004056573 [SCORE] : 0.5696649074554443\n",
      "[339/1000]\n",
      "- [VAL] LOSS : 0.04325912520289421 [SCORE] : 1.0\n",
      "[340/1000]\n",
      "- [TRAIN] LOSS : 0.05422733929008246 [SCORE] : 0.5696649074554443\n",
      "[340/1000]\n",
      "- [VAL] LOSS : 0.04322141408920288 [SCORE] : 1.0\n",
      "[341/1000]\n",
      "- [TRAIN] LOSS : 0.05420987910280625 [SCORE] : 0.5696649074554443\n",
      "[341/1000]\n",
      "- [VAL] LOSS : 0.04318400099873543 [SCORE] : 1.0\n",
      "[342/1000]\n",
      "- [TRAIN] LOSS : 0.054192587112387024 [SCORE] : 0.5696649074554443\n",
      "[342/1000]\n",
      "- [VAL] LOSS : 0.043146781623363495 [SCORE] : 1.0\n",
      "[343/1000]\n",
      "- [TRAIN] LOSS : 0.054175416380167006 [SCORE] : 0.5696649074554443\n",
      "[343/1000]\n",
      "- [VAL] LOSS : 0.04310983046889305 [SCORE] : 1.0\n",
      "[344/1000]\n",
      "- [TRAIN] LOSS : 0.05415838264549772 [SCORE] : 0.5696649074554443\n",
      "[344/1000]\n",
      "- [VAL] LOSS : 0.0430731438100338 [SCORE] : 1.0\n",
      "[345/1000]\n",
      "- [TRAIN] LOSS : 0.05414151530712843 [SCORE] : 0.5696649074554443\n",
      "[345/1000]\n",
      "- [VAL] LOSS : 0.04303677752614021 [SCORE] : 1.0\n",
      "[346/1000]\n",
      "- [TRAIN] LOSS : 0.05412470732505123 [SCORE] : 0.5696649074554443\n",
      "[346/1000]\n",
      "- [VAL] LOSS : 0.04300052300095558 [SCORE] : 1.0\n",
      "[347/1000]\n",
      "- [TRAIN] LOSS : 0.05410809127303461 [SCORE] : 0.5696649074554443\n",
      "[347/1000]\n",
      "- [VAL] LOSS : 0.04296458140015602 [SCORE] : 1.0\n",
      "[348/1000]\n",
      "- [TRAIN] LOSS : 0.054091557130838436 [SCORE] : 0.5696649074554443\n",
      "[348/1000]\n",
      "- [VAL] LOSS : 0.042928896844387054 [SCORE] : 1.0\n",
      "[349/1000]\n",
      "- [TRAIN] LOSS : 0.05407518834496538 [SCORE] : 0.5696649074554443\n",
      "[349/1000]\n",
      "- [VAL] LOSS : 0.04289349168539047 [SCORE] : 1.0\n",
      "[350/1000]\n",
      "- [TRAIN] LOSS : 0.05405892807369431 [SCORE] : 0.5696649074554443\n",
      "[350/1000]\n",
      "- [VAL] LOSS : 0.0428583100438118 [SCORE] : 1.0\n",
      "[351/1000]\n",
      "- [TRAIN] LOSS : 0.054042792630692324 [SCORE] : 0.5696649074554443\n",
      "[351/1000]\n",
      "- [VAL] LOSS : 0.04282335191965103 [SCORE] : 1.0\n",
      "[352/1000]\n",
      "- [TRAIN] LOSS : 0.05402676230296492 [SCORE] : 0.5696649074554443\n",
      "[352/1000]\n",
      "- [VAL] LOSS : 0.04278859868645668 [SCORE] : 1.0\n",
      "[353/1000]\n",
      "- [TRAIN] LOSS : 0.05401085739334424 [SCORE] : 0.5696649074554443\n",
      "[353/1000]\n",
      "- [VAL] LOSS : 0.042754121124744415 [SCORE] : 1.0\n",
      "[354/1000]\n",
      "- [TRAIN] LOSS : 0.053995077436168985 [SCORE] : 0.5696649074554443\n",
      "[354/1000]\n",
      "- [VAL] LOSS : 0.04271984100341797 [SCORE] : 1.0\n",
      "[355/1000]\n",
      "- [TRAIN] LOSS : 0.053979422974710665 [SCORE] : 0.5696649074554443\n",
      "[355/1000]\n",
      "- [VAL] LOSS : 0.04268584027886391 [SCORE] : 1.0\n",
      "[356/1000]\n",
      "- [TRAIN] LOSS : 0.05396389923989773 [SCORE] : 0.5696649074554443\n",
      "[356/1000]\n",
      "- [VAL] LOSS : 0.04265204444527626 [SCORE] : 1.0\n",
      "[357/1000]\n",
      "- [TRAIN] LOSS : 0.05394845755460362 [SCORE] : 0.5696649074554443\n",
      "[357/1000]\n",
      "- [VAL] LOSS : 0.04261840507388115 [SCORE] : 1.0\n",
      "[358/1000]\n",
      "- [TRAIN] LOSS : 0.05393312790741523 [SCORE] : 0.5696649074554443\n",
      "[358/1000]\n",
      "- [VAL] LOSS : 0.04258504509925842 [SCORE] : 1.0\n",
      "[359/1000]\n",
      "- [TRAIN] LOSS : 0.05391791675550242 [SCORE] : 0.5696649074554443\n",
      "[359/1000]\n",
      "- [VAL] LOSS : 0.04255188629031181 [SCORE] : 1.0\n",
      "[360/1000]\n",
      "- [TRAIN] LOSS : 0.05390280139011641 [SCORE] : 0.5696649074554443\n",
      "[360/1000]\n",
      "- [VAL] LOSS : 0.04251888394355774 [SCORE] : 1.0\n",
      "[361/1000]\n",
      "- [TRAIN] LOSS : 0.053887857543304565 [SCORE] : 0.5696649074554443\n",
      "[361/1000]\n",
      "- [VAL] LOSS : 0.04248626157641411 [SCORE] : 1.0\n",
      "[362/1000]\n",
      "- [TRAIN] LOSS : 0.05387294092215598 [SCORE] : 0.5696649074554443\n",
      "[362/1000]\n",
      "- [VAL] LOSS : 0.042453814297914505 [SCORE] : 1.0\n",
      "[363/1000]\n",
      "- [TRAIN] LOSS : 0.05385816410804788 [SCORE] : 0.5696649074554443\n",
      "[363/1000]\n",
      "- [VAL] LOSS : 0.042421456426382065 [SCORE] : 1.0\n",
      "[364/1000]\n",
      "- [TRAIN] LOSS : 0.05384350709306697 [SCORE] : 0.5696649074554443\n",
      "[364/1000]\n",
      "- [VAL] LOSS : 0.042389385402202606 [SCORE] : 1.0\n",
      "[365/1000]\n",
      "- [TRAIN] LOSS : 0.05382894769621392 [SCORE] : 0.5696649074554443\n",
      "[365/1000]\n",
      "- [VAL] LOSS : 0.0423574261367321 [SCORE] : 1.0\n",
      "[366/1000]\n",
      "- [TRAIN] LOSS : 0.053814476293822126 [SCORE] : 0.5696649074554443\n",
      "[366/1000]\n",
      "- [VAL] LOSS : 0.04232579097151756 [SCORE] : 1.0\n",
      "[367/1000]\n",
      "- [TRAIN] LOSS : 0.053800108128537735 [SCORE] : 0.5696649074554443\n",
      "[367/1000]\n",
      "- [VAL] LOSS : 0.04229428619146347 [SCORE] : 1.0\n",
      "[368/1000]\n",
      "- [TRAIN] LOSS : 0.05378583056541781 [SCORE] : 0.5696649074554443\n",
      "[368/1000]\n",
      "- [VAL] LOSS : 0.04226302728056908 [SCORE] : 1.0\n",
      "[369/1000]\n",
      "- [TRAIN] LOSS : 0.053771684023862086 [SCORE] : 0.5696649074554443\n",
      "[369/1000]\n",
      "- [VAL] LOSS : 0.0422319695353508 [SCORE] : 1.0\n",
      "[370/1000]\n",
      "- [TRAIN] LOSS : 0.05375761192602416 [SCORE] : 0.5696649074554443\n",
      "[370/1000]\n",
      "- [VAL] LOSS : 0.042201049625873566 [SCORE] : 1.0\n",
      "[371/1000]\n",
      "- [TRAIN] LOSS : 0.05374364503659308 [SCORE] : 0.5696649074554443\n",
      "[371/1000]\n",
      "- [VAL] LOSS : 0.042170364409685135 [SCORE] : 1.0\n",
      "[372/1000]\n",
      "- [TRAIN] LOSS : 0.05372979619229833 [SCORE] : 0.5696649074554443\n",
      "[372/1000]\n",
      "- [VAL] LOSS : 0.04213985428214073 [SCORE] : 1.0\n",
      "[373/1000]\n",
      "- [TRAIN] LOSS : 0.05371603889701267 [SCORE] : 0.5696649074554443\n",
      "[373/1000]\n",
      "- [VAL] LOSS : 0.04210953786969185 [SCORE] : 1.0\n",
      "[374/1000]\n",
      "- [TRAIN] LOSS : 0.053702299219245714 [SCORE] : 0.5696649074554443\n",
      "[374/1000]\n",
      "- [VAL] LOSS : 0.042079273611307144 [SCORE] : 1.0\n",
      "[375/1000]\n",
      "- [TRAIN] LOSS : 0.05368874610091249 [SCORE] : 0.5696649074554443\n",
      "[375/1000]\n",
      "- [VAL] LOSS : 0.04204937443137169 [SCORE] : 1.0\n",
      "[376/1000]\n",
      "- [TRAIN] LOSS : 0.05367523590102792 [SCORE] : 0.5696649074554443\n",
      "[376/1000]\n",
      "- [VAL] LOSS : 0.04201959818601608 [SCORE] : 1.0\n",
      "[377/1000]\n",
      "- [TRAIN] LOSS : 0.05366183465036253 [SCORE] : 0.5696649074554443\n",
      "[377/1000]\n",
      "- [VAL] LOSS : 0.04198992997407913 [SCORE] : 1.0\n",
      "[378/1000]\n",
      "- [TRAIN] LOSS : 0.05364851476624608 [SCORE] : 0.5696649074554443\n",
      "[378/1000]\n",
      "- [VAL] LOSS : 0.04196051508188248 [SCORE] : 1.0\n",
      "[379/1000]\n",
      "- [TRAIN] LOSS : 0.05363531308248639 [SCORE] : 0.5696649074554443\n",
      "[379/1000]\n",
      "- [VAL] LOSS : 0.04193124547600746 [SCORE] : 1.0\n",
      "[380/1000]\n",
      "- [TRAIN] LOSS : 0.05362218174462517 [SCORE] : 0.5696649074554443\n",
      "[380/1000]\n",
      "- [VAL] LOSS : 0.04190213233232498 [SCORE] : 1.0\n",
      "[381/1000]\n",
      "- [TRAIN] LOSS : 0.0536091533023864 [SCORE] : 0.5696649074554443\n",
      "[381/1000]\n",
      "- [VAL] LOSS : 0.04187328368425369 [SCORE] : 1.0\n",
      "[382/1000]\n",
      "- [TRAIN] LOSS : 0.053596198388064904 [SCORE] : 0.5696649074554443\n",
      "[382/1000]\n",
      "- [VAL] LOSS : 0.04184455797076225 [SCORE] : 1.0\n",
      "[383/1000]\n",
      "- [TRAIN] LOSS : 0.05358329797163606 [SCORE] : 0.5696649074554443\n",
      "[383/1000]\n",
      "- [VAL] LOSS : 0.04181594401597977 [SCORE] : 1.0\n",
      "[384/1000]\n",
      "- [TRAIN] LOSS : 0.05357052530162036 [SCORE] : 0.5696649074554443\n",
      "[384/1000]\n",
      "- [VAL] LOSS : 0.041787661612033844 [SCORE] : 1.0\n",
      "[385/1000]\n",
      "- [TRAIN] LOSS : 0.05355782505745689 [SCORE] : 0.5696649074554443\n",
      "[385/1000]\n",
      "- [VAL] LOSS : 0.04175950959324837 [SCORE] : 1.0\n",
      "[386/1000]\n",
      "- [TRAIN] LOSS : 0.05354517423547804 [SCORE] : 0.5696649074554443\n",
      "[386/1000]\n",
      "- [VAL] LOSS : 0.04173140972852707 [SCORE] : 1.0\n",
      "[387/1000]\n",
      "- [TRAIN] LOSS : 0.053532636056964594 [SCORE] : 0.5696649074554443\n",
      "[387/1000]\n",
      "- [VAL] LOSS : 0.04170352220535278 [SCORE] : 1.0\n",
      "[388/1000]\n",
      "- [TRAIN] LOSS : 0.05352016778973242 [SCORE] : 0.5696649074554443\n",
      "[388/1000]\n",
      "- [VAL] LOSS : 0.04167575016617775 [SCORE] : 1.0\n",
      "[389/1000]\n",
      "- [TRAIN] LOSS : 0.05350780476195117 [SCORE] : 0.5696649074554443\n",
      "[389/1000]\n",
      "- [VAL] LOSS : 0.041648272424936295 [SCORE] : 1.0\n",
      "[390/1000]\n",
      "- [TRAIN] LOSS : 0.053495498824243745 [SCORE] : 0.5696649074554443\n",
      "[390/1000]\n",
      "- [VAL] LOSS : 0.04162096604704857 [SCORE] : 1.0\n",
      "[391/1000]\n",
      "- [TRAIN] LOSS : 0.0534832652968665 [SCORE] : 0.5696649074554443\n",
      "[391/1000]\n",
      "- [VAL] LOSS : 0.04159367457032204 [SCORE] : 1.0\n",
      "[392/1000]\n",
      "- [TRAIN] LOSS : 0.053471110357592506 [SCORE] : 0.5696649074554443\n",
      "[392/1000]\n",
      "- [VAL] LOSS : 0.04156650975346565 [SCORE] : 1.0\n",
      "[393/1000]\n",
      "- [TRAIN] LOSS : 0.053459054542084536 [SCORE] : 0.5696649074554443\n",
      "[393/1000]\n",
      "- [VAL] LOSS : 0.04153954237699509 [SCORE] : 1.0\n",
      "[394/1000]\n",
      "- [TRAIN] LOSS : 0.053447105533753834 [SCORE] : 0.5696649074554443\n",
      "[394/1000]\n",
      "- [VAL] LOSS : 0.04151289537549019 [SCORE] : 1.0\n",
      "[395/1000]\n",
      "- [TRAIN] LOSS : 0.05343512903588513 [SCORE] : 0.5696649074554443\n",
      "[395/1000]\n",
      "- [VAL] LOSS : 0.04148627445101738 [SCORE] : 1.0\n",
      "[396/1000]\n",
      "- [TRAIN] LOSS : 0.05342330451433857 [SCORE] : 0.5696649074554443\n",
      "[396/1000]\n",
      "- [VAL] LOSS : 0.04145986586809158 [SCORE] : 1.0\n",
      "[397/1000]\n",
      "- [TRAIN] LOSS : 0.05341154534059266 [SCORE] : 0.5696649074554443\n",
      "[397/1000]\n",
      "- [VAL] LOSS : 0.041433535516262054 [SCORE] : 1.0\n",
      "[398/1000]\n",
      "- [TRAIN] LOSS : 0.0533998124456654 [SCORE] : 0.5696649074554443\n",
      "[398/1000]\n",
      "- [VAL] LOSS : 0.04140729084610939 [SCORE] : 1.0\n",
      "[399/1000]\n",
      "- [TRAIN] LOSS : 0.05338823723917206 [SCORE] : 0.5696649074554443\n",
      "[399/1000]\n",
      "- [VAL] LOSS : 0.041381340473890305 [SCORE] : 1.0\n",
      "[400/1000]\n",
      "- [TRAIN] LOSS : 0.05337668491216997 [SCORE] : 0.5696649074554443\n",
      "[400/1000]\n",
      "- [VAL] LOSS : 0.04135557636618614 [SCORE] : 1.0\n",
      "[401/1000]\n",
      "- [TRAIN] LOSS : 0.05336516449848811 [SCORE] : 0.5696649074554443\n",
      "[401/1000]\n",
      "- [VAL] LOSS : 0.04132988303899765 [SCORE] : 1.0\n",
      "[402/1000]\n",
      "- [TRAIN] LOSS : 0.053353744683166344 [SCORE] : 0.5696649074554443\n",
      "[402/1000]\n",
      "- [VAL] LOSS : 0.041304223239421844 [SCORE] : 1.0\n",
      "[403/1000]\n",
      "- [TRAIN] LOSS : 0.05334243928082287 [SCORE] : 0.5696649074554443\n",
      "[403/1000]\n",
      "- [VAL] LOSS : 0.04127883166074753 [SCORE] : 1.0\n",
      "[404/1000]\n",
      "- [TRAIN] LOSS : 0.05333117802316944 [SCORE] : 0.5696649074554443\n",
      "[404/1000]\n",
      "- [VAL] LOSS : 0.041253622621297836 [SCORE] : 1.0\n",
      "[405/1000]\n",
      "- [TRAIN] LOSS : 0.05331991858159502 [SCORE] : 0.5696649074554443\n",
      "[405/1000]\n",
      "- [VAL] LOSS : 0.04122846573591232 [SCORE] : 1.0\n",
      "[406/1000]\n",
      "- [TRAIN] LOSS : 0.05330879037889342 [SCORE] : 0.5696649074554443\n",
      "[406/1000]\n",
      "- [VAL] LOSS : 0.04120347648859024 [SCORE] : 1.0\n",
      "[407/1000]\n",
      "- [TRAIN] LOSS : 0.053297740609074634 [SCORE] : 0.5696649074554443\n",
      "[407/1000]\n",
      "- [VAL] LOSS : 0.04117867350578308 [SCORE] : 1.0\n",
      "[408/1000]\n",
      "- [TRAIN] LOSS : 0.05328672599668304 [SCORE] : 0.5696649074554443\n",
      "[408/1000]\n",
      "- [VAL] LOSS : 0.04115394875407219 [SCORE] : 1.0\n",
      "[409/1000]\n",
      "- [TRAIN] LOSS : 0.053275788032139344 [SCORE] : 0.5696649074554443\n",
      "[409/1000]\n",
      "- [VAL] LOSS : 0.04112933203577995 [SCORE] : 1.0\n",
      "[410/1000]\n",
      "- [TRAIN] LOSS : 0.05326491335096459 [SCORE] : 0.5696649074554443\n",
      "[410/1000]\n",
      "- [VAL] LOSS : 0.04110490903258324 [SCORE] : 1.0\n",
      "[411/1000]\n",
      "- [TRAIN] LOSS : 0.053254111825178065 [SCORE] : 0.5696649074554443\n",
      "[411/1000]\n",
      "- [VAL] LOSS : 0.04108067974448204 [SCORE] : 1.0\n",
      "[412/1000]\n",
      "- [TRAIN] LOSS : 0.05324333282187581 [SCORE] : 0.5696649074554443\n",
      "[412/1000]\n",
      "- [VAL] LOSS : 0.04105648398399353 [SCORE] : 1.0\n",
      "[413/1000]\n",
      "- [TRAIN] LOSS : 0.05323266607398788 [SCORE] : 0.5696649074554443\n",
      "[413/1000]\n",
      "- [VAL] LOSS : 0.04103245958685875 [SCORE] : 1.0\n",
      "[414/1000]\n",
      "- [TRAIN] LOSS : 0.053222028585150835 [SCORE] : 0.5696649074554443\n",
      "[414/1000]\n",
      "- [VAL] LOSS : 0.04100847244262695 [SCORE] : 1.0\n",
      "[415/1000]\n",
      "- [TRAIN] LOSS : 0.05321149576144914 [SCORE] : 0.5696649074554443\n",
      "[415/1000]\n",
      "- [VAL] LOSS : 0.04098472371697426 [SCORE] : 1.0\n",
      "[416/1000]\n",
      "- [TRAIN] LOSS : 0.053200978552922606 [SCORE] : 0.5696649074554443\n",
      "[416/1000]\n",
      "- [VAL] LOSS : 0.040961090475320816 [SCORE] : 1.0\n",
      "[417/1000]\n",
      "- [TRAIN] LOSS : 0.05319053779045741 [SCORE] : 0.5696649074554443\n",
      "[417/1000]\n",
      "- [VAL] LOSS : 0.04093751683831215 [SCORE] : 1.0\n",
      "[418/1000]\n",
      "- [TRAIN] LOSS : 0.053180165681988 [SCORE] : 0.5696649074554443\n",
      "[418/1000]\n",
      "- [VAL] LOSS : 0.04091418534517288 [SCORE] : 1.0\n",
      "[419/1000]\n",
      "- [TRAIN] LOSS : 0.053169851082687576 [SCORE] : 0.5696649074554443\n",
      "[419/1000]\n",
      "- [VAL] LOSS : 0.040890924632549286 [SCORE] : 1.0\n",
      "[420/1000]\n",
      "- [TRAIN] LOSS : 0.053159607512255506 [SCORE] : 0.5696649074554443\n",
      "[420/1000]\n",
      "- [VAL] LOSS : 0.04086783155798912 [SCORE] : 1.0\n",
      "[421/1000]\n",
      "- [TRAIN] LOSS : 0.05314940415943662 [SCORE] : 0.5696649074554443\n",
      "[421/1000]\n",
      "- [VAL] LOSS : 0.04084480553865433 [SCORE] : 1.0\n",
      "[422/1000]\n",
      "- [TRAIN] LOSS : 0.053139219200238584 [SCORE] : 0.5696649074554443\n",
      "[422/1000]\n",
      "- [VAL] LOSS : 0.0408218577504158 [SCORE] : 1.0\n",
      "[423/1000]\n",
      "- [TRAIN] LOSS : 0.05312916825835903 [SCORE] : 0.5696649074554443\n",
      "[423/1000]\n",
      "- [VAL] LOSS : 0.04079904779791832 [SCORE] : 1.0\n",
      "[424/1000]\n",
      "- [TRAIN] LOSS : 0.05311917196959257 [SCORE] : 0.5696649074554443\n",
      "[424/1000]\n",
      "- [VAL] LOSS : 0.040776558220386505 [SCORE] : 1.0\n",
      "[425/1000]\n",
      "- [TRAIN] LOSS : 0.05310916630551219 [SCORE] : 0.5696649074554443\n",
      "[425/1000]\n",
      "- [VAL] LOSS : 0.04075413569808006 [SCORE] : 1.0\n",
      "[426/1000]\n",
      "- [TRAIN] LOSS : 0.053099248185753824 [SCORE] : 0.5696649074554443\n",
      "[426/1000]\n",
      "- [VAL] LOSS : 0.040731701999902725 [SCORE] : 1.0\n",
      "[427/1000]\n",
      "- [TRAIN] LOSS : 0.05308935265056789 [SCORE] : 0.5696649074554443\n",
      "[427/1000]\n",
      "- [VAL] LOSS : 0.04070936515927315 [SCORE] : 1.0\n",
      "[428/1000]\n",
      "- [TRAIN] LOSS : 0.053079546770701806 [SCORE] : 0.5696649074554443\n",
      "[428/1000]\n",
      "- [VAL] LOSS : 0.04068724438548088 [SCORE] : 1.0\n",
      "[429/1000]\n",
      "- [TRAIN] LOSS : 0.05306978894708057 [SCORE] : 0.5696649074554443\n",
      "[429/1000]\n",
      "- [VAL] LOSS : 0.04066513106226921 [SCORE] : 1.0\n",
      "[430/1000]\n",
      "- [TRAIN] LOSS : 0.053060082951560616 [SCORE] : 0.5696649074554443\n",
      "[430/1000]\n",
      "- [VAL] LOSS : 0.04064308851957321 [SCORE] : 1.0\n",
      "[431/1000]\n",
      "- [TRAIN] LOSS : 0.053050435769061245 [SCORE] : 0.5696649074554443\n",
      "[431/1000]\n",
      "- [VAL] LOSS : 0.040621284395456314 [SCORE] : 1.0\n",
      "[432/1000]\n",
      "- [TRAIN] LOSS : 0.0530408988861988 [SCORE] : 0.5696649074554443\n",
      "[432/1000]\n",
      "- [VAL] LOSS : 0.04059971123933792 [SCORE] : 1.0\n",
      "[433/1000]\n",
      "- [TRAIN] LOSS : 0.05303131068746249 [SCORE] : 0.5696649074554443\n",
      "[433/1000]\n",
      "- [VAL] LOSS : 0.04057816043496132 [SCORE] : 1.0\n",
      "[434/1000]\n",
      "- [TRAIN] LOSS : 0.05302181276492775 [SCORE] : 0.5696649074554443\n",
      "[434/1000]\n",
      "- [VAL] LOSS : 0.04055662080645561 [SCORE] : 1.0\n",
      "[435/1000]\n",
      "- [TRAIN] LOSS : 0.05301237038026253 [SCORE] : 0.5696649074554443\n",
      "[435/1000]\n",
      "- [VAL] LOSS : 0.04053519293665886 [SCORE] : 1.0\n",
      "[436/1000]\n",
      "- [TRAIN] LOSS : 0.053003001399338244 [SCORE] : 0.5696649074554443\n",
      "[436/1000]\n",
      "- [VAL] LOSS : 0.04051395505666733 [SCORE] : 1.0\n",
      "[437/1000]\n",
      "- [TRAIN] LOSS : 0.052993906072030465 [SCORE] : 0.5696649074554443\n",
      "[437/1000]\n",
      "- [VAL] LOSS : 0.04049336165189743 [SCORE] : 1.0\n",
      "[438/1000]\n",
      "- [TRAIN] LOSS : 0.0529845398850739 [SCORE] : 0.5696649074554443\n",
      "[438/1000]\n",
      "- [VAL] LOSS : 0.04047280550003052 [SCORE] : 1.0\n",
      "[439/1000]\n",
      "- [TRAIN] LOSS : 0.052975239356358846 [SCORE] : 0.5696649074554443\n",
      "[439/1000]\n",
      "- [VAL] LOSS : 0.040452055633068085 [SCORE] : 1.0\n",
      "[440/1000]\n",
      "- [TRAIN] LOSS : 0.05296596875414252 [SCORE] : 0.5696649074554443\n",
      "[440/1000]\n",
      "- [VAL] LOSS : 0.040431149303913116 [SCORE] : 1.0\n",
      "[441/1000]\n",
      "- [TRAIN] LOSS : 0.052956863803168136 [SCORE] : 0.5696649074554443\n",
      "[441/1000]\n",
      "- [VAL] LOSS : 0.040410347282886505 [SCORE] : 1.0\n",
      "[442/1000]\n",
      "- [TRAIN] LOSS : 0.052947791572660205 [SCORE] : 0.5696649074554443\n",
      "[442/1000]\n",
      "- [VAL] LOSS : 0.0403897725045681 [SCORE] : 1.0\n",
      "[443/1000]\n",
      "- [TRAIN] LOSS : 0.052938793506473306 [SCORE] : 0.5696649074554443\n",
      "[443/1000]\n",
      "- [VAL] LOSS : 0.040369339287281036 [SCORE] : 1.0\n",
      "[444/1000]\n",
      "- [TRAIN] LOSS : 0.05292980984474222 [SCORE] : 0.5696649074554443\n",
      "[444/1000]\n",
      "- [VAL] LOSS : 0.04034896567463875 [SCORE] : 1.0\n",
      "[445/1000]\n",
      "- [TRAIN] LOSS : 0.05292085994345446 [SCORE] : 0.5696649074554443\n",
      "[445/1000]\n",
      "- [VAL] LOSS : 0.04032866284251213 [SCORE] : 1.0\n",
      "[446/1000]\n",
      "- [TRAIN] LOSS : 0.05291195142393311 [SCORE] : 0.5696649074554443\n",
      "[446/1000]\n",
      "- [VAL] LOSS : 0.04030846804380417 [SCORE] : 1.0\n",
      "[447/1000]\n",
      "- [TRAIN] LOSS : 0.052903099451214075 [SCORE] : 0.5696649074554443\n",
      "[447/1000]\n",
      "- [VAL] LOSS : 0.04028831049799919 [SCORE] : 1.0\n",
      "[448/1000]\n",
      "- [TRAIN] LOSS : 0.05289437551982701 [SCORE] : 0.5696649074554443\n",
      "[448/1000]\n",
      "- [VAL] LOSS : 0.04026851803064346 [SCORE] : 1.0\n",
      "[449/1000]\n",
      "- [TRAIN] LOSS : 0.05288559369121989 [SCORE] : 0.5696649074554443\n",
      "[449/1000]\n",
      "- [VAL] LOSS : 0.04024869576096535 [SCORE] : 1.0\n",
      "[450/1000]\n",
      "- [TRAIN] LOSS : 0.052876906003803015 [SCORE] : 0.5696649074554443\n",
      "[450/1000]\n",
      "- [VAL] LOSS : 0.04022892937064171 [SCORE] : 1.0\n",
      "[451/1000]\n",
      "- [TRAIN] LOSS : 0.05286823878996074 [SCORE] : 0.5696649074554443\n",
      "[451/1000]\n",
      "- [VAL] LOSS : 0.04020930081605911 [SCORE] : 1.0\n",
      "[452/1000]\n",
      "- [TRAIN] LOSS : 0.052859608611712856 [SCORE] : 0.5696649074554443\n",
      "[452/1000]\n",
      "- [VAL] LOSS : 0.040189702063798904 [SCORE] : 1.0\n",
      "[453/1000]\n",
      "- [TRAIN] LOSS : 0.05285103706022103 [SCORE] : 0.5696649074554443\n",
      "[453/1000]\n",
      "- [VAL] LOSS : 0.04017022252082825 [SCORE] : 1.0\n",
      "[454/1000]\n",
      "- [TRAIN] LOSS : 0.052842498663812874 [SCORE] : 0.5696649074554443\n",
      "[454/1000]\n",
      "- [VAL] LOSS : 0.04015081003308296 [SCORE] : 1.0\n",
      "[455/1000]\n",
      "- [TRAIN] LOSS : 0.05283401998070379 [SCORE] : 0.5696649074554443\n",
      "[455/1000]\n",
      "- [VAL] LOSS : 0.04013148695230484 [SCORE] : 1.0\n",
      "[456/1000]\n",
      "- [TRAIN] LOSS : 0.05282556709523002 [SCORE] : 0.5696649074554443\n",
      "[456/1000]\n",
      "- [VAL] LOSS : 0.04011229798197746 [SCORE] : 1.0\n",
      "[457/1000]\n",
      "- [TRAIN] LOSS : 0.052817183329413334 [SCORE] : 0.5696649074554443\n",
      "[457/1000]\n",
      "- [VAL] LOSS : 0.04009317606687546 [SCORE] : 1.0\n",
      "[458/1000]\n",
      "- [TRAIN] LOSS : 0.052808809994409484 [SCORE] : 0.5696649074554443\n",
      "[458/1000]\n",
      "- [VAL] LOSS : 0.040074169635772705 [SCORE] : 1.0\n",
      "[459/1000]\n",
      "- [TRAIN] LOSS : 0.05280048446729779 [SCORE] : 0.5696649074554443\n",
      "[459/1000]\n",
      "- [VAL] LOSS : 0.04005524516105652 [SCORE] : 1.0\n",
      "[460/1000]\n",
      "- [TRAIN] LOSS : 0.05279223776112 [SCORE] : 0.5696649074554443\n",
      "[460/1000]\n",
      "- [VAL] LOSS : 0.040036432445049286 [SCORE] : 1.0\n",
      "[461/1000]\n",
      "- [TRAIN] LOSS : 0.052783969510346654 [SCORE] : 0.5696649074554443\n",
      "[461/1000]\n",
      "- [VAL] LOSS : 0.040017712861299515 [SCORE] : 1.0\n",
      "[462/1000]\n",
      "- [TRAIN] LOSS : 0.05277578591679533 [SCORE] : 0.5696649074554443\n",
      "[462/1000]\n",
      "- [VAL] LOSS : 0.039999064058065414 [SCORE] : 1.0\n",
      "[463/1000]\n",
      "- [TRAIN] LOSS : 0.052767631023501356 [SCORE] : 0.5696649074554443\n",
      "[463/1000]\n",
      "- [VAL] LOSS : 0.03998049721121788 [SCORE] : 1.0\n",
      "[464/1000]\n",
      "- [TRAIN] LOSS : 0.052759490938236314 [SCORE] : 0.5696649074554443\n",
      "[464/1000]\n",
      "- [VAL] LOSS : 0.0399620495736599 [SCORE] : 1.0\n",
      "[465/1000]\n",
      "- [TRAIN] LOSS : 0.05275142197497189 [SCORE] : 0.5696649074554443\n",
      "[465/1000]\n",
      "- [VAL] LOSS : 0.03994368389248848 [SCORE] : 1.0\n",
      "[466/1000]\n",
      "- [TRAIN] LOSS : 0.05274340102138619 [SCORE] : 0.5696649074554443\n",
      "[466/1000]\n",
      "- [VAL] LOSS : 0.03992540389299393 [SCORE] : 1.0\n",
      "[467/1000]\n",
      "- [TRAIN] LOSS : 0.052735377879192434 [SCORE] : 0.5696649074554443\n",
      "[467/1000]\n",
      "- [VAL] LOSS : 0.03990719094872475 [SCORE] : 1.0\n",
      "[468/1000]\n",
      "- [TRAIN] LOSS : 0.05272743434955676 [SCORE] : 0.5696649074554443\n",
      "[468/1000]\n",
      "- [VAL] LOSS : 0.03988911584019661 [SCORE] : 1.0\n",
      "[469/1000]\n",
      "- [TRAIN] LOSS : 0.05271952049806714 [SCORE] : 0.5696649074554443\n",
      "[469/1000]\n",
      "- [VAL] LOSS : 0.03987110033631325 [SCORE] : 1.0\n",
      "[470/1000]\n",
      "- [TRAIN] LOSS : 0.052711576052630944 [SCORE] : 0.5696649074554443\n",
      "[470/1000]\n",
      "- [VAL] LOSS : 0.03985314443707466 [SCORE] : 1.0\n",
      "[471/1000]\n",
      "- [TRAIN] LOSS : 0.052703768791009985 [SCORE] : 0.5696649074554443\n",
      "[471/1000]\n",
      "- [VAL] LOSS : 0.039835333824157715 [SCORE] : 1.0\n",
      "[472/1000]\n",
      "- [TRAIN] LOSS : 0.05269592758268118 [SCORE] : 0.5696649074554443\n",
      "[472/1000]\n",
      "- [VAL] LOSS : 0.03981751948595047 [SCORE] : 1.0\n",
      "[473/1000]\n",
      "- [TRAIN] LOSS : 0.052688158210366966 [SCORE] : 0.5696649074554443\n",
      "[473/1000]\n",
      "- [VAL] LOSS : 0.03979984670877457 [SCORE] : 1.0\n",
      "[474/1000]\n",
      "- [TRAIN] LOSS : 0.05268041575327516 [SCORE] : 0.5696649074554443\n",
      "[474/1000]\n",
      "- [VAL] LOSS : 0.03978228196501732 [SCORE] : 1.0\n",
      "[475/1000]\n",
      "- [TRAIN] LOSS : 0.05267274888853232 [SCORE] : 0.5696649074554443\n",
      "[475/1000]\n",
      "- [VAL] LOSS : 0.039764754474163055 [SCORE] : 1.0\n",
      "[476/1000]\n",
      "- [TRAIN] LOSS : 0.052665074650819106 [SCORE] : 0.5696649074554443\n",
      "[476/1000]\n",
      "- [VAL] LOSS : 0.03974734991788864 [SCORE] : 1.0\n",
      "[477/1000]\n",
      "- [TRAIN] LOSS : 0.05265741841867566 [SCORE] : 0.5696649074554443\n",
      "[477/1000]\n",
      "- [VAL] LOSS : 0.03973003104329109 [SCORE] : 1.0\n",
      "[478/1000]\n",
      "- [TRAIN] LOSS : 0.05264982885370652 [SCORE] : 0.5696649074554443\n",
      "[478/1000]\n",
      "- [VAL] LOSS : 0.03971269354224205 [SCORE] : 1.0\n",
      "[479/1000]\n",
      "- [TRAIN] LOSS : 0.052642321307212116 [SCORE] : 0.5696649074554443\n",
      "[479/1000]\n",
      "- [VAL] LOSS : 0.03969556465744972 [SCORE] : 1.0\n",
      "[480/1000]\n",
      "- [TRAIN] LOSS : 0.0526347475592047 [SCORE] : 0.5696649074554443\n",
      "[480/1000]\n",
      "- [VAL] LOSS : 0.03967844694852829 [SCORE] : 1.0\n",
      "[481/1000]\n",
      "- [TRAIN] LOSS : 0.05262725815797845 [SCORE] : 0.5696649074554443\n",
      "[481/1000]\n",
      "- [VAL] LOSS : 0.039661429822444916 [SCORE] : 1.0\n",
      "[482/1000]\n",
      "- [TRAIN] LOSS : 0.05261982039858897 [SCORE] : 0.5696649074554443\n",
      "[482/1000]\n",
      "- [VAL] LOSS : 0.03964445739984512 [SCORE] : 1.0\n",
      "[483/1000]\n",
      "- [TRAIN] LOSS : 0.05261239157989621 [SCORE] : 0.5696649074554443\n",
      "[483/1000]\n",
      "- [VAL] LOSS : 0.039627570658922195 [SCORE] : 1.0\n",
      "[484/1000]\n",
      "- [TRAIN] LOSS : 0.052605011096845074 [SCORE] : 0.5696649074554443\n",
      "[484/1000]\n",
      "- [VAL] LOSS : 0.03961080312728882 [SCORE] : 1.0\n",
      "[485/1000]\n",
      "- [TRAIN] LOSS : 0.05259766619031628 [SCORE] : 0.5696649074554443\n",
      "[485/1000]\n",
      "- [VAL] LOSS : 0.03959416225552559 [SCORE] : 1.0\n",
      "[486/1000]\n",
      "- [TRAIN] LOSS : 0.05259031009239455 [SCORE] : 0.5696649074554443\n",
      "[486/1000]\n",
      "- [VAL] LOSS : 0.039577510207891464 [SCORE] : 1.0\n",
      "[487/1000]\n",
      "- [TRAIN] LOSS : 0.05258304417754213 [SCORE] : 0.5696649074554443\n",
      "[487/1000]\n",
      "- [VAL] LOSS : 0.039560914039611816 [SCORE] : 1.0\n",
      "[488/1000]\n",
      "- [TRAIN] LOSS : 0.052575750602409245 [SCORE] : 0.5696649074554443\n",
      "[488/1000]\n",
      "- [VAL] LOSS : 0.03954443335533142 [SCORE] : 1.0\n",
      "[489/1000]\n",
      "- [TRAIN] LOSS : 0.05256855088906984 [SCORE] : 0.5696649074554443\n",
      "[489/1000]\n",
      "- [VAL] LOSS : 0.03952804580330849 [SCORE] : 1.0\n",
      "[490/1000]\n",
      "- [TRAIN] LOSS : 0.052561391269167264 [SCORE] : 0.5696649074554443\n",
      "[490/1000]\n",
      "- [VAL] LOSS : 0.03951171785593033 [SCORE] : 1.0\n",
      "[491/1000]\n",
      "- [TRAIN] LOSS : 0.05255419658496976 [SCORE] : 0.5696649074554443\n",
      "[491/1000]\n",
      "- [VAL] LOSS : 0.03949545696377754 [SCORE] : 1.0\n",
      "[492/1000]\n",
      "- [TRAIN] LOSS : 0.05254708121841153 [SCORE] : 0.5696649074554443\n",
      "[492/1000]\n",
      "- [VAL] LOSS : 0.03947927802801132 [SCORE] : 1.0\n",
      "[493/1000]\n",
      "- [TRAIN] LOSS : 0.052539974171668294 [SCORE] : 0.5696649074554443\n",
      "[493/1000]\n",
      "- [VAL] LOSS : 0.03946316987276077 [SCORE] : 1.0\n",
      "[494/1000]\n",
      "- [TRAIN] LOSS : 0.052532910276204346 [SCORE] : 0.5696649074554443\n",
      "[494/1000]\n",
      "- [VAL] LOSS : 0.03944713994860649 [SCORE] : 1.0\n",
      "[495/1000]\n",
      "- [TRAIN] LOSS : 0.05252585134779413 [SCORE] : 0.5696649074554443\n",
      "[495/1000]\n",
      "- [VAL] LOSS : 0.039431165903806686 [SCORE] : 1.0\n",
      "[496/1000]\n",
      "- [TRAIN] LOSS : 0.05251884455792606 [SCORE] : 0.5696649074554443\n",
      "[496/1000]\n",
      "- [VAL] LOSS : 0.03941529989242554 [SCORE] : 1.0\n",
      "[497/1000]\n",
      "- [TRAIN] LOSS : 0.05251192341869076 [SCORE] : 0.5696649074554443\n",
      "[497/1000]\n",
      "- [VAL] LOSS : 0.039399515837430954 [SCORE] : 1.0\n",
      "[498/1000]\n",
      "- [TRAIN] LOSS : 0.05250497739762068 [SCORE] : 0.5696649074554443\n",
      "[498/1000]\n",
      "- [VAL] LOSS : 0.03938378766179085 [SCORE] : 1.0\n",
      "[499/1000]\n",
      "- [TRAIN] LOSS : 0.05249804969256123 [SCORE] : 0.5696649074554443\n",
      "[499/1000]\n",
      "- [VAL] LOSS : 0.03936808928847313 [SCORE] : 1.0\n",
      "[500/1000]\n",
      "- [TRAIN] LOSS : 0.05249128937721252 [SCORE] : 0.5696649074554443\n",
      "[500/1000]\n",
      "- [VAL] LOSS : 0.03935294970870018 [SCORE] : 1.0\n",
      "[501/1000]\n",
      "- [TRAIN] LOSS : 0.052484402727956576 [SCORE] : 0.5696649074554443\n",
      "[501/1000]\n",
      "- [VAL] LOSS : 0.039337776601314545 [SCORE] : 1.0\n",
      "[502/1000]\n",
      "- [TRAIN] LOSS : 0.05247744141767422 [SCORE] : 0.5696649074554443\n",
      "[502/1000]\n",
      "- [VAL] LOSS : 0.03932235762476921 [SCORE] : 1.0\n",
      "[503/1000]\n",
      "- [TRAIN] LOSS : 0.05247064703144133 [SCORE] : 0.5696649074554443\n",
      "[503/1000]\n",
      "- [VAL] LOSS : 0.03930690512061119 [SCORE] : 1.0\n",
      "[504/1000]\n",
      "- [TRAIN] LOSS : 0.0524639259558171 [SCORE] : 0.5696649074554443\n",
      "[504/1000]\n",
      "- [VAL] LOSS : 0.03929156810045242 [SCORE] : 1.0\n",
      "[505/1000]\n",
      "- [TRAIN] LOSS : 0.052457208093255756 [SCORE] : 0.5696649074554443\n",
      "[505/1000]\n",
      "- [VAL] LOSS : 0.039276331663131714 [SCORE] : 1.0\n",
      "[506/1000]\n",
      "- [TRAIN] LOSS : 0.05245053738666077 [SCORE] : 0.5696649074554443\n",
      "[506/1000]\n",
      "- [VAL] LOSS : 0.039261240512132645 [SCORE] : 1.0\n",
      "[507/1000]\n",
      "- [TRAIN] LOSS : 0.05244385531793038 [SCORE] : 0.5696649074554443\n",
      "[507/1000]\n",
      "- [VAL] LOSS : 0.039246223866939545 [SCORE] : 1.0\n",
      "[508/1000]\n",
      "- [TRAIN] LOSS : 0.052437232341617346 [SCORE] : 0.5696649074554443\n",
      "[508/1000]\n",
      "- [VAL] LOSS : 0.03923116251826286 [SCORE] : 1.0\n",
      "[509/1000]\n",
      "- [TRAIN] LOSS : 0.052430616691708565 [SCORE] : 0.5696649074554443\n",
      "[509/1000]\n",
      "- [VAL] LOSS : 0.03921619802713394 [SCORE] : 1.0\n",
      "[510/1000]\n",
      "- [TRAIN] LOSS : 0.05242401488746206 [SCORE] : 0.5696649074554443\n",
      "[510/1000]\n",
      "- [VAL] LOSS : 0.0392012856900692 [SCORE] : 1.0\n",
      "[511/1000]\n",
      "- [TRAIN] LOSS : 0.05241745701059699 [SCORE] : 0.5696649074554443\n",
      "[511/1000]\n",
      "- [VAL] LOSS : 0.039186470210552216 [SCORE] : 1.0\n",
      "[512/1000]\n",
      "- [TRAIN] LOSS : 0.052410928253084424 [SCORE] : 0.5696649074554443\n",
      "[512/1000]\n",
      "- [VAL] LOSS : 0.039171718060970306 [SCORE] : 1.0\n",
      "[513/1000]\n",
      "- [TRAIN] LOSS : 0.05240444612378876 [SCORE] : 0.5696649074554443\n",
      "[513/1000]\n",
      "- [VAL] LOSS : 0.039157092571258545 [SCORE] : 1.0\n",
      "[514/1000]\n",
      "- [TRAIN] LOSS : 0.052397978274772564 [SCORE] : 0.5696649074554443\n",
      "[514/1000]\n",
      "- [VAL] LOSS : 0.03914247080683708 [SCORE] : 1.0\n",
      "[515/1000]\n",
      "- [TRAIN] LOSS : 0.05239151427522302 [SCORE] : 0.5696649074554443\n",
      "[515/1000]\n",
      "- [VAL] LOSS : 0.0391278900206089 [SCORE] : 1.0\n",
      "[516/1000]\n",
      "- [TRAIN] LOSS : 0.052385068591684104 [SCORE] : 0.5696649074554443\n",
      "[516/1000]\n",
      "- [VAL] LOSS : 0.0391133688390255 [SCORE] : 1.0\n",
      "[517/1000]\n",
      "- [TRAIN] LOSS : 0.05237868937353293 [SCORE] : 0.5696649074554443\n",
      "[517/1000]\n",
      "- [VAL] LOSS : 0.039098918437957764 [SCORE] : 1.0\n",
      "[518/1000]\n",
      "- [TRAIN] LOSS : 0.05237231928234299 [SCORE] : 0.5607760190963745\n",
      "[518/1000]\n",
      "- [VAL] LOSS : 0.039084553718566895 [SCORE] : 1.0\n",
      "[519/1000]\n",
      "- [TRAIN] LOSS : 0.05236597166707118 [SCORE] : 0.5607760190963745\n",
      "[519/1000]\n",
      "- [VAL] LOSS : 0.0390702486038208 [SCORE] : 1.0\n",
      "[520/1000]\n",
      "- [TRAIN] LOSS : 0.052359682988996306 [SCORE] : 0.5607760190963745\n",
      "[520/1000]\n",
      "- [VAL] LOSS : 0.03905601054430008 [SCORE] : 1.0\n",
      "[521/1000]\n",
      "- [TRAIN] LOSS : 0.0523533757776022 [SCORE] : 0.5607760190963745\n",
      "[521/1000]\n",
      "- [VAL] LOSS : 0.03904180973768234 [SCORE] : 1.0\n",
      "[522/1000]\n",
      "- [TRAIN] LOSS : 0.05234712570284804 [SCORE] : 0.5607760190963745\n",
      "[522/1000]\n",
      "- [VAL] LOSS : 0.039027754217386246 [SCORE] : 1.0\n",
      "[523/1000]\n",
      "- [TRAIN] LOSS : 0.05234086316389342 [SCORE] : 0.5607760190963745\n",
      "[523/1000]\n",
      "- [VAL] LOSS : 0.03901362791657448 [SCORE] : 1.0\n",
      "[524/1000]\n",
      "- [TRAIN] LOSS : 0.05233467747457325 [SCORE] : 0.5607760190963745\n",
      "[524/1000]\n",
      "- [VAL] LOSS : 0.03899967297911644 [SCORE] : 1.0\n",
      "[525/1000]\n",
      "- [TRAIN] LOSS : 0.0523284549669673 [SCORE] : 0.5607760190963745\n",
      "[525/1000]\n",
      "- [VAL] LOSS : 0.03898567706346512 [SCORE] : 1.0\n",
      "[526/1000]\n",
      "- [TRAIN] LOSS : 0.052322310566281276 [SCORE] : 0.5607760190963745\n",
      "[526/1000]\n",
      "- [VAL] LOSS : 0.03897181898355484 [SCORE] : 1.0\n",
      "[527/1000]\n",
      "- [TRAIN] LOSS : 0.0523161802906543 [SCORE] : 0.5607760190963745\n",
      "[527/1000]\n",
      "- [VAL] LOSS : 0.03895802050828934 [SCORE] : 1.0\n",
      "[528/1000]\n",
      "- [TRAIN] LOSS : 0.05231003863736987 [SCORE] : 0.5607760190963745\n",
      "[528/1000]\n",
      "- [VAL] LOSS : 0.03894424065947533 [SCORE] : 1.0\n",
      "[529/1000]\n",
      "- [TRAIN] LOSS : 0.05230395101631681 [SCORE] : 0.5607760190963745\n",
      "[529/1000]\n",
      "- [VAL] LOSS : 0.03893054649233818 [SCORE] : 1.0\n",
      "[530/1000]\n",
      "- [TRAIN] LOSS : 0.052297880345334606 [SCORE] : 0.5607760190963745\n",
      "[530/1000]\n",
      "- [VAL] LOSS : 0.038916848599910736 [SCORE] : 1.0\n",
      "[531/1000]\n",
      "- [TRAIN] LOSS : 0.05229186077291767 [SCORE] : 0.5607760190963745\n",
      "[531/1000]\n",
      "- [VAL] LOSS : 0.03890330344438553 [SCORE] : 1.0\n",
      "[532/1000]\n",
      "- [TRAIN] LOSS : 0.05228582598889867 [SCORE] : 0.5607760190963745\n",
      "[532/1000]\n",
      "- [VAL] LOSS : 0.03888977691531181 [SCORE] : 1.0\n",
      "[533/1000]\n",
      "- [TRAIN] LOSS : 0.05227982580351333 [SCORE] : 0.5607760190963745\n",
      "[533/1000]\n",
      "- [VAL] LOSS : 0.038876306265592575 [SCORE] : 1.0\n",
      "[534/1000]\n",
      "- [TRAIN] LOSS : 0.052273861862098175 [SCORE] : 0.5607760190963745\n",
      "[534/1000]\n",
      "- [VAL] LOSS : 0.038862891495227814 [SCORE] : 1.0\n",
      "[535/1000]\n",
      "- [TRAIN] LOSS : 0.05226793612043063 [SCORE] : 0.5607760190963745\n",
      "[535/1000]\n",
      "- [VAL] LOSS : 0.03884952887892723 [SCORE] : 1.0\n",
      "[536/1000]\n",
      "- [TRAIN] LOSS : 0.052261967413748306 [SCORE] : 0.5607760190963745\n",
      "[536/1000]\n",
      "- [VAL] LOSS : 0.038836218416690826 [SCORE] : 1.0\n",
      "[537/1000]\n",
      "- [TRAIN] LOSS : 0.05225606681779027 [SCORE] : 0.5607760190963745\n",
      "[537/1000]\n",
      "- [VAL] LOSS : 0.03882293775677681 [SCORE] : 1.0\n",
      "[538/1000]\n",
      "- [TRAIN] LOSS : 0.052250198228284715 [SCORE] : 0.5607760190963745\n",
      "[538/1000]\n",
      "- [VAL] LOSS : 0.038809727877378464 [SCORE] : 1.0\n",
      "[539/1000]\n",
      "- [TRAIN] LOSS : 0.05224435053144892 [SCORE] : 0.5607760190963745\n",
      "[539/1000]\n",
      "- [VAL] LOSS : 0.03879665583372116 [SCORE] : 1.0\n",
      "[540/1000]\n",
      "- [TRAIN] LOSS : 0.05223850896582007 [SCORE] : 0.5607760190963745\n",
      "[540/1000]\n",
      "- [VAL] LOSS : 0.03878355026245117 [SCORE] : 1.0\n",
      "[541/1000]\n",
      "- [TRAIN] LOSS : 0.052232680997500815 [SCORE] : 0.5607760190963745\n",
      "[541/1000]\n",
      "- [VAL] LOSS : 0.038770537823438644 [SCORE] : 1.0\n",
      "[542/1000]\n",
      "- [TRAIN] LOSS : 0.05222691431020697 [SCORE] : 0.5607760190963745\n",
      "[542/1000]\n",
      "- [VAL] LOSS : 0.03875754028558731 [SCORE] : 1.0\n",
      "[543/1000]\n",
      "- [TRAIN] LOSS : 0.052221141972889504 [SCORE] : 0.5607760190963745\n",
      "[543/1000]\n",
      "- [VAL] LOSS : 0.038744647055864334 [SCORE] : 1.0\n",
      "[544/1000]\n",
      "- [TRAIN] LOSS : 0.052215375223507485 [SCORE] : 0.5607760190963745\n",
      "[544/1000]\n",
      "- [VAL] LOSS : 0.03873179480433464 [SCORE] : 1.0\n",
      "[545/1000]\n",
      "- [TRAIN] LOSS : 0.05220964546315372 [SCORE] : 0.5607760190963745\n",
      "[545/1000]\n",
      "- [VAL] LOSS : 0.03871893137693405 [SCORE] : 1.0\n",
      "[546/1000]\n",
      "- [TRAIN] LOSS : 0.05220392563690742 [SCORE] : 0.5607760190963745\n",
      "[546/1000]\n",
      "- [VAL] LOSS : 0.038706205785274506 [SCORE] : 1.0\n",
      "[547/1000]\n",
      "- [TRAIN] LOSS : 0.052198275551199914 [SCORE] : 0.5607760190963745\n",
      "[547/1000]\n",
      "- [VAL] LOSS : 0.03869350627064705 [SCORE] : 1.0\n",
      "[548/1000]\n",
      "- [TRAIN] LOSS : 0.052192616866280635 [SCORE] : 0.5607760190963745\n",
      "[548/1000]\n",
      "- [VAL] LOSS : 0.038680821657180786 [SCORE] : 1.0\n",
      "[549/1000]\n",
      "- [TRAIN] LOSS : 0.0521869820697854 [SCORE] : 0.5607760190963745\n",
      "[549/1000]\n",
      "- [VAL] LOSS : 0.03866828233003616 [SCORE] : 1.0\n",
      "[550/1000]\n",
      "- [TRAIN] LOSS : 0.052181346838672954 [SCORE] : 0.5607760190963745\n",
      "[550/1000]\n",
      "- [VAL] LOSS : 0.03865566477179527 [SCORE] : 1.0\n",
      "[551/1000]\n",
      "- [TRAIN] LOSS : 0.05217574828614791 [SCORE] : 0.5607760190963745\n",
      "[551/1000]\n",
      "- [VAL] LOSS : 0.03864315152168274 [SCORE] : 1.0\n",
      "[552/1000]\n",
      "- [TRAIN] LOSS : 0.05217017927207053 [SCORE] : 0.5607760190963745\n",
      "[552/1000]\n",
      "- [VAL] LOSS : 0.03863074257969856 [SCORE] : 1.0\n",
      "[553/1000]\n",
      "- [TRAIN] LOSS : 0.05216462531437476 [SCORE] : 0.5607760190963745\n",
      "[553/1000]\n",
      "- [VAL] LOSS : 0.03861836716532707 [SCORE] : 1.0\n",
      "[554/1000]\n",
      "- [TRAIN] LOSS : 0.05215910865614812 [SCORE] : 0.5607760190963745\n",
      "[554/1000]\n",
      "- [VAL] LOSS : 0.03860601410269737 [SCORE] : 1.0\n",
      "[555/1000]\n",
      "- [TRAIN] LOSS : 0.052153594450404246 [SCORE] : 0.5607760190963745\n",
      "[555/1000]\n",
      "- [VAL] LOSS : 0.03859373554587364 [SCORE] : 1.0\n",
      "[556/1000]\n",
      "- [TRAIN] LOSS : 0.052148102891320984 [SCORE] : 0.5607760190963745\n",
      "[556/1000]\n",
      "- [VAL] LOSS : 0.038581483066082 [SCORE] : 1.0\n",
      "[557/1000]\n",
      "- [TRAIN] LOSS : 0.05214262016428014 [SCORE] : 0.5607760190963745\n",
      "[557/1000]\n",
      "- [VAL] LOSS : 0.038569267839193344 [SCORE] : 1.0\n",
      "[558/1000]\n",
      "- [TRAIN] LOSS : 0.05213718563318252 [SCORE] : 0.5607760190963745\n",
      "[558/1000]\n",
      "- [VAL] LOSS : 0.038557108491659164 [SCORE] : 1.0\n",
      "[559/1000]\n",
      "- [TRAIN] LOSS : 0.05213172910735011 [SCORE] : 0.5607760190963745\n",
      "[559/1000]\n",
      "- [VAL] LOSS : 0.03854503110051155 [SCORE] : 1.0\n",
      "[560/1000]\n",
      "- [TRAIN] LOSS : 0.05212633047873775 [SCORE] : 0.5607760190963745\n",
      "[560/1000]\n",
      "- [VAL] LOSS : 0.038533005863428116 [SCORE] : 1.0\n",
      "[561/1000]\n",
      "- [TRAIN] LOSS : 0.052120954093212886 [SCORE] : 0.5607760190963745\n",
      "[561/1000]\n",
      "- [VAL] LOSS : 0.03852101415395737 [SCORE] : 1.0\n",
      "[562/1000]\n",
      "- [TRAIN] LOSS : 0.052115539399286114 [SCORE] : 0.5607760190963745\n",
      "[562/1000]\n",
      "- [VAL] LOSS : 0.03850902244448662 [SCORE] : 1.0\n",
      "[563/1000]\n",
      "- [TRAIN] LOSS : 0.052110219436387224 [SCORE] : 0.5607760190963745\n",
      "[563/1000]\n",
      "- [VAL] LOSS : 0.03849717229604721 [SCORE] : 1.0\n",
      "[564/1000]\n",
      "- [TRAIN] LOSS : 0.05210487915513416 [SCORE] : 0.5607760190963745\n",
      "[564/1000]\n",
      "- [VAL] LOSS : 0.03848529979586601 [SCORE] : 1.0\n",
      "[565/1000]\n",
      "- [TRAIN] LOSS : 0.05209956654968361 [SCORE] : 0.5607760190963745\n",
      "[565/1000]\n",
      "- [VAL] LOSS : 0.03847349062561989 [SCORE] : 1.0\n",
      "[566/1000]\n",
      "- [TRAIN] LOSS : 0.05209424570202827 [SCORE] : 0.5607760190963745\n",
      "[566/1000]\n",
      "- [VAL] LOSS : 0.03846174478530884 [SCORE] : 1.0\n",
      "[567/1000]\n",
      "- [TRAIN] LOSS : 0.05208897736544411 [SCORE] : 0.5607760190963745\n",
      "[567/1000]\n",
      "- [VAL] LOSS : 0.038450051099061966 [SCORE] : 1.0\n",
      "[568/1000]\n",
      "- [TRAIN] LOSS : 0.052083710689718524 [SCORE] : 0.5607760190963745\n",
      "[568/1000]\n",
      "- [VAL] LOSS : 0.0384383425116539 [SCORE] : 1.0\n",
      "[569/1000]\n",
      "- [TRAIN] LOSS : 0.05207849106130501 [SCORE] : 0.5607760190963745\n",
      "[569/1000]\n",
      "- [VAL] LOSS : 0.03842676058411598 [SCORE] : 1.0\n",
      "[570/1000]\n",
      "- [TRAIN] LOSS : 0.05207323411790033 [SCORE] : 0.5607760190963745\n",
      "[570/1000]\n",
      "- [VAL] LOSS : 0.03841517120599747 [SCORE] : 1.0\n",
      "[571/1000]\n",
      "- [TRAIN] LOSS : 0.052068020775914194 [SCORE] : 0.5607760190963745\n",
      "[571/1000]\n",
      "- [VAL] LOSS : 0.03840365633368492 [SCORE] : 1.0\n",
      "[572/1000]\n",
      "- [TRAIN] LOSS : 0.05206289387618502 [SCORE] : 0.5607760190963745\n",
      "[572/1000]\n",
      "- [VAL] LOSS : 0.03839215636253357 [SCORE] : 1.0\n",
      "[573/1000]\n",
      "- [TRAIN] LOSS : 0.05205772224192818 [SCORE] : 0.5607760190963745\n",
      "[573/1000]\n",
      "- [VAL] LOSS : 0.03838076442480087 [SCORE] : 1.0\n",
      "[574/1000]\n",
      "- [TRAIN] LOSS : 0.052052568861593804 [SCORE] : 0.5607760190963745\n",
      "[574/1000]\n",
      "- [VAL] LOSS : 0.03836943954229355 [SCORE] : 1.0\n",
      "[575/1000]\n",
      "- [TRAIN] LOSS : 0.05204741198879977 [SCORE] : 0.5607760190963745\n",
      "[575/1000]\n",
      "- [VAL] LOSS : 0.03835807368159294 [SCORE] : 1.0\n",
      "[576/1000]\n",
      "- [TRAIN] LOSS : 0.052042310948794086 [SCORE] : 0.5607760190963745\n",
      "[576/1000]\n",
      "- [VAL] LOSS : 0.038346778601408005 [SCORE] : 1.0\n",
      "[577/1000]\n",
      "- [TRAIN] LOSS : 0.052037212438881396 [SCORE] : 0.5607760190963745\n",
      "[577/1000]\n",
      "- [VAL] LOSS : 0.03833555057644844 [SCORE] : 1.0\n",
      "[578/1000]\n",
      "- [TRAIN] LOSS : 0.05203213711890082 [SCORE] : 0.5607760190963745\n",
      "[578/1000]\n",
      "- [VAL] LOSS : 0.03832435607910156 [SCORE] : 1.0\n",
      "[579/1000]\n",
      "- [TRAIN] LOSS : 0.05202709708052377 [SCORE] : 0.5607760190963745\n",
      "[579/1000]\n",
      "- [VAL] LOSS : 0.03831316903233528 [SCORE] : 1.0\n",
      "[580/1000]\n",
      "- [TRAIN] LOSS : 0.05202203574590385 [SCORE] : 0.5607760190963745\n",
      "[580/1000]\n",
      "- [VAL] LOSS : 0.03830205649137497 [SCORE] : 1.0\n",
      "[581/1000]\n",
      "- [TRAIN] LOSS : 0.052017024531960485 [SCORE] : 0.5607760190963745\n",
      "[581/1000]\n",
      "- [VAL] LOSS : 0.03829104080796242 [SCORE] : 1.0\n",
      "[582/1000]\n",
      "- [TRAIN] LOSS : 0.05201201398546497 [SCORE] : 0.5607760190963745\n",
      "[582/1000]\n",
      "- [VAL] LOSS : 0.03827996924519539 [SCORE] : 1.0\n",
      "[583/1000]\n",
      "- [TRAIN] LOSS : 0.05200701612047851 [SCORE] : 0.5607760190963745\n",
      "[583/1000]\n",
      "- [VAL] LOSS : 0.038268961012363434 [SCORE] : 1.0\n",
      "[584/1000]\n",
      "- [TRAIN] LOSS : 0.05200206491475304 [SCORE] : 0.5607760190963745\n",
      "[584/1000]\n",
      "- [VAL] LOSS : 0.03825805336236954 [SCORE] : 1.0\n",
      "[585/1000]\n",
      "- [TRAIN] LOSS : 0.05199709283187985 [SCORE] : 0.5607760190963745\n",
      "[585/1000]\n",
      "- [VAL] LOSS : 0.038247138261795044 [SCORE] : 1.0\n",
      "[586/1000]\n",
      "- [TRAIN] LOSS : 0.05199215908845266 [SCORE] : 0.5607760190963745\n",
      "[586/1000]\n",
      "- [VAL] LOSS : 0.03823627158999443 [SCORE] : 1.0\n",
      "[587/1000]\n",
      "- [TRAIN] LOSS : 0.05198722310985128 [SCORE] : 0.5607760190963745\n",
      "[587/1000]\n",
      "- [VAL] LOSS : 0.038225505501031876 [SCORE] : 1.0\n",
      "[588/1000]\n",
      "- [TRAIN] LOSS : 0.051982359138006966 [SCORE] : 0.5607760190963745\n",
      "[588/1000]\n",
      "- [VAL] LOSS : 0.03821474313735962 [SCORE] : 1.0\n",
      "[589/1000]\n",
      "- [TRAIN] LOSS : 0.051977424106250204 [SCORE] : 0.5607760190963745\n",
      "[589/1000]\n",
      "- [VAL] LOSS : 0.03820403292775154 [SCORE] : 1.0\n",
      "[590/1000]\n",
      "- [TRAIN] LOSS : 0.05197256651396553 [SCORE] : 0.5607760190963745\n",
      "[590/1000]\n",
      "- [VAL] LOSS : 0.038193341344594955 [SCORE] : 1.0\n",
      "[591/1000]\n",
      "- [TRAIN] LOSS : 0.051967705398177105 [SCORE] : 0.5607760190963745\n",
      "[591/1000]\n",
      "- [VAL] LOSS : 0.03818265348672867 [SCORE] : 1.0\n",
      "[592/1000]\n",
      "- [TRAIN] LOSS : 0.05196286896243692 [SCORE] : 0.5607760190963745\n",
      "[592/1000]\n",
      "- [VAL] LOSS : 0.038172073662281036 [SCORE] : 1.0\n",
      "[593/1000]\n",
      "- [TRAIN] LOSS : 0.05195804272467892 [SCORE] : 0.5607760190963745\n",
      "[593/1000]\n",
      "- [VAL] LOSS : 0.03816153481602669 [SCORE] : 1.0\n",
      "[594/1000]\n",
      "- [TRAIN] LOSS : 0.051953277581681806 [SCORE] : 0.5607760190963745\n",
      "[594/1000]\n",
      "- [VAL] LOSS : 0.038151033222675323 [SCORE] : 1.0\n",
      "[595/1000]\n",
      "- [TRAIN] LOSS : 0.05194848026148975 [SCORE] : 0.5607760190963745\n",
      "[595/1000]\n",
      "- [VAL] LOSS : 0.03814053535461426 [SCORE] : 1.0\n",
      "[596/1000]\n",
      "- [TRAIN] LOSS : 0.05194370606914163 [SCORE] : 0.5607760190963745\n",
      "[596/1000]\n",
      "- [VAL] LOSS : 0.038130056113004684 [SCORE] : 1.0\n",
      "[597/1000]\n",
      "- [TRAIN] LOSS : 0.05193892940878868 [SCORE] : 0.5607760190963745\n",
      "[597/1000]\n",
      "- [VAL] LOSS : 0.03811965137720108 [SCORE] : 1.0\n",
      "[598/1000]\n",
      "- [TRAIN] LOSS : 0.05193419108788173 [SCORE] : 0.5607760190963745\n",
      "[598/1000]\n",
      "- [VAL] LOSS : 0.03810933977365494 [SCORE] : 1.0\n",
      "[599/1000]\n",
      "- [TRAIN] LOSS : 0.05192947074150046 [SCORE] : 0.5607760190963745\n",
      "[599/1000]\n",
      "- [VAL] LOSS : 0.0380990207195282 [SCORE] : 1.0\n",
      "[600/1000]\n",
      "- [TRAIN] LOSS : 0.05192474336363375 [SCORE] : 0.5607760190963745\n",
      "[600/1000]\n",
      "- [VAL] LOSS : 0.03808873891830444 [SCORE] : 1.0\n",
      "[601/1000]\n",
      "- [TRAIN] LOSS : 0.05192005992867053 [SCORE] : 0.5607760190963745\n",
      "[601/1000]\n",
      "- [VAL] LOSS : 0.03807850927114487 [SCORE] : 1.0\n",
      "[602/1000]\n",
      "- [TRAIN] LOSS : 0.05191539741742114 [SCORE] : 0.5607760190963745\n",
      "[602/1000]\n",
      "- [VAL] LOSS : 0.03806832805275917 [SCORE] : 1.0\n",
      "[603/1000]\n",
      "- [TRAIN] LOSS : 0.051910694657514495 [SCORE] : 0.5607760190963745\n",
      "[603/1000]\n",
      "- [VAL] LOSS : 0.03805811330676079 [SCORE] : 1.0\n",
      "[604/1000]\n",
      "- [TRAIN] LOSS : 0.05190606188649933 [SCORE] : 0.5607760190963745\n",
      "[604/1000]\n",
      "- [VAL] LOSS : 0.038047995418310165 [SCORE] : 1.0\n",
      "[605/1000]\n",
      "- [TRAIN] LOSS : 0.05190142832385997 [SCORE] : 0.5607760190963745\n",
      "[605/1000]\n",
      "- [VAL] LOSS : 0.03803792968392372 [SCORE] : 1.0\n",
      "[606/1000]\n",
      "- [TRAIN] LOSS : 0.05189681723713875 [SCORE] : 0.5607760190963745\n",
      "[606/1000]\n",
      "- [VAL] LOSS : 0.03802788630127907 [SCORE] : 1.0\n",
      "[607/1000]\n",
      "- [TRAIN] LOSS : 0.0518922069730858 [SCORE] : 0.5607760190963745\n",
      "[607/1000]\n",
      "- [VAL] LOSS : 0.03801790997385979 [SCORE] : 1.0\n",
      "[608/1000]\n",
      "- [TRAIN] LOSS : 0.05188760097759466 [SCORE] : 0.5607760190963745\n",
      "[608/1000]\n",
      "- [VAL] LOSS : 0.03800797462463379 [SCORE] : 1.0\n",
      "[609/1000]\n",
      "- [TRAIN] LOSS : 0.051883033274983364 [SCORE] : 0.5607760190963745\n",
      "[609/1000]\n",
      "- [VAL] LOSS : 0.0379980243742466 [SCORE] : 1.0\n",
      "[610/1000]\n",
      "- [TRAIN] LOSS : 0.05187849473829071 [SCORE] : 0.5607760190963745\n",
      "[610/1000]\n",
      "- [VAL] LOSS : 0.03798813000321388 [SCORE] : 1.0\n",
      "[611/1000]\n",
      "- [TRAIN] LOSS : 0.051873926911503075 [SCORE] : 0.5607760190963745\n",
      "[611/1000]\n",
      "- [VAL] LOSS : 0.037978287786245346 [SCORE] : 1.0\n",
      "[612/1000]\n",
      "- [TRAIN] LOSS : 0.051869436322400965 [SCORE] : 0.5607760190963745\n",
      "[612/1000]\n",
      "- [VAL] LOSS : 0.03796845301985741 [SCORE] : 1.0\n",
      "[613/1000]\n",
      "- [TRAIN] LOSS : 0.05186489530218144 [SCORE] : 0.5607760190963745\n",
      "[613/1000]\n",
      "- [VAL] LOSS : 0.037958670407533646 [SCORE] : 1.0\n",
      "[614/1000]\n",
      "- [TRAIN] LOSS : 0.051860384099806346 [SCORE] : 0.5607760190963745\n",
      "[614/1000]\n",
      "- [VAL] LOSS : 0.03794892504811287 [SCORE] : 1.0\n",
      "[615/1000]\n",
      "- [TRAIN] LOSS : 0.05185591146970789 [SCORE] : 0.5607760190963745\n",
      "[615/1000]\n",
      "- [VAL] LOSS : 0.03793920949101448 [SCORE] : 1.0\n",
      "[616/1000]\n",
      "- [TRAIN] LOSS : 0.05185142834670842 [SCORE] : 0.5607760190963745\n",
      "[616/1000]\n",
      "- [VAL] LOSS : 0.037929560989141464 [SCORE] : 1.0\n",
      "[617/1000]\n",
      "- [TRAIN] LOSS : 0.051846987940371035 [SCORE] : 0.5607760190963745\n",
      "[617/1000]\n",
      "- [VAL] LOSS : 0.037919897586107254 [SCORE] : 1.0\n",
      "[618/1000]\n",
      "- [TRAIN] LOSS : 0.05184252932667732 [SCORE] : 0.5607760190963745\n",
      "[618/1000]\n",
      "- [VAL] LOSS : 0.0379103347659111 [SCORE] : 1.0\n",
      "[619/1000]\n",
      "- [TRAIN] LOSS : 0.05183811017001669 [SCORE] : 0.5607760190963745\n",
      "[619/1000]\n",
      "- [VAL] LOSS : 0.03790079802274704 [SCORE] : 1.0\n",
      "[620/1000]\n",
      "- [TRAIN] LOSS : 0.05183369852602482 [SCORE] : 0.5607760190963745\n",
      "[620/1000]\n",
      "- [VAL] LOSS : 0.03789125010371208 [SCORE] : 1.0\n",
      "[621/1000]\n",
      "- [TRAIN] LOSS : 0.05182929052971304 [SCORE] : 0.5607760190963745\n",
      "[621/1000]\n",
      "- [VAL] LOSS : 0.03788179159164429 [SCORE] : 1.0\n",
      "[622/1000]\n",
      "- [TRAIN] LOSS : 0.05182487559504807 [SCORE] : 0.5607760190963745\n",
      "[622/1000]\n",
      "- [VAL] LOSS : 0.03787234053015709 [SCORE] : 1.0\n",
      "[623/1000]\n",
      "- [TRAIN] LOSS : 0.05182049386203289 [SCORE] : 0.5607760190963745\n",
      "[623/1000]\n",
      "- [VAL] LOSS : 0.03786288574337959 [SCORE] : 1.0\n",
      "[624/1000]\n",
      "- [TRAIN] LOSS : 0.05181614500470459 [SCORE] : 0.5607760190963745\n",
      "[624/1000]\n",
      "- [VAL] LOSS : 0.037853505462408066 [SCORE] : 1.0\n",
      "[625/1000]\n",
      "- [TRAIN] LOSS : 0.051811833136404556 [SCORE] : 0.5607760190963745\n",
      "[625/1000]\n",
      "- [VAL] LOSS : 0.037844233214855194 [SCORE] : 1.0\n",
      "[626/1000]\n",
      "- [TRAIN] LOSS : 0.05180747197009623 [SCORE] : 0.5607760190963745\n",
      "[626/1000]\n",
      "- [VAL] LOSS : 0.037834882736206055 [SCORE] : 1.0\n",
      "[627/1000]\n",
      "- [TRAIN] LOSS : 0.051803134676689906 [SCORE] : 0.5607760190963745\n",
      "[627/1000]\n",
      "- [VAL] LOSS : 0.037825632840394974 [SCORE] : 1.0\n",
      "[628/1000]\n",
      "- [TRAIN] LOSS : 0.05179882968465487 [SCORE] : 0.5607760190963745\n",
      "[628/1000]\n",
      "- [VAL] LOSS : 0.03781629726290703 [SCORE] : 1.0\n",
      "[629/1000]\n",
      "- [TRAIN] LOSS : 0.05179454757211109 [SCORE] : 0.5607760190963745\n",
      "[629/1000]\n",
      "- [VAL] LOSS : 0.037807125598192215 [SCORE] : 1.0\n",
      "[630/1000]\n",
      "- [TRAIN] LOSS : 0.05179028146279355 [SCORE] : 0.5607760190963745\n",
      "[630/1000]\n",
      "- [VAL] LOSS : 0.03779793158173561 [SCORE] : 1.0\n",
      "[631/1000]\n",
      "- [TRAIN] LOSS : 0.05178600813572606 [SCORE] : 0.5607760190963745\n",
      "[631/1000]\n",
      "- [VAL] LOSS : 0.03778878599405289 [SCORE] : 1.0\n",
      "[632/1000]\n",
      "- [TRAIN] LOSS : 0.051781766364971796 [SCORE] : 0.5607760190963745\n",
      "[632/1000]\n",
      "- [VAL] LOSS : 0.03777967020869255 [SCORE] : 1.0\n",
      "[633/1000]\n",
      "- [TRAIN] LOSS : 0.0517774970891575 [SCORE] : 0.5607760190963745\n",
      "[633/1000]\n",
      "- [VAL] LOSS : 0.03777055814862251 [SCORE] : 1.0\n",
      "[634/1000]\n",
      "- [TRAIN] LOSS : 0.051773281193648775 [SCORE] : 0.5607760190963745\n",
      "[634/1000]\n",
      "- [VAL] LOSS : 0.03776147961616516 [SCORE] : 1.0\n",
      "[635/1000]\n",
      "- [TRAIN] LOSS : 0.051769111786658564 [SCORE] : 0.5607760190963745\n",
      "[635/1000]\n",
      "- [VAL] LOSS : 0.03775247931480408 [SCORE] : 1.0\n",
      "[636/1000]\n",
      "- [TRAIN] LOSS : 0.051764894649386405 [SCORE] : 0.5607760190963745\n",
      "[636/1000]\n",
      "- [VAL] LOSS : 0.0377434603869915 [SCORE] : 1.0\n",
      "[637/1000]\n",
      "- [TRAIN] LOSS : 0.05176069738032917 [SCORE] : 0.5607760190963745\n",
      "[637/1000]\n",
      "- [VAL] LOSS : 0.03773454576730728 [SCORE] : 1.0\n",
      "[638/1000]\n",
      "- [TRAIN] LOSS : 0.05175653211772442 [SCORE] : 0.5607760190963745\n",
      "[638/1000]\n",
      "- [VAL] LOSS : 0.037725627422332764 [SCORE] : 1.0\n",
      "[639/1000]\n",
      "- [TRAIN] LOSS : 0.05175234588483969 [SCORE] : 0.5607760190963745\n",
      "[639/1000]\n",
      "- [VAL] LOSS : 0.03771669417619705 [SCORE] : 1.0\n",
      "[640/1000]\n",
      "- [TRAIN] LOSS : 0.051748210952306785 [SCORE] : 0.5607760190963745\n",
      "[640/1000]\n",
      "- [VAL] LOSS : 0.03770787641406059 [SCORE] : 1.0\n",
      "[641/1000]\n",
      "- [TRAIN] LOSS : 0.051744091386596365 [SCORE] : 0.5607760190963745\n",
      "[641/1000]\n",
      "- [VAL] LOSS : 0.03769902139902115 [SCORE] : 1.0\n",
      "[642/1000]\n",
      "- [TRAIN] LOSS : 0.05173996994271875 [SCORE] : 0.5607760190963745\n",
      "[642/1000]\n",
      "- [VAL] LOSS : 0.03769024461507797 [SCORE] : 1.0\n",
      "[643/1000]\n",
      "- [TRAIN] LOSS : 0.051735812611877915 [SCORE] : 0.5607760190963745\n",
      "[643/1000]\n",
      "- [VAL] LOSS : 0.03768143802881241 [SCORE] : 1.0\n",
      "[644/1000]\n",
      "- [TRAIN] LOSS : 0.05173173321721455 [SCORE] : 0.5607760190963745\n",
      "[644/1000]\n",
      "- [VAL] LOSS : 0.037672702223062515 [SCORE] : 1.0\n",
      "[645/1000]\n",
      "- [TRAIN] LOSS : 0.05172766417575379 [SCORE] : 0.5607760190963745\n",
      "[645/1000]\n",
      "- [VAL] LOSS : 0.037664033472537994 [SCORE] : 1.0\n",
      "[646/1000]\n",
      "- [TRAIN] LOSS : 0.05172359682619572 [SCORE] : 0.5607760190963745\n",
      "[646/1000]\n",
      "- [VAL] LOSS : 0.037655364722013474 [SCORE] : 1.0\n",
      "[647/1000]\n",
      "- [TRAIN] LOSS : 0.05171954212710261 [SCORE] : 0.5607760190963745\n",
      "[647/1000]\n",
      "- [VAL] LOSS : 0.03764673322439194 [SCORE] : 1.0\n",
      "[648/1000]\n",
      "- [TRAIN] LOSS : 0.05171544508387645 [SCORE] : 0.5607760190963745\n",
      "[648/1000]\n",
      "- [VAL] LOSS : 0.037638045847415924 [SCORE] : 1.0\n",
      "[649/1000]\n",
      "- [TRAIN] LOSS : 0.05171143803745508 [SCORE] : 0.5607760190963745\n",
      "[649/1000]\n",
      "- [VAL] LOSS : 0.03762948140501976 [SCORE] : 1.0\n",
      "[650/1000]\n",
      "- [TRAIN] LOSS : 0.051707420001427334 [SCORE] : 0.5607760190963745\n",
      "[650/1000]\n",
      "- [VAL] LOSS : 0.03762098401784897 [SCORE] : 1.0\n",
      "[651/1000]\n",
      "- [TRAIN] LOSS : 0.05170340331581732 [SCORE] : 0.5607760190963745\n",
      "[651/1000]\n",
      "- [VAL] LOSS : 0.03761252015829086 [SCORE] : 1.0\n",
      "[652/1000]\n",
      "- [TRAIN] LOSS : 0.051699361810460684 [SCORE] : 0.5607760190963745\n",
      "[652/1000]\n",
      "- [VAL] LOSS : 0.037603992968797684 [SCORE] : 1.0\n",
      "[653/1000]\n",
      "- [TRAIN] LOSS : 0.05169539538522561 [SCORE] : 0.5607760190963745\n",
      "[653/1000]\n",
      "- [VAL] LOSS : 0.03759552910923958 [SCORE] : 1.0\n",
      "[654/1000]\n",
      "- [TRAIN] LOSS : 0.051691424939781426 [SCORE] : 0.5607760190963745\n",
      "[654/1000]\n",
      "- [VAL] LOSS : 0.03758709505200386 [SCORE] : 1.0\n",
      "[655/1000]\n",
      "- [TRAIN] LOSS : 0.05168741286421816 [SCORE] : 0.5607760190963745\n",
      "[655/1000]\n",
      "- [VAL] LOSS : 0.03757866472005844 [SCORE] : 1.0\n",
      "[656/1000]\n",
      "- [TRAIN] LOSS : 0.05168353117381533 [SCORE] : 0.5607760190963745\n",
      "[656/1000]\n",
      "- [VAL] LOSS : 0.03757030516862869 [SCORE] : 1.0\n",
      "[657/1000]\n",
      "- [TRAIN] LOSS : 0.05167953760052721 [SCORE] : 0.5607760190963745\n",
      "[657/1000]\n",
      "- [VAL] LOSS : 0.03756198659539223 [SCORE] : 1.0\n",
      "[658/1000]\n",
      "- [TRAIN] LOSS : 0.05167563140081863 [SCORE] : 0.5607760190963745\n",
      "[658/1000]\n",
      "- [VAL] LOSS : 0.03755370154976845 [SCORE] : 1.0\n",
      "[659/1000]\n",
      "- [TRAIN] LOSS : 0.05167166367173195 [SCORE] : 0.5607760190963745\n",
      "[659/1000]\n",
      "- [VAL] LOSS : 0.037545450031757355 [SCORE] : 1.0\n",
      "[660/1000]\n",
      "- [TRAIN] LOSS : 0.05166777279227972 [SCORE] : 0.5607760190963745\n",
      "[660/1000]\n",
      "- [VAL] LOSS : 0.03753717616200447 [SCORE] : 1.0\n",
      "[661/1000]\n",
      "- [TRAIN] LOSS : 0.05166387238229315 [SCORE] : 0.5607760190963745\n",
      "[661/1000]\n",
      "- [VAL] LOSS : 0.03752896562218666 [SCORE] : 1.0\n",
      "[662/1000]\n",
      "- [TRAIN] LOSS : 0.05166001603938639 [SCORE] : 0.5607760190963745\n",
      "[662/1000]\n",
      "- [VAL] LOSS : 0.037520796060562134 [SCORE] : 1.0\n",
      "[663/1000]\n",
      "- [TRAIN] LOSS : 0.05165610569529235 [SCORE] : 0.5607760190963745\n",
      "[663/1000]\n",
      "- [VAL] LOSS : 0.037512630224227905 [SCORE] : 1.0\n",
      "[664/1000]\n",
      "- [TRAIN] LOSS : 0.051652263244614006 [SCORE] : 0.5607760190963745\n",
      "[664/1000]\n",
      "- [VAL] LOSS : 0.037504542618989944 [SCORE] : 1.0\n",
      "[665/1000]\n",
      "- [TRAIN] LOSS : 0.05164837695968648 [SCORE] : 0.5607760190963745\n",
      "[665/1000]\n",
      "- [VAL] LOSS : 0.03749638795852661 [SCORE] : 1.0\n",
      "[666/1000]\n",
      "- [TRAIN] LOSS : 0.05164453930531939 [SCORE] : 0.5607760190963745\n",
      "[666/1000]\n",
      "- [VAL] LOSS : 0.037488337606191635 [SCORE] : 1.0\n",
      "[667/1000]\n",
      "- [TRAIN] LOSS : 0.051640729606151584 [SCORE] : 0.5607760190963745\n",
      "[667/1000]\n",
      "- [VAL] LOSS : 0.037480294704437256 [SCORE] : 1.0\n",
      "[668/1000]\n",
      "- [TRAIN] LOSS : 0.05163689848656456 [SCORE] : 0.5607760190963745\n",
      "[668/1000]\n",
      "- [VAL] LOSS : 0.03747224807739258 [SCORE] : 1.0\n",
      "[669/1000]\n",
      "- [TRAIN] LOSS : 0.0516330823302269 [SCORE] : 0.5607760190963745\n",
      "[669/1000]\n",
      "- [VAL] LOSS : 0.037464290857315063 [SCORE] : 1.0\n",
      "[670/1000]\n",
      "- [TRAIN] LOSS : 0.051629285250479974 [SCORE] : 0.5607760190963745\n",
      "[670/1000]\n",
      "- [VAL] LOSS : 0.03745632246136665 [SCORE] : 1.0\n",
      "[671/1000]\n",
      "- [TRAIN] LOSS : 0.051625503009806076 [SCORE] : 0.5607760190963745\n",
      "[671/1000]\n",
      "- [VAL] LOSS : 0.037448376417160034 [SCORE] : 1.0\n",
      "[672/1000]\n",
      "- [TRAIN] LOSS : 0.05162172759883106 [SCORE] : 0.5607760190963745\n",
      "[672/1000]\n",
      "- [VAL] LOSS : 0.03744049742817879 [SCORE] : 1.0\n",
      "[673/1000]\n",
      "- [TRAIN] LOSS : 0.051617949673285084 [SCORE] : 0.5607760190963745\n",
      "[673/1000]\n",
      "- [VAL] LOSS : 0.03743258863687515 [SCORE] : 1.0\n",
      "[674/1000]\n",
      "- [TRAIN] LOSS : 0.05161418609010677 [SCORE] : 0.5607760190963745\n",
      "[674/1000]\n",
      "- [VAL] LOSS : 0.03742479160428047 [SCORE] : 1.0\n",
      "[675/1000]\n",
      "- [TRAIN] LOSS : 0.05161044336855412 [SCORE] : 0.5607760190963745\n",
      "[675/1000]\n",
      "- [VAL] LOSS : 0.037416938692331314 [SCORE] : 1.0\n",
      "[676/1000]\n",
      "- [TRAIN] LOSS : 0.05160667559442421 [SCORE] : 0.5607760190963745\n",
      "[676/1000]\n",
      "- [VAL] LOSS : 0.03740913048386574 [SCORE] : 1.0\n",
      "[677/1000]\n",
      "- [TRAIN] LOSS : 0.05160297454955677 [SCORE] : 0.5607760190963745\n",
      "[677/1000]\n",
      "- [VAL] LOSS : 0.03740134835243225 [SCORE] : 1.0\n",
      "[678/1000]\n",
      "- [TRAIN] LOSS : 0.05159926856867969 [SCORE] : 0.5607760190963745\n",
      "[678/1000]\n",
      "- [VAL] LOSS : 0.037393659353256226 [SCORE] : 1.0\n",
      "[679/1000]\n",
      "- [TRAIN] LOSS : 0.05159555403515696 [SCORE] : 0.5607760190963745\n",
      "[679/1000]\n",
      "- [VAL] LOSS : 0.037385936826467514 [SCORE] : 1.0\n",
      "[680/1000]\n",
      "- [TRAIN] LOSS : 0.051591866199548045 [SCORE] : 0.5607760190963745\n",
      "[680/1000]\n",
      "- [VAL] LOSS : 0.037378277629613876 [SCORE] : 1.0\n",
      "[681/1000]\n",
      "- [TRAIN] LOSS : 0.05158816914384564 [SCORE] : 0.5607760190963745\n",
      "[681/1000]\n",
      "- [VAL] LOSS : 0.03737059235572815 [SCORE] : 1.0\n",
      "[682/1000]\n",
      "- [TRAIN] LOSS : 0.051584486942738296 [SCORE] : 0.5607760190963745\n",
      "[682/1000]\n",
      "- [VAL] LOSS : 0.0373629666864872 [SCORE] : 1.0\n",
      "[683/1000]\n",
      "- [TRAIN] LOSS : 0.05158085285996397 [SCORE] : 0.5607760190963745\n",
      "[683/1000]\n",
      "- [VAL] LOSS : 0.03735535591840744 [SCORE] : 1.0\n",
      "[684/1000]\n",
      "- [TRAIN] LOSS : 0.051577146832520765 [SCORE] : 0.5607760190963745\n",
      "[684/1000]\n",
      "- [VAL] LOSS : 0.03734780475497246 [SCORE] : 1.0\n",
      "[685/1000]\n",
      "- [TRAIN] LOSS : 0.0515734967465202 [SCORE] : 0.5607760190963745\n",
      "[685/1000]\n",
      "- [VAL] LOSS : 0.03734024241566658 [SCORE] : 1.0\n",
      "[686/1000]\n",
      "- [TRAIN] LOSS : 0.051569901794816055 [SCORE] : 0.5607760190963745\n",
      "[686/1000]\n",
      "- [VAL] LOSS : 0.037332773208618164 [SCORE] : 1.0\n",
      "[687/1000]\n",
      "- [TRAIN] LOSS : 0.051566290017217395 [SCORE] : 0.5607760190963745\n",
      "[687/1000]\n",
      "- [VAL] LOSS : 0.037325259298086166 [SCORE] : 1.0\n",
      "[688/1000]\n",
      "- [TRAIN] LOSS : 0.05156263957420985 [SCORE] : 0.5607760190963745\n",
      "[688/1000]\n",
      "- [VAL] LOSS : 0.037317801266908646 [SCORE] : 1.0\n",
      "[689/1000]\n",
      "- [TRAIN] LOSS : 0.051559026911854745 [SCORE] : 0.5607760190963745\n",
      "[689/1000]\n",
      "- [VAL] LOSS : 0.03731032833456993 [SCORE] : 1.0\n",
      "[690/1000]\n",
      "- [TRAIN] LOSS : 0.05155543447472155 [SCORE] : 0.5607760190963745\n",
      "[690/1000]\n",
      "- [VAL] LOSS : 0.03730294853448868 [SCORE] : 1.0\n",
      "[691/1000]\n",
      "- [TRAIN] LOSS : 0.0515518590187033 [SCORE] : 0.5607760190963745\n",
      "[691/1000]\n",
      "- [VAL] LOSS : 0.03729553148150444 [SCORE] : 1.0\n",
      "[692/1000]\n",
      "- [TRAIN] LOSS : 0.05154829515765111 [SCORE] : 0.5607760190963745\n",
      "[692/1000]\n",
      "- [VAL] LOSS : 0.03728821128606796 [SCORE] : 1.0\n",
      "[693/1000]\n",
      "- [TRAIN] LOSS : 0.051544729309777416 [SCORE] : 0.5607760190963745\n",
      "[693/1000]\n",
      "- [VAL] LOSS : 0.037280838936567307 [SCORE] : 1.0\n",
      "[694/1000]\n",
      "- [TRAIN] LOSS : 0.051541153729582824 [SCORE] : 0.5607760190963745\n",
      "[694/1000]\n",
      "- [VAL] LOSS : 0.037273503839969635 [SCORE] : 1.0\n",
      "[695/1000]\n",
      "- [TRAIN] LOSS : 0.05153761877057453 [SCORE] : 0.5607760190963745\n",
      "[695/1000]\n",
      "- [VAL] LOSS : 0.03726622089743614 [SCORE] : 1.0\n",
      "[696/1000]\n",
      "- [TRAIN] LOSS : 0.05153406156847874 [SCORE] : 0.5607760190963745\n",
      "[696/1000]\n",
      "- [VAL] LOSS : 0.03725899010896683 [SCORE] : 1.0\n",
      "[697/1000]\n",
      "- [TRAIN] LOSS : 0.051530545375620324 [SCORE] : 0.5607760190963745\n",
      "[697/1000]\n",
      "- [VAL] LOSS : 0.037251751869916916 [SCORE] : 1.0\n",
      "[698/1000]\n",
      "- [TRAIN] LOSS : 0.051527033218493064 [SCORE] : 0.5607760190963745\n",
      "[698/1000]\n",
      "- [VAL] LOSS : 0.037244535982608795 [SCORE] : 1.0\n",
      "[699/1000]\n",
      "- [TRAIN] LOSS : 0.05152351021145781 [SCORE] : 0.5607760190963745\n",
      "[699/1000]\n",
      "- [VAL] LOSS : 0.037237342447042465 [SCORE] : 1.0\n",
      "[700/1000]\n",
      "- [TRAIN] LOSS : 0.05151999987040957 [SCORE] : 0.5607760190963745\n",
      "[700/1000]\n",
      "- [VAL] LOSS : 0.03723018243908882 [SCORE] : 1.0\n",
      "[701/1000]\n",
      "- [TRAIN] LOSS : 0.051516507364188634 [SCORE] : 0.5607760190963745\n",
      "[701/1000]\n",
      "- [VAL] LOSS : 0.03722308948636055 [SCORE] : 1.0\n",
      "[702/1000]\n",
      "- [TRAIN] LOSS : 0.05151303902578851 [SCORE] : 0.5607760190963745\n",
      "[702/1000]\n",
      "- [VAL] LOSS : 0.03721600025892258 [SCORE] : 1.0\n",
      "[703/1000]\n",
      "- [TRAIN] LOSS : 0.05150953931733966 [SCORE] : 0.5607760190963745\n",
      "[703/1000]\n",
      "- [VAL] LOSS : 0.03720887750387192 [SCORE] : 1.0\n",
      "[704/1000]\n",
      "- [TRAIN] LOSS : 0.05150612238794565 [SCORE] : 0.5607760190963745\n",
      "[704/1000]\n",
      "- [VAL] LOSS : 0.03720179945230484 [SCORE] : 1.0\n",
      "[705/1000]\n",
      "- [TRAIN] LOSS : 0.05150266213652988 [SCORE] : 0.5607760190963745\n",
      "[705/1000]\n",
      "- [VAL] LOSS : 0.037194810807704926 [SCORE] : 1.0\n",
      "[706/1000]\n",
      "- [TRAIN] LOSS : 0.05149917060819765 [SCORE] : 0.5607760190963745\n",
      "[706/1000]\n",
      "- [VAL] LOSS : 0.03718775138258934 [SCORE] : 1.0\n",
      "[707/1000]\n",
      "- [TRAIN] LOSS : 0.05149575336836278 [SCORE] : 0.5607760190963745\n",
      "[707/1000]\n",
      "- [VAL] LOSS : 0.03718075156211853 [SCORE] : 1.0\n",
      "[708/1000]\n",
      "- [TRAIN] LOSS : 0.051492337106416625 [SCORE] : 0.5607760190963745\n",
      "[708/1000]\n",
      "- [VAL] LOSS : 0.0371738076210022 [SCORE] : 1.0\n",
      "[709/1000]\n",
      "- [TRAIN] LOSS : 0.05148890595883131 [SCORE] : 0.5607760190963745\n",
      "[709/1000]\n",
      "- [VAL] LOSS : 0.037166889756917953 [SCORE] : 1.0\n",
      "[710/1000]\n",
      "- [TRAIN] LOSS : 0.051485490954170626 [SCORE] : 0.5607760190963745\n",
      "[710/1000]\n",
      "- [VAL] LOSS : 0.0371600016951561 [SCORE] : 1.0\n",
      "[711/1000]\n",
      "- [TRAIN] LOSS : 0.05148211812290052 [SCORE] : 0.5607760190963745\n",
      "[711/1000]\n",
      "- [VAL] LOSS : 0.03715307265520096 [SCORE] : 1.0\n",
      "[712/1000]\n",
      "- [TRAIN] LOSS : 0.051478689846893154 [SCORE] : 0.5607760190963745\n",
      "[712/1000]\n",
      "- [VAL] LOSS : 0.037146199494600296 [SCORE] : 1.0\n",
      "[713/1000]\n",
      "- [TRAIN] LOSS : 0.05147531802455584 [SCORE] : 0.5607760190963745\n",
      "[713/1000]\n",
      "- [VAL] LOSS : 0.037139326333999634 [SCORE] : 1.0\n",
      "[714/1000]\n",
      "- [TRAIN] LOSS : 0.051471952442079784 [SCORE] : 0.5607760190963745\n",
      "[714/1000]\n",
      "- [VAL] LOSS : 0.03713251277804375 [SCORE] : 1.0\n",
      "[715/1000]\n",
      "- [TRAIN] LOSS : 0.05146859781816602 [SCORE] : 0.5607760190963745\n",
      "[715/1000]\n",
      "- [VAL] LOSS : 0.03712570294737816 [SCORE] : 1.0\n",
      "[716/1000]\n",
      "- [TRAIN] LOSS : 0.05146521587545673 [SCORE] : 0.5607760190963745\n",
      "[716/1000]\n",
      "- [VAL] LOSS : 0.03711891919374466 [SCORE] : 1.0\n",
      "[717/1000]\n",
      "- [TRAIN] LOSS : 0.05146188260987401 [SCORE] : 0.5607760190963745\n",
      "[717/1000]\n",
      "- [VAL] LOSS : 0.03711218386888504 [SCORE] : 1.0\n",
      "[718/1000]\n",
      "- [TRAIN] LOSS : 0.05145853203721344 [SCORE] : 0.5607760190963745\n",
      "[718/1000]\n",
      "- [VAL] LOSS : 0.03710545226931572 [SCORE] : 1.0\n",
      "[719/1000]\n",
      "- [TRAIN] LOSS : 0.0514551994856447 [SCORE] : 0.5607760190963745\n",
      "[719/1000]\n",
      "- [VAL] LOSS : 0.037098757922649384 [SCORE] : 1.0\n",
      "[720/1000]\n",
      "- [TRAIN] LOSS : 0.05145186679437756 [SCORE] : 0.5607760190963745\n",
      "[720/1000]\n",
      "- [VAL] LOSS : 0.03709204122424126 [SCORE] : 1.0\n",
      "[721/1000]\n",
      "- [TRAIN] LOSS : 0.051448572892695665 [SCORE] : 0.5607760190963745\n",
      "[721/1000]\n",
      "- [VAL] LOSS : 0.0370853953063488 [SCORE] : 1.0\n",
      "[722/1000]\n",
      "- [TRAIN] LOSS : 0.051445259045188624 [SCORE] : 0.5607760190963745\n",
      "[722/1000]\n",
      "- [VAL] LOSS : 0.037078794091939926 [SCORE] : 1.0\n",
      "[723/1000]\n",
      "- [TRAIN] LOSS : 0.05144191182528933 [SCORE] : 0.5607760190963745\n",
      "[723/1000]\n",
      "- [VAL] LOSS : 0.03707210347056389 [SCORE] : 1.0\n",
      "[724/1000]\n",
      "- [TRAIN] LOSS : 0.05143865728750825 [SCORE] : 0.5607760190963745\n",
      "[724/1000]\n",
      "- [VAL] LOSS : 0.037065546959638596 [SCORE] : 1.0\n",
      "[725/1000]\n",
      "- [TRAIN] LOSS : 0.05143542643636465 [SCORE] : 0.5607760190963745\n",
      "[725/1000]\n",
      "- [VAL] LOSS : 0.03705901280045509 [SCORE] : 1.0\n",
      "[726/1000]\n",
      "- [TRAIN] LOSS : 0.0514320848044008 [SCORE] : 0.5607760190963745\n",
      "[726/1000]\n",
      "- [VAL] LOSS : 0.03705244138836861 [SCORE] : 1.0\n",
      "[727/1000]\n",
      "- [TRAIN] LOSS : 0.05142883616499603 [SCORE] : 0.5607760190963745\n",
      "[727/1000]\n",
      "- [VAL] LOSS : 0.03704587742686272 [SCORE] : 1.0\n",
      "[728/1000]\n",
      "- [TRAIN] LOSS : 0.051425599477564296 [SCORE] : 0.5607760190963745\n",
      "[728/1000]\n",
      "- [VAL] LOSS : 0.037039440125226974 [SCORE] : 1.0\n",
      "[729/1000]\n",
      "- [TRAIN] LOSS : 0.051422360648090644 [SCORE] : 0.5607760190963745\n",
      "[729/1000]\n",
      "- [VAL] LOSS : 0.03703293949365616 [SCORE] : 1.0\n",
      "[730/1000]\n",
      "- [TRAIN] LOSS : 0.05141907343640924 [SCORE] : 0.5607760190963745\n",
      "[730/1000]\n",
      "- [VAL] LOSS : 0.037026435136795044 [SCORE] : 1.0\n",
      "[731/1000]\n",
      "- [TRAIN] LOSS : 0.05141587569378316 [SCORE] : 0.5607760190963745\n",
      "[731/1000]\n",
      "- [VAL] LOSS : 0.037020016461610794 [SCORE] : 1.0\n",
      "[732/1000]\n",
      "- [TRAIN] LOSS : 0.0514126459757487 [SCORE] : 0.5607760190963745\n",
      "[732/1000]\n",
      "- [VAL] LOSS : 0.03701364994049072 [SCORE] : 1.0\n",
      "[733/1000]\n",
      "- [TRAIN] LOSS : 0.051409399742260574 [SCORE] : 0.5607760190963745\n",
      "[733/1000]\n",
      "- [VAL] LOSS : 0.03700722008943558 [SCORE] : 1.0\n",
      "[734/1000]\n",
      "- [TRAIN] LOSS : 0.0514062220385919 [SCORE] : 0.5607760190963745\n",
      "[734/1000]\n",
      "- [VAL] LOSS : 0.03700076416134834 [SCORE] : 1.0\n",
      "[735/1000]\n",
      "- [TRAIN] LOSS : 0.051403006600836916 [SCORE] : 0.5607760190963745\n",
      "[735/1000]\n",
      "- [VAL] LOSS : 0.03699445724487305 [SCORE] : 1.0\n",
      "[736/1000]\n",
      "- [TRAIN] LOSS : 0.05139978098062178 [SCORE] : 0.5607760190963745\n",
      "[736/1000]\n",
      "- [VAL] LOSS : 0.03698810935020447 [SCORE] : 1.0\n",
      "[737/1000]\n",
      "- [TRAIN] LOSS : 0.05139666322308282 [SCORE] : 0.5607760190963745\n",
      "[737/1000]\n",
      "- [VAL] LOSS : 0.03698181360960007 [SCORE] : 1.0\n",
      "[738/1000]\n",
      "- [TRAIN] LOSS : 0.05139344255439937 [SCORE] : 0.5607760190963745\n",
      "[738/1000]\n",
      "- [VAL] LOSS : 0.03697555512189865 [SCORE] : 1.0\n",
      "[739/1000]\n",
      "- [TRAIN] LOSS : 0.051390259588758154 [SCORE] : 0.5607760190963745\n",
      "[739/1000]\n",
      "- [VAL] LOSS : 0.03696924075484276 [SCORE] : 1.0\n",
      "[740/1000]\n",
      "- [TRAIN] LOSS : 0.051387117523699996 [SCORE] : 0.5607760190963745\n",
      "[740/1000]\n",
      "- [VAL] LOSS : 0.03696299344301224 [SCORE] : 1.0\n",
      "[741/1000]\n",
      "- [TRAIN] LOSS : 0.051383982862656316 [SCORE] : 0.5607760190963745\n",
      "[741/1000]\n",
      "- [VAL] LOSS : 0.03695673868060112 [SCORE] : 1.0\n",
      "[742/1000]\n",
      "- [TRAIN] LOSS : 0.05138083407655358 [SCORE] : 0.5607760190963745\n",
      "[742/1000]\n",
      "- [VAL] LOSS : 0.03695051744580269 [SCORE] : 1.0\n",
      "[743/1000]\n",
      "- [TRAIN] LOSS : 0.05137768429704011 [SCORE] : 0.5607760190963745\n",
      "[743/1000]\n",
      "- [VAL] LOSS : 0.03694435581564903 [SCORE] : 1.0\n",
      "[744/1000]\n",
      "- [TRAIN] LOSS : 0.05137454519669215 [SCORE] : 0.5607760190963745\n",
      "[744/1000]\n",
      "- [VAL] LOSS : 0.03693818673491478 [SCORE] : 1.0\n",
      "[745/1000]\n",
      "- [TRAIN] LOSS : 0.05137147259277602 [SCORE] : 0.5607760190963745\n",
      "[745/1000]\n",
      "- [VAL] LOSS : 0.0369320772588253 [SCORE] : 1.0\n",
      "[746/1000]\n",
      "- [TRAIN] LOSS : 0.05136832032973568 [SCORE] : 0.5607760190963745\n",
      "[746/1000]\n",
      "- [VAL] LOSS : 0.03692592307925224 [SCORE] : 1.0\n",
      "[747/1000]\n",
      "- [TRAIN] LOSS : 0.05136521413611869 [SCORE] : 0.5607760190963745\n",
      "[747/1000]\n",
      "- [VAL] LOSS : 0.036919813603162766 [SCORE] : 1.0\n",
      "[748/1000]\n",
      "- [TRAIN] LOSS : 0.05136208444212874 [SCORE] : 0.5607760190963745\n",
      "[748/1000]\n",
      "- [VAL] LOSS : 0.03691372275352478 [SCORE] : 1.0\n",
      "[749/1000]\n",
      "- [TRAIN] LOSS : 0.05135900320795675 [SCORE] : 0.5607760190963745\n",
      "[749/1000]\n",
      "- [VAL] LOSS : 0.03690766915678978 [SCORE] : 1.0\n",
      "[750/1000]\n",
      "- [TRAIN] LOSS : 0.05135591053403914 [SCORE] : 0.5607760190963745\n",
      "[750/1000]\n",
      "- [VAL] LOSS : 0.03690159320831299 [SCORE] : 1.0\n",
      "[751/1000]\n",
      "- [TRAIN] LOSS : 0.051352852412189044 [SCORE] : 0.5607760190963745\n",
      "[751/1000]\n",
      "- [VAL] LOSS : 0.03689558058977127 [SCORE] : 1.0\n",
      "[752/1000]\n",
      "- [TRAIN] LOSS : 0.05134979477152228 [SCORE] : 0.5607760190963745\n",
      "[752/1000]\n",
      "- [VAL] LOSS : 0.03688960522413254 [SCORE] : 1.0\n",
      "[753/1000]\n",
      "- [TRAIN] LOSS : 0.051346710945169134 [SCORE] : 0.5607760190963745\n",
      "[753/1000]\n",
      "- [VAL] LOSS : 0.03688361495733261 [SCORE] : 1.0\n",
      "[754/1000]\n",
      "- [TRAIN] LOSS : 0.05134366864028076 [SCORE] : 0.5607760190963745\n",
      "[754/1000]\n",
      "- [VAL] LOSS : 0.03687765449285507 [SCORE] : 1.0\n",
      "[755/1000]\n",
      "- [TRAIN] LOSS : 0.05134062183399995 [SCORE] : 0.5607760190963745\n",
      "[755/1000]\n",
      "- [VAL] LOSS : 0.036871712654829025 [SCORE] : 1.0\n",
      "[756/1000]\n",
      "- [TRAIN] LOSS : 0.05133757876853148 [SCORE] : 0.5607760190963745\n",
      "[756/1000]\n",
      "- [VAL] LOSS : 0.03686579689383507 [SCORE] : 1.0\n",
      "[757/1000]\n",
      "- [TRAIN] LOSS : 0.051334539397309226 [SCORE] : 0.5607760190963745\n",
      "[757/1000]\n",
      "- [VAL] LOSS : 0.03685985878109932 [SCORE] : 1.0\n",
      "[758/1000]\n",
      "- [TRAIN] LOSS : 0.051331510317201415 [SCORE] : 0.5607760190963745\n",
      "[758/1000]\n",
      "- [VAL] LOSS : 0.036853961646556854 [SCORE] : 1.0\n",
      "[759/1000]\n",
      "- [TRAIN] LOSS : 0.05132848443463445 [SCORE] : 0.5607760190963745\n",
      "[759/1000]\n",
      "- [VAL] LOSS : 0.03684815764427185 [SCORE] : 1.0\n",
      "[760/1000]\n",
      "- [TRAIN] LOSS : 0.05132546702710291 [SCORE] : 0.5607760190963745\n",
      "[760/1000]\n",
      "- [VAL] LOSS : 0.036842215806245804 [SCORE] : 1.0\n",
      "[761/1000]\n",
      "- [TRAIN] LOSS : 0.05132246070231001 [SCORE] : 0.5607760190963745\n",
      "[761/1000]\n",
      "- [VAL] LOSS : 0.0368364118039608 [SCORE] : 1.0\n",
      "[762/1000]\n",
      "- [TRAIN] LOSS : 0.05131946243345738 [SCORE] : 0.5607760190963745\n",
      "[762/1000]\n",
      "- [VAL] LOSS : 0.03683064132928848 [SCORE] : 1.0\n",
      "[763/1000]\n",
      "- [TRAIN] LOSS : 0.051316474300498766 [SCORE] : 0.5607760190963745\n",
      "[763/1000]\n",
      "- [VAL] LOSS : 0.03682483360171318 [SCORE] : 1.0\n",
      "[764/1000]\n",
      "- [TRAIN] LOSS : 0.05131349332320193 [SCORE] : 0.5607760190963745\n",
      "[764/1000]\n",
      "- [VAL] LOSS : 0.03681907430291176 [SCORE] : 1.0\n",
      "[765/1000]\n",
      "- [TRAIN] LOSS : 0.051310523754606645 [SCORE] : 0.5607760190963745\n",
      "[765/1000]\n",
      "- [VAL] LOSS : 0.036813318729400635 [SCORE] : 1.0\n",
      "[766/1000]\n",
      "- [TRAIN] LOSS : 0.05130753420914213 [SCORE] : 0.5607760190963745\n",
      "[766/1000]\n",
      "- [VAL] LOSS : 0.036807578057050705 [SCORE] : 1.0\n",
      "[767/1000]\n",
      "- [TRAIN] LOSS : 0.0513045715012898 [SCORE] : 0.5607760190963745\n",
      "[767/1000]\n",
      "- [VAL] LOSS : 0.03680185228586197 [SCORE] : 1.0\n",
      "[768/1000]\n",
      "- [TRAIN] LOSS : 0.05130164216582974 [SCORE] : 0.5607760190963745\n",
      "[768/1000]\n",
      "- [VAL] LOSS : 0.036796193569898605 [SCORE] : 1.0\n",
      "[769/1000]\n",
      "- [TRAIN] LOSS : 0.05129867852665484 [SCORE] : 0.5607760190963745\n",
      "[769/1000]\n",
      "- [VAL] LOSS : 0.03679050877690315 [SCORE] : 1.0\n",
      "[770/1000]\n",
      "- [TRAIN] LOSS : 0.05129573571806153 [SCORE] : 0.5607760190963745\n",
      "[770/1000]\n",
      "- [VAL] LOSS : 0.036784857511520386 [SCORE] : 1.0\n",
      "[771/1000]\n",
      "- [TRAIN] LOSS : 0.051292792924990255 [SCORE] : 0.5607760190963745\n",
      "[771/1000]\n",
      "- [VAL] LOSS : 0.036779213696718216 [SCORE] : 1.0\n",
      "[772/1000]\n",
      "- [TRAIN] LOSS : 0.05128987591403226 [SCORE] : 0.5607760190963745\n",
      "[772/1000]\n",
      "- [VAL] LOSS : 0.03677358850836754 [SCORE] : 1.0\n",
      "[773/1000]\n",
      "- [TRAIN] LOSS : 0.051286929628501336 [SCORE] : 0.5607760190963745\n",
      "[773/1000]\n",
      "- [VAL] LOSS : 0.03676796704530716 [SCORE] : 1.0\n",
      "[774/1000]\n",
      "- [TRAIN] LOSS : 0.05128405171756943 [SCORE] : 0.5607760190963745\n",
      "[774/1000]\n",
      "- [VAL] LOSS : 0.03676237538456917 [SCORE] : 1.0\n",
      "[775/1000]\n",
      "- [TRAIN] LOSS : 0.05128112714737654 [SCORE] : 0.5607760190963745\n",
      "[775/1000]\n",
      "- [VAL] LOSS : 0.03675677999854088 [SCORE] : 1.0\n",
      "[776/1000]\n",
      "- [TRAIN] LOSS : 0.051278791607668 [SCORE] : 0.5607760190963745\n",
      "[776/1000]\n",
      "- [VAL] LOSS : 0.036751918494701385 [SCORE] : 1.0\n",
      "[777/1000]\n",
      "- [TRAIN] LOSS : 0.051275739911943674 [SCORE] : 0.5607760190963745\n",
      "[777/1000]\n",
      "- [VAL] LOSS : 0.03674694150686264 [SCORE] : 1.0\n",
      "[778/1000]\n",
      "- [TRAIN] LOSS : 0.05127251648033659 [SCORE] : 0.5607760190963745\n",
      "[778/1000]\n",
      "- [VAL] LOSS : 0.03674156218767166 [SCORE] : 1.0\n",
      "[779/1000]\n",
      "- [TRAIN] LOSS : 0.05126952299227317 [SCORE] : 0.5607760190963745\n",
      "[779/1000]\n",
      "- [VAL] LOSS : 0.036735955625772476 [SCORE] : 1.0\n",
      "[780/1000]\n",
      "- [TRAIN] LOSS : 0.051266682660207154 [SCORE] : 0.5607760190963745\n",
      "[780/1000]\n",
      "- [VAL] LOSS : 0.036730337888002396 [SCORE] : 1.0\n",
      "[781/1000]\n",
      "- [TRAIN] LOSS : 0.05126392940680186 [SCORE] : 0.5607760190963745\n",
      "[781/1000]\n",
      "- [VAL] LOSS : 0.03672485426068306 [SCORE] : 1.0\n",
      "[782/1000]\n",
      "- [TRAIN] LOSS : 0.05126110139923791 [SCORE] : 0.5607760190963745\n",
      "[782/1000]\n",
      "- [VAL] LOSS : 0.03671946004033089 [SCORE] : 1.0\n",
      "[783/1000]\n",
      "- [TRAIN] LOSS : 0.05125831981810431 [SCORE] : 0.5607760190963745\n",
      "[783/1000]\n",
      "- [VAL] LOSS : 0.03671417385339737 [SCORE] : 1.0\n",
      "[784/1000]\n",
      "- [TRAIN] LOSS : 0.05125549826771021 [SCORE] : 0.5607760190963745\n",
      "[784/1000]\n",
      "- [VAL] LOSS : 0.03670891746878624 [SCORE] : 1.0\n",
      "[785/1000]\n",
      "- [TRAIN] LOSS : 0.051252606743946674 [SCORE] : 0.5607760190963745\n",
      "[785/1000]\n",
      "- [VAL] LOSS : 0.036703627556562424 [SCORE] : 1.0\n",
      "[786/1000]\n",
      "- [TRAIN] LOSS : 0.051249717362225056 [SCORE] : 0.5607760190963745\n",
      "[786/1000]\n",
      "- [VAL] LOSS : 0.036698225885629654 [SCORE] : 1.0\n",
      "[787/1000]\n",
      "- [TRAIN] LOSS : 0.051246900390833613 [SCORE] : 0.5607760190963745\n",
      "[787/1000]\n",
      "- [VAL] LOSS : 0.03669289872050285 [SCORE] : 1.0\n",
      "[788/1000]\n",
      "- [TRAIN] LOSS : 0.051244068161274 [SCORE] : 0.5607760190963745\n",
      "[788/1000]\n",
      "- [VAL] LOSS : 0.03668756037950516 [SCORE] : 1.0\n",
      "[789/1000]\n",
      "- [TRAIN] LOSS : 0.051241355032349625 [SCORE] : 0.5607760190963745\n",
      "[789/1000]\n",
      "- [VAL] LOSS : 0.036682240664958954 [SCORE] : 1.0\n",
      "[790/1000]\n",
      "- [TRAIN] LOSS : 0.0512386094002674 [SCORE] : 0.5607760190963745\n",
      "[790/1000]\n",
      "- [VAL] LOSS : 0.03667701035737991 [SCORE] : 1.0\n",
      "[791/1000]\n",
      "- [TRAIN] LOSS : 0.05123579117159049 [SCORE] : 0.5607760190963745\n",
      "[791/1000]\n",
      "- [VAL] LOSS : 0.03667181730270386 [SCORE] : 1.0\n",
      "[792/1000]\n",
      "- [TRAIN] LOSS : 0.051232990358645716 [SCORE] : 0.5607760190963745\n",
      "[792/1000]\n",
      "- [VAL] LOSS : 0.036666613072156906 [SCORE] : 1.0\n",
      "[793/1000]\n",
      "- [TRAIN] LOSS : 0.051230195847650366 [SCORE] : 0.5607760190963745\n",
      "[793/1000]\n",
      "- [VAL] LOSS : 0.03666142001748085 [SCORE] : 1.0\n",
      "[794/1000]\n",
      "- [TRAIN] LOSS : 0.05122741290057699 [SCORE] : 0.5607760190963745\n",
      "[794/1000]\n",
      "- [VAL] LOSS : 0.03665618970990181 [SCORE] : 1.0\n",
      "[795/1000]\n",
      "- [TRAIN] LOSS : 0.05122467391192913 [SCORE] : 0.5607760190963745\n",
      "[795/1000]\n",
      "- [VAL] LOSS : 0.03665102273225784 [SCORE] : 1.0\n",
      "[796/1000]\n",
      "- [TRAIN] LOSS : 0.0512219299407055 [SCORE] : 0.5607760190963745\n",
      "[796/1000]\n",
      "- [VAL] LOSS : 0.03664586320519447 [SCORE] : 1.0\n",
      "[797/1000]\n",
      "- [TRAIN] LOSS : 0.051219148095697165 [SCORE] : 0.5607760190963745\n",
      "[797/1000]\n",
      "- [VAL] LOSS : 0.036640703678131104 [SCORE] : 1.0\n",
      "[798/1000]\n",
      "- [TRAIN] LOSS : 0.05121642885108789 [SCORE] : 0.5607760190963745\n",
      "[798/1000]\n",
      "- [VAL] LOSS : 0.036635588854551315 [SCORE] : 1.0\n",
      "[799/1000]\n",
      "- [TRAIN] LOSS : 0.05121367964893579 [SCORE] : 0.5607760190963745\n",
      "[799/1000]\n",
      "- [VAL] LOSS : 0.03663044050335884 [SCORE] : 1.0\n",
      "[800/1000]\n",
      "- [TRAIN] LOSS : 0.05121099410268168 [SCORE] : 0.5607760190963745\n",
      "[800/1000]\n",
      "- [VAL] LOSS : 0.03662538155913353 [SCORE] : 1.0\n",
      "[801/1000]\n",
      "- [TRAIN] LOSS : 0.05120821349943678 [SCORE] : 0.5607760190963745\n",
      "[801/1000]\n",
      "- [VAL] LOSS : 0.036620255559682846 [SCORE] : 1.0\n",
      "[802/1000]\n",
      "- [TRAIN] LOSS : 0.051205444429069755 [SCORE] : 0.5607760190963745\n",
      "[802/1000]\n",
      "- [VAL] LOSS : 0.03661510720849037 [SCORE] : 1.0\n",
      "[803/1000]\n",
      "- [TRAIN] LOSS : 0.05120281164223949 [SCORE] : 0.5607760190963745\n",
      "[803/1000]\n",
      "- [VAL] LOSS : 0.036610059440135956 [SCORE] : 1.0\n",
      "[804/1000]\n",
      "- [TRAIN] LOSS : 0.05120016013582548 [SCORE] : 0.5607760190963745\n",
      "[804/1000]\n",
      "- [VAL] LOSS : 0.036605048924684525 [SCORE] : 1.0\n",
      "[805/1000]\n",
      "- [TRAIN] LOSS : 0.05119740002167721 [SCORE] : 0.5607760190963745\n",
      "[805/1000]\n",
      "- [VAL] LOSS : 0.03660004585981369 [SCORE] : 1.0\n",
      "[806/1000]\n",
      "- [TRAIN] LOSS : 0.05119472155347467 [SCORE] : 0.5607760190963745\n",
      "[806/1000]\n",
      "- [VAL] LOSS : 0.036595068871974945 [SCORE] : 1.0\n",
      "[807/1000]\n",
      "- [TRAIN] LOSS : 0.051192012274016936 [SCORE] : 0.5607760190963745\n",
      "[807/1000]\n",
      "- [VAL] LOSS : 0.03659004345536232 [SCORE] : 1.0\n",
      "[808/1000]\n",
      "- [TRAIN] LOSS : 0.0511893551175793 [SCORE] : 0.5607760190963745\n",
      "[808/1000]\n",
      "- [VAL] LOSS : 0.03658508509397507 [SCORE] : 1.0\n",
      "[809/1000]\n",
      "- [TRAIN] LOSS : 0.051186635593573254 [SCORE] : 0.5607760190963745\n",
      "[809/1000]\n",
      "- [VAL] LOSS : 0.03658010810613632 [SCORE] : 1.0\n",
      "[810/1000]\n",
      "- [TRAIN] LOSS : 0.051184011669829485 [SCORE] : 0.5607760190963745\n",
      "[810/1000]\n",
      "- [VAL] LOSS : 0.03657519444823265 [SCORE] : 1.0\n",
      "[811/1000]\n",
      "- [TRAIN] LOSS : 0.051181327427426974 [SCORE] : 0.5607760190963745\n",
      "[811/1000]\n",
      "- [VAL] LOSS : 0.0365702286362648 [SCORE] : 1.0\n",
      "[812/1000]\n",
      "- [TRAIN] LOSS : 0.05117868358890216 [SCORE] : 0.5607760190963745\n",
      "[812/1000]\n",
      "- [VAL] LOSS : 0.03656533360481262 [SCORE] : 1.0\n",
      "[813/1000]\n",
      "- [TRAIN] LOSS : 0.0511759876118352 [SCORE] : 0.5607760190963745\n",
      "[813/1000]\n",
      "- [VAL] LOSS : 0.03656039386987686 [SCORE] : 1.0\n",
      "[814/1000]\n",
      "- [TRAIN] LOSS : 0.051173351549853884 [SCORE] : 0.5607760190963745\n",
      "[814/1000]\n",
      "- [VAL] LOSS : 0.03655552491545677 [SCORE] : 1.0\n",
      "[815/1000]\n",
      "- [TRAIN] LOSS : 0.05117069855332375 [SCORE] : 0.5607760190963745\n",
      "[815/1000]\n",
      "- [VAL] LOSS : 0.036550622433423996 [SCORE] : 1.0\n",
      "[816/1000]\n",
      "- [TRAIN] LOSS : 0.051168123617147405 [SCORE] : 0.5607760190963745\n",
      "[816/1000]\n",
      "- [VAL] LOSS : 0.03654582425951958 [SCORE] : 1.0\n",
      "[817/1000]\n",
      "- [TRAIN] LOSS : 0.051165455409015216 [SCORE] : 0.5607760190963745\n",
      "[817/1000]\n",
      "- [VAL] LOSS : 0.03654096648097038 [SCORE] : 1.0\n",
      "[818/1000]\n",
      "- [TRAIN] LOSS : 0.051162861132373415 [SCORE] : 0.5607760190963745\n",
      "[818/1000]\n",
      "- [VAL] LOSS : 0.03653613477945328 [SCORE] : 1.0\n",
      "[819/1000]\n",
      "- [TRAIN] LOSS : 0.05116019529911379 [SCORE] : 0.5607760190963745\n",
      "[819/1000]\n",
      "- [VAL] LOSS : 0.036531299352645874 [SCORE] : 1.0\n",
      "[820/1000]\n",
      "- [TRAIN] LOSS : 0.0511576012087365 [SCORE] : 0.5607760190963745\n",
      "[820/1000]\n",
      "- [VAL] LOSS : 0.036526501178741455 [SCORE] : 1.0\n",
      "[821/1000]\n",
      "- [TRAIN] LOSS : 0.05115498996650179 [SCORE] : 0.5607760190963745\n",
      "[821/1000]\n",
      "- [VAL] LOSS : 0.03652169182896614 [SCORE] : 1.0\n",
      "[822/1000]\n",
      "- [TRAIN] LOSS : 0.051152387727051975 [SCORE] : 0.5607760190963745\n",
      "[822/1000]\n",
      "- [VAL] LOSS : 0.0365169420838356 [SCORE] : 1.0\n",
      "[823/1000]\n",
      "- [TRAIN] LOSS : 0.05114978345421453 [SCORE] : 0.5607760190963745\n",
      "[823/1000]\n",
      "- [VAL] LOSS : 0.03651219233870506 [SCORE] : 1.0\n",
      "[824/1000]\n",
      "- [TRAIN] LOSS : 0.05114720120715598 [SCORE] : 0.5607760190963745\n",
      "[824/1000]\n",
      "- [VAL] LOSS : 0.036507464945316315 [SCORE] : 1.0\n",
      "[825/1000]\n",
      "- [TRAIN] LOSS : 0.05114460277060668 [SCORE] : 0.5607760190963745\n",
      "[825/1000]\n",
      "- [VAL] LOSS : 0.03650274500250816 [SCORE] : 1.0\n",
      "[826/1000]\n",
      "- [TRAIN] LOSS : 0.051142033903549114 [SCORE] : 0.5607760190963745\n",
      "[826/1000]\n",
      "- [VAL] LOSS : 0.03649801015853882 [SCORE] : 1.0\n",
      "[827/1000]\n",
      "- [TRAIN] LOSS : 0.051139443383241695 [SCORE] : 0.5607760190963745\n",
      "[827/1000]\n",
      "- [VAL] LOSS : 0.03649332746863365 [SCORE] : 1.0\n",
      "[828/1000]\n",
      "- [TRAIN] LOSS : 0.05113687217235565 [SCORE] : 0.5607760190963745\n",
      "[828/1000]\n",
      "- [VAL] LOSS : 0.03648862987756729 [SCORE] : 1.0\n",
      "[829/1000]\n",
      "- [TRAIN] LOSS : 0.05113432464810709 [SCORE] : 0.5607760190963745\n",
      "[829/1000]\n",
      "- [VAL] LOSS : 0.03648395091295242 [SCORE] : 1.0\n",
      "[830/1000]\n",
      "- [TRAIN] LOSS : 0.05113178676304718 [SCORE] : 0.5607760190963745\n",
      "[830/1000]\n",
      "- [VAL] LOSS : 0.03647933527827263 [SCORE] : 1.0\n",
      "[831/1000]\n",
      "- [TRAIN] LOSS : 0.05112921594021221 [SCORE] : 0.5607760190963745\n",
      "[831/1000]\n",
      "- [VAL] LOSS : 0.03647468239068985 [SCORE] : 1.0\n",
      "[832/1000]\n",
      "- [TRAIN] LOSS : 0.05112666177252929 [SCORE] : 0.5607760190963745\n",
      "[832/1000]\n",
      "- [VAL] LOSS : 0.03647003695368767 [SCORE] : 1.0\n",
      "[833/1000]\n",
      "- [TRAIN] LOSS : 0.0511241517495364 [SCORE] : 0.5607760190963745\n",
      "[833/1000]\n",
      "- [VAL] LOSS : 0.03646538034081459 [SCORE] : 1.0\n",
      "[834/1000]\n",
      "- [TRAIN] LOSS : 0.0511215911557277 [SCORE] : 0.5607760190963745\n",
      "[834/1000]\n",
      "- [VAL] LOSS : 0.03646080940961838 [SCORE] : 1.0\n",
      "[835/1000]\n",
      "- [TRAIN] LOSS : 0.051119067271550495 [SCORE] : 0.5607760190963745\n",
      "[835/1000]\n",
      "- [VAL] LOSS : 0.03645624965429306 [SCORE] : 1.0\n",
      "[836/1000]\n",
      "- [TRAIN] LOSS : 0.051116526251037915 [SCORE] : 0.5607760190963745\n",
      "[836/1000]\n",
      "- [VAL] LOSS : 0.03645168989896774 [SCORE] : 1.0\n",
      "[837/1000]\n",
      "- [TRAIN] LOSS : 0.0511140212106208 [SCORE] : 0.5607760190963745\n",
      "[837/1000]\n",
      "- [VAL] LOSS : 0.03644710034132004 [SCORE] : 1.0\n",
      "[838/1000]\n",
      "- [TRAIN] LOSS : 0.05111147151328623 [SCORE] : 0.5607760190963745\n",
      "[838/1000]\n",
      "- [VAL] LOSS : 0.03644249215722084 [SCORE] : 1.0\n",
      "[839/1000]\n",
      "- [TRAIN] LOSS : 0.051108986434216304 [SCORE] : 0.5607760190963745\n",
      "[839/1000]\n",
      "- [VAL] LOSS : 0.03643795847892761 [SCORE] : 1.0\n",
      "[840/1000]\n",
      "- [TRAIN] LOSS : 0.05110645776924987 [SCORE] : 0.5607760190963745\n",
      "[840/1000]\n",
      "- [VAL] LOSS : 0.03643346205353737 [SCORE] : 1.0\n",
      "[841/1000]\n",
      "- [TRAIN] LOSS : 0.051103966496884826 [SCORE] : 0.5607760190963745\n",
      "[841/1000]\n",
      "- [VAL] LOSS : 0.0364290289580822 [SCORE] : 1.0\n",
      "[842/1000]\n",
      "- [TRAIN] LOSS : 0.05110146732379993 [SCORE] : 0.5607760190963745\n",
      "[842/1000]\n",
      "- [VAL] LOSS : 0.036424487829208374 [SCORE] : 1.0\n",
      "[843/1000]\n",
      "- [TRAIN] LOSS : 0.05109896175563335 [SCORE] : 0.5607760190963745\n",
      "[843/1000]\n",
      "- [VAL] LOSS : 0.036419980227947235 [SCORE] : 1.0\n",
      "[844/1000]\n",
      "- [TRAIN] LOSS : 0.051096513665591675 [SCORE] : 0.5607760190963745\n",
      "[844/1000]\n",
      "- [VAL] LOSS : 0.036415521055459976 [SCORE] : 1.0\n",
      "[845/1000]\n",
      "- [TRAIN] LOSS : 0.05109400684013963 [SCORE] : 0.5607760190963745\n",
      "[845/1000]\n",
      "- [VAL] LOSS : 0.03641107678413391 [SCORE] : 1.0\n",
      "[846/1000]\n",
      "- [TRAIN] LOSS : 0.05109151524181167 [SCORE] : 0.5607760190963745\n",
      "[846/1000]\n",
      "- [VAL] LOSS : 0.03640660271048546 [SCORE] : 1.0\n",
      "[847/1000]\n",
      "- [TRAIN] LOSS : 0.051089056053509316 [SCORE] : 0.5607760190963745\n",
      "[847/1000]\n",
      "- [VAL] LOSS : 0.03640221804380417 [SCORE] : 1.0\n",
      "[848/1000]\n",
      "- [TRAIN] LOSS : 0.05108660593008001 [SCORE] : 0.5607760190963745\n",
      "[848/1000]\n",
      "- [VAL] LOSS : 0.03639780730009079 [SCORE] : 1.0\n",
      "[849/1000]\n",
      "- [TRAIN] LOSS : 0.0510841506998986 [SCORE] : 0.5607760190963745\n",
      "[849/1000]\n",
      "- [VAL] LOSS : 0.03639338165521622 [SCORE] : 1.0\n",
      "[850/1000]\n",
      "- [TRAIN] LOSS : 0.05108167120876412 [SCORE] : 0.5607760190963745\n",
      "[850/1000]\n",
      "- [VAL] LOSS : 0.03638899326324463 [SCORE] : 1.0\n",
      "[851/1000]\n",
      "- [TRAIN] LOSS : 0.05107922327394287 [SCORE] : 0.5607760190963745\n",
      "[851/1000]\n",
      "- [VAL] LOSS : 0.03638464957475662 [SCORE] : 1.0\n",
      "[852/1000]\n",
      "- [TRAIN] LOSS : 0.051076773724829154 [SCORE] : 0.5607760190963745\n",
      "[852/1000]\n",
      "- [VAL] LOSS : 0.03638024255633354 [SCORE] : 1.0\n",
      "[853/1000]\n",
      "- [TRAIN] LOSS : 0.05107438160727421 [SCORE] : 0.5607760190963745\n",
      "[853/1000]\n",
      "- [VAL] LOSS : 0.03637592867016792 [SCORE] : 1.0\n",
      "[854/1000]\n",
      "- [TRAIN] LOSS : 0.05107193247725566 [SCORE] : 0.5607760190963745\n",
      "[854/1000]\n",
      "- [VAL] LOSS : 0.03637159243226051 [SCORE] : 1.0\n",
      "[855/1000]\n",
      "- [TRAIN] LOSS : 0.05106946158533295 [SCORE] : 0.5607760190963745\n",
      "[855/1000]\n",
      "- [VAL] LOSS : 0.036367267370224 [SCORE] : 1.0\n",
      "[856/1000]\n",
      "- [TRAIN] LOSS : 0.05106708124900858 [SCORE] : 0.5607760190963745\n",
      "[856/1000]\n",
      "- [VAL] LOSS : 0.03636295720934868 [SCORE] : 1.0\n",
      "[857/1000]\n",
      "- [TRAIN] LOSS : 0.051064621486390634 [SCORE] : 0.5607760190963745\n",
      "[857/1000]\n",
      "- [VAL] LOSS : 0.03635865077376366 [SCORE] : 1.0\n",
      "[858/1000]\n",
      "- [TRAIN] LOSS : 0.05106224166229367 [SCORE] : 0.5607760190963745\n",
      "[858/1000]\n",
      "- [VAL] LOSS : 0.03635436296463013 [SCORE] : 1.0\n",
      "[859/1000]\n",
      "- [TRAIN] LOSS : 0.05105980436007182 [SCORE] : 0.5607760190963745\n",
      "[859/1000]\n",
      "- [VAL] LOSS : 0.036350078880786896 [SCORE] : 1.0\n",
      "[860/1000]\n",
      "- [TRAIN] LOSS : 0.051057407166808844 [SCORE] : 0.5607760190963745\n",
      "[860/1000]\n",
      "- [VAL] LOSS : 0.03634580597281456 [SCORE] : 1.0\n",
      "[861/1000]\n",
      "- [TRAIN] LOSS : 0.05105504151433706 [SCORE] : 0.5607760190963745\n",
      "[861/1000]\n",
      "- [VAL] LOSS : 0.0363415963947773 [SCORE] : 1.0\n",
      "[862/1000]\n",
      "- [TRAIN] LOSS : 0.05105264619924128 [SCORE] : 0.5607760190963745\n",
      "[862/1000]\n",
      "- [VAL] LOSS : 0.03633735701441765 [SCORE] : 1.0\n",
      "[863/1000]\n",
      "- [TRAIN] LOSS : 0.051050212762008114 [SCORE] : 0.5607760190963745\n",
      "[863/1000]\n",
      "- [VAL] LOSS : 0.0363331101834774 [SCORE] : 1.0\n",
      "[864/1000]\n",
      "- [TRAIN] LOSS : 0.051047859837611516 [SCORE] : 0.5607760190963745\n",
      "[864/1000]\n",
      "- [VAL] LOSS : 0.03632892295718193 [SCORE] : 1.0\n",
      "[865/1000]\n",
      "- [TRAIN] LOSS : 0.05104544796049595 [SCORE] : 0.5607760190963745\n",
      "[865/1000]\n",
      "- [VAL] LOSS : 0.03632470220327377 [SCORE] : 1.0\n",
      "[866/1000]\n",
      "- [TRAIN] LOSS : 0.05104306850892802 [SCORE] : 0.5607760190963745\n",
      "[866/1000]\n",
      "- [VAL] LOSS : 0.036320507526397705 [SCORE] : 1.0\n",
      "[867/1000]\n",
      "- [TRAIN] LOSS : 0.05104070402060946 [SCORE] : 0.5607760190963745\n",
      "[867/1000]\n",
      "- [VAL] LOSS : 0.03631633147597313 [SCORE] : 1.0\n",
      "[868/1000]\n",
      "- [TRAIN] LOSS : 0.051038336691757044 [SCORE] : 0.5607760190963745\n",
      "[868/1000]\n",
      "- [VAL] LOSS : 0.03631216660141945 [SCORE] : 1.0\n",
      "[869/1000]\n",
      "- [TRAIN] LOSS : 0.05103598128383358 [SCORE] : 0.5607760190963745\n",
      "[869/1000]\n",
      "- [VAL] LOSS : 0.036308031529188156 [SCORE] : 1.0\n",
      "[870/1000]\n",
      "- [TRAIN] LOSS : 0.05103360430027048 [SCORE] : 0.5607760190963745\n",
      "[870/1000]\n",
      "- [VAL] LOSS : 0.03630387783050537 [SCORE] : 1.0\n",
      "[871/1000]\n",
      "- [TRAIN] LOSS : 0.051031235108772915 [SCORE] : 0.5607760190963745\n",
      "[871/1000]\n",
      "- [VAL] LOSS : 0.036299753934144974 [SCORE] : 1.0\n",
      "[872/1000]\n",
      "- [TRAIN] LOSS : 0.05102893514558673 [SCORE] : 0.5607760190963745\n",
      "[872/1000]\n",
      "- [VAL] LOSS : 0.03629562631249428 [SCORE] : 1.0\n",
      "[873/1000]\n",
      "- [TRAIN] LOSS : 0.051026583354299264 [SCORE] : 0.5607760190963745\n",
      "[873/1000]\n",
      "- [VAL] LOSS : 0.036291513592004776 [SCORE] : 1.0\n",
      "[874/1000]\n",
      "- [TRAIN] LOSS : 0.05102420668117702 [SCORE] : 0.5607760190963745\n",
      "[874/1000]\n",
      "- [VAL] LOSS : 0.03628741577267647 [SCORE] : 1.0\n",
      "[875/1000]\n",
      "- [TRAIN] LOSS : 0.05102186820780238 [SCORE] : 0.5607760190963745\n",
      "[875/1000]\n",
      "- [VAL] LOSS : 0.036283355206251144 [SCORE] : 1.0\n",
      "[876/1000]\n",
      "- [TRAIN] LOSS : 0.05101956194266677 [SCORE] : 0.5607760190963745\n",
      "[876/1000]\n",
      "- [VAL] LOSS : 0.03627932816743851 [SCORE] : 1.0\n",
      "[877/1000]\n",
      "- [TRAIN] LOSS : 0.05101724703175326 [SCORE] : 0.5607760190963745\n",
      "[877/1000]\n",
      "- [VAL] LOSS : 0.03627524897456169 [SCORE] : 1.0\n",
      "[878/1000]\n",
      "- [TRAIN] LOSS : 0.051014912718286114 [SCORE] : 0.5607760190963745\n",
      "[878/1000]\n",
      "- [VAL] LOSS : 0.036271192133426666 [SCORE] : 1.0\n",
      "[879/1000]\n",
      "- [TRAIN] LOSS : 0.05101258375992378 [SCORE] : 0.5607760190963745\n",
      "[879/1000]\n",
      "- [VAL] LOSS : 0.03626715764403343 [SCORE] : 1.0\n",
      "[880/1000]\n",
      "- [TRAIN] LOSS : 0.051010277153303224 [SCORE] : 0.5607760190963745\n",
      "[880/1000]\n",
      "- [VAL] LOSS : 0.03626318648457527 [SCORE] : 1.0\n",
      "[881/1000]\n",
      "- [TRAIN] LOSS : 0.051007948955520986 [SCORE] : 0.5607760190963745\n",
      "[881/1000]\n",
      "- [VAL] LOSS : 0.03625916317105293 [SCORE] : 1.0\n",
      "[882/1000]\n",
      "- [TRAIN] LOSS : 0.05100568104535341 [SCORE] : 0.5607760190963745\n",
      "[882/1000]\n",
      "- [VAL] LOSS : 0.036255162209272385 [SCORE] : 1.0\n",
      "[883/1000]\n",
      "- [TRAIN] LOSS : 0.05100334572295348 [SCORE] : 0.5607760190963745\n",
      "[883/1000]\n",
      "- [VAL] LOSS : 0.03625119850039482 [SCORE] : 1.0\n",
      "[884/1000]\n",
      "- [TRAIN] LOSS : 0.051001044393827515 [SCORE] : 0.5607760190963745\n",
      "[884/1000]\n",
      "- [VAL] LOSS : 0.03624716401100159 [SCORE] : 1.0\n",
      "[885/1000]\n",
      "- [TRAIN] LOSS : 0.05099902246147394 [SCORE] : 0.5607760190963745\n",
      "[885/1000]\n",
      "- [VAL] LOSS : 0.036243367940187454 [SCORE] : 1.0\n",
      "[886/1000]\n",
      "- [TRAIN] LOSS : 0.05099671138450503 [SCORE] : 0.5607760190963745\n",
      "[886/1000]\n",
      "- [VAL] LOSS : 0.036239586770534515 [SCORE] : 1.0\n",
      "[887/1000]\n",
      "- [TRAIN] LOSS : 0.050994315464049575 [SCORE] : 0.5607760190963745\n",
      "[887/1000]\n",
      "- [VAL] LOSS : 0.03623571991920471 [SCORE] : 1.0\n",
      "[888/1000]\n",
      "- [TRAIN] LOSS : 0.050991980157171685 [SCORE] : 0.5607760190963745\n",
      "[888/1000]\n",
      "- [VAL] LOSS : 0.03623178228735924 [SCORE] : 1.0\n",
      "[889/1000]\n",
      "- [TRAIN] LOSS : 0.050989678610737124 [SCORE] : 0.5607760190963745\n",
      "[889/1000]\n",
      "- [VAL] LOSS : 0.03622784838080406 [SCORE] : 1.0\n",
      "[890/1000]\n",
      "- [TRAIN] LOSS : 0.05098743631194035 [SCORE] : 0.5607760190963745\n",
      "[890/1000]\n",
      "- [VAL] LOSS : 0.036223944276571274 [SCORE] : 1.0\n",
      "[891/1000]\n",
      "- [TRAIN] LOSS : 0.0509852163027972 [SCORE] : 0.5607760190963745\n",
      "[891/1000]\n",
      "- [VAL] LOSS : 0.03622005134820938 [SCORE] : 1.0\n",
      "[892/1000]\n",
      "- [TRAIN] LOSS : 0.05098294561418394 [SCORE] : 0.5607760190963745\n",
      "[892/1000]\n",
      "- [VAL] LOSS : 0.03621620684862137 [SCORE] : 1.0\n",
      "[893/1000]\n",
      "- [TRAIN] LOSS : 0.05098070842213929 [SCORE] : 0.5607760190963745\n",
      "[893/1000]\n",
      "- [VAL] LOSS : 0.03621235489845276 [SCORE] : 1.0\n",
      "[894/1000]\n",
      "- [TRAIN] LOSS : 0.050978498191883166 [SCORE] : 0.5607760190963745\n",
      "[894/1000]\n",
      "- [VAL] LOSS : 0.03620849922299385 [SCORE] : 1.0\n",
      "[895/1000]\n",
      "- [TRAIN] LOSS : 0.05097621654470762 [SCORE] : 0.5607760190963745\n",
      "[895/1000]\n",
      "- [VAL] LOSS : 0.03620464354753494 [SCORE] : 1.0\n",
      "[896/1000]\n",
      "- [TRAIN] LOSS : 0.05097395222013195 [SCORE] : 0.5607760190963745\n",
      "[896/1000]\n",
      "- [VAL] LOSS : 0.03620078042149544 [SCORE] : 1.0\n",
      "[897/1000]\n",
      "- [TRAIN] LOSS : 0.050971736758947374 [SCORE] : 0.5607760190963745\n",
      "[897/1000]\n",
      "- [VAL] LOSS : 0.036196984350681305 [SCORE] : 1.0\n",
      "[898/1000]\n",
      "- [TRAIN] LOSS : 0.050969508445511263 [SCORE] : 0.5607760190963745\n",
      "[898/1000]\n",
      "- [VAL] LOSS : 0.036193158477544785 [SCORE] : 1.0\n",
      "[899/1000]\n",
      "- [TRAIN] LOSS : 0.05096729377595087 [SCORE] : 0.5607760190963745\n",
      "[899/1000]\n",
      "- [VAL] LOSS : 0.03618937358260155 [SCORE] : 1.0\n",
      "[900/1000]\n",
      "- [TRAIN] LOSS : 0.05096506988629699 [SCORE] : 0.5607760190963745\n",
      "[900/1000]\n",
      "- [VAL] LOSS : 0.03618558123707771 [SCORE] : 1.0\n",
      "[901/1000]\n",
      "- [TRAIN] LOSS : 0.05096282830151419 [SCORE] : 0.5607760190963745\n",
      "[901/1000]\n",
      "- [VAL] LOSS : 0.03618180379271507 [SCORE] : 1.0\n",
      "[902/1000]\n",
      "- [TRAIN] LOSS : 0.05096062016673386 [SCORE] : 0.5607760190963745\n",
      "[902/1000]\n",
      "- [VAL] LOSS : 0.03617803379893303 [SCORE] : 1.0\n",
      "[903/1000]\n",
      "- [TRAIN] LOSS : 0.05095842697968086 [SCORE] : 0.5607760190963745\n",
      "[903/1000]\n",
      "- [VAL] LOSS : 0.03617430850863457 [SCORE] : 1.0\n",
      "[904/1000]\n",
      "- [TRAIN] LOSS : 0.050956255213047065 [SCORE] : 0.5607760190963745\n",
      "[904/1000]\n",
      "- [VAL] LOSS : 0.03617066890001297 [SCORE] : 1.0\n",
      "[905/1000]\n",
      "- [TRAIN] LOSS : 0.05095395216097434 [SCORE] : 0.5607760190963745\n",
      "[905/1000]\n",
      "- [VAL] LOSS : 0.03616691008210182 [SCORE] : 1.0\n",
      "[906/1000]\n",
      "- [TRAIN] LOSS : 0.05095183731367191 [SCORE] : 0.5607760190963745\n",
      "[906/1000]\n",
      "- [VAL] LOSS : 0.036163244396448135 [SCORE] : 1.0\n",
      "[907/1000]\n",
      "- [TRAIN] LOSS : 0.05094959023408592 [SCORE] : 0.5607760190963745\n",
      "[907/1000]\n",
      "- [VAL] LOSS : 0.03615947440266609 [SCORE] : 1.0\n",
      "[908/1000]\n",
      "- [TRAIN] LOSS : 0.05094740277466674 [SCORE] : 0.5607760190963745\n",
      "[908/1000]\n",
      "- [VAL] LOSS : 0.03615577146410942 [SCORE] : 1.0\n",
      "[909/1000]\n",
      "- [TRAIN] LOSS : 0.05094528940195839 [SCORE] : 0.5607760190963745\n",
      "[909/1000]\n",
      "- [VAL] LOSS : 0.03615214675664902 [SCORE] : 1.0\n",
      "[910/1000]\n",
      "- [TRAIN] LOSS : 0.05094305224095782 [SCORE] : 0.5607760190963745\n",
      "[910/1000]\n",
      "- [VAL] LOSS : 0.03614843636751175 [SCORE] : 1.0\n",
      "[911/1000]\n",
      "- [TRAIN] LOSS : 0.05094094361799459 [SCORE] : 0.5607760190963745\n",
      "[911/1000]\n",
      "- [VAL] LOSS : 0.03614483401179314 [SCORE] : 1.0\n",
      "[912/1000]\n",
      "- [TRAIN] LOSS : 0.050938692331934966 [SCORE] : 0.5607760190963745\n",
      "[912/1000]\n",
      "- [VAL] LOSS : 0.036141183227300644 [SCORE] : 1.0\n",
      "[913/1000]\n",
      "- [TRAIN] LOSS : 0.050936550041660665 [SCORE] : 0.5607760190963745\n",
      "[913/1000]\n",
      "- [VAL] LOSS : 0.036137502640485764 [SCORE] : 1.0\n",
      "[914/1000]\n",
      "- [TRAIN] LOSS : 0.050934459238002695 [SCORE] : 0.5607760190963745\n",
      "[914/1000]\n",
      "- [VAL] LOSS : 0.036133915185928345 [SCORE] : 1.0\n",
      "[915/1000]\n",
      "- [TRAIN] LOSS : 0.05093226376920938 [SCORE] : 0.5607760190963745\n",
      "[915/1000]\n",
      "- [VAL] LOSS : 0.03613036870956421 [SCORE] : 1.0\n",
      "[916/1000]\n",
      "- [TRAIN] LOSS : 0.05093004610389471 [SCORE] : 0.5607760190963745\n",
      "[916/1000]\n",
      "- [VAL] LOSS : 0.03612669184803963 [SCORE] : 1.0\n",
      "[917/1000]\n",
      "- [TRAIN] LOSS : 0.05092788899006943 [SCORE] : 0.5607760190963745\n",
      "[917/1000]\n",
      "- [VAL] LOSS : 0.03612304851412773 [SCORE] : 1.0\n",
      "[918/1000]\n",
      "- [TRAIN] LOSS : 0.05092584751546383 [SCORE] : 0.5607760190963745\n",
      "[918/1000]\n",
      "- [VAL] LOSS : 0.0361194983124733 [SCORE] : 1.0\n",
      "[919/1000]\n",
      "- [TRAIN] LOSS : 0.05092364434773723 [SCORE] : 0.5607760190963745\n",
      "[919/1000]\n",
      "- [VAL] LOSS : 0.03611590713262558 [SCORE] : 1.0\n",
      "[920/1000]\n",
      "- [TRAIN] LOSS : 0.05092155085876584 [SCORE] : 0.5607760190963745\n",
      "[920/1000]\n",
      "- [VAL] LOSS : 0.03611236438155174 [SCORE] : 1.0\n",
      "[921/1000]\n",
      "- [TRAIN] LOSS : 0.05091934381052852 [SCORE] : 0.5607760190963745\n",
      "[921/1000]\n",
      "- [VAL] LOSS : 0.03610879182815552 [SCORE] : 1.0\n",
      "[922/1000]\n",
      "- [TRAIN] LOSS : 0.050917295087128875 [SCORE] : 0.5607760190963745\n",
      "[922/1000]\n",
      "- [VAL] LOSS : 0.036105282604694366 [SCORE] : 1.0\n",
      "[923/1000]\n",
      "- [TRAIN] LOSS : 0.05091508398763835 [SCORE] : 0.5607760190963745\n",
      "[923/1000]\n",
      "- [VAL] LOSS : 0.03610169515013695 [SCORE] : 1.0\n",
      "[924/1000]\n",
      "- [TRAIN] LOSS : 0.050913054527093965 [SCORE] : 0.5607760190963745\n",
      "[924/1000]\n",
      "- [VAL] LOSS : 0.036098238080739975 [SCORE] : 1.0\n",
      "[925/1000]\n",
      "- [TRAIN] LOSS : 0.050910834999134146 [SCORE] : 0.5607760190963745\n",
      "[925/1000]\n",
      "- [VAL] LOSS : 0.03609466180205345 [SCORE] : 1.0\n",
      "[926/1000]\n",
      "- [TRAIN] LOSS : 0.05090879068399469 [SCORE] : 0.5607760190963745\n",
      "[926/1000]\n",
      "- [VAL] LOSS : 0.0360911525785923 [SCORE] : 1.0\n",
      "[927/1000]\n",
      "- [TRAIN] LOSS : 0.05090665609265367 [SCORE] : 0.5607760190963745\n",
      "[927/1000]\n",
      "- [VAL] LOSS : 0.03608763962984085 [SCORE] : 1.0\n",
      "[928/1000]\n",
      "- [TRAIN] LOSS : 0.05090460280577342 [SCORE] : 0.5607760190963745\n",
      "[928/1000]\n",
      "- [VAL] LOSS : 0.03608420118689537 [SCORE] : 1.0\n",
      "[929/1000]\n",
      "- [TRAIN] LOSS : 0.05090247516830762 [SCORE] : 0.5607760190963745\n",
      "[929/1000]\n",
      "- [VAL] LOSS : 0.036080773919820786 [SCORE] : 1.0\n",
      "[930/1000]\n",
      "- [TRAIN] LOSS : 0.05090026939287782 [SCORE] : 0.5607760190963745\n",
      "[930/1000]\n",
      "- [VAL] LOSS : 0.03607723489403725 [SCORE] : 1.0\n",
      "[931/1000]\n",
      "- [TRAIN] LOSS : 0.05089821804625293 [SCORE] : 0.5607760190963745\n",
      "[931/1000]\n",
      "- [VAL] LOSS : 0.036073725670576096 [SCORE] : 1.0\n",
      "[932/1000]\n",
      "- [TRAIN] LOSS : 0.05089625966114302 [SCORE] : 0.5607760190963745\n",
      "[932/1000]\n",
      "- [VAL] LOSS : 0.036070339381694794 [SCORE] : 1.0\n",
      "[933/1000]\n",
      "- [TRAIN] LOSS : 0.05089412955567241 [SCORE] : 0.5607760190963745\n",
      "[933/1000]\n",
      "- [VAL] LOSS : 0.036066923290491104 [SCORE] : 1.0\n",
      "[934/1000]\n",
      "- [TRAIN] LOSS : 0.05089193315555652 [SCORE] : 0.5607760190963745\n",
      "[934/1000]\n",
      "- [VAL] LOSS : 0.036063432693481445 [SCORE] : 1.0\n",
      "[935/1000]\n",
      "- [TRAIN] LOSS : 0.05088994059090813 [SCORE] : 0.5607760190963745\n",
      "[935/1000]\n",
      "- [VAL] LOSS : 0.03606007620692253 [SCORE] : 1.0\n",
      "[936/1000]\n",
      "- [TRAIN] LOSS : 0.05088781644590199 [SCORE] : 0.5607760190963745\n",
      "[936/1000]\n",
      "- [VAL] LOSS : 0.03605658933520317 [SCORE] : 1.0\n",
      "[937/1000]\n",
      "- [TRAIN] LOSS : 0.05088580382677416 [SCORE] : 0.5607760190963745\n",
      "[937/1000]\n",
      "- [VAL] LOSS : 0.03605327010154724 [SCORE] : 1.0\n",
      "[938/1000]\n",
      "- [TRAIN] LOSS : 0.050883708009496334 [SCORE] : 0.5607760190963745\n",
      "[938/1000]\n",
      "- [VAL] LOSS : 0.03604989871382713 [SCORE] : 1.0\n",
      "[939/1000]\n",
      "- [TRAIN] LOSS : 0.05088158982495467 [SCORE] : 0.5607760190963745\n",
      "[939/1000]\n",
      "- [VAL] LOSS : 0.03604646399617195 [SCORE] : 1.0\n",
      "[940/1000]\n",
      "- [TRAIN] LOSS : 0.050879581334690255 [SCORE] : 0.5607760190963745\n",
      "[940/1000]\n",
      "- [VAL] LOSS : 0.036043088883161545 [SCORE] : 1.0\n",
      "[941/1000]\n",
      "- [TRAIN] LOSS : 0.05087747626627485 [SCORE] : 0.5607760190963745\n",
      "[941/1000]\n",
      "- [VAL] LOSS : 0.036039698868989944 [SCORE] : 1.0\n",
      "[942/1000]\n",
      "- [TRAIN] LOSS : 0.05087548686812322 [SCORE] : 0.5607760190963745\n",
      "[942/1000]\n",
      "- [VAL] LOSS : 0.03603634238243103 [SCORE] : 1.0\n",
      "[943/1000]\n",
      "- [TRAIN] LOSS : 0.05087344669736922 [SCORE] : 0.5607760190963745\n",
      "[943/1000]\n",
      "- [VAL] LOSS : 0.0360330231487751 [SCORE] : 1.0\n",
      "[944/1000]\n",
      "- [TRAIN] LOSS : 0.05087130606795351 [SCORE] : 0.5607760190963745\n",
      "[944/1000]\n",
      "- [VAL] LOSS : 0.0360296331346035 [SCORE] : 1.0\n",
      "[945/1000]\n",
      "- [TRAIN] LOSS : 0.050869317989175517 [SCORE] : 0.5607760190963745\n",
      "[945/1000]\n",
      "- [VAL] LOSS : 0.03602633252739906 [SCORE] : 1.0\n",
      "[946/1000]\n",
      "- [TRAIN] LOSS : 0.05086723786468307 [SCORE] : 0.5607760190963745\n",
      "[946/1000]\n",
      "- [VAL] LOSS : 0.03602294251322746 [SCORE] : 1.0\n",
      "[947/1000]\n",
      "- [TRAIN] LOSS : 0.050865301148345074 [SCORE] : 0.5607760190963745\n",
      "[947/1000]\n",
      "- [VAL] LOSS : 0.03601966053247452 [SCORE] : 1.0\n",
      "[948/1000]\n",
      "- [TRAIN] LOSS : 0.050863260853414735 [SCORE] : 0.5607760190963745\n",
      "[948/1000]\n",
      "- [VAL] LOSS : 0.036016374826431274 [SCORE] : 1.0\n",
      "[949/1000]\n",
      "- [TRAIN] LOSS : 0.050861122909312446 [SCORE] : 0.5607760190963745\n",
      "[949/1000]\n",
      "- [VAL] LOSS : 0.036013029515743256 [SCORE] : 1.0\n",
      "[950/1000]\n",
      "- [TRAIN] LOSS : 0.05085916672833264 [SCORE] : 0.5607760190963745\n",
      "[950/1000]\n",
      "- [VAL] LOSS : 0.0360097661614418 [SCORE] : 1.0\n",
      "[951/1000]\n",
      "- [TRAIN] LOSS : 0.05085716607669989 [SCORE] : 0.5607760190963745\n",
      "[951/1000]\n",
      "- [VAL] LOSS : 0.03600652888417244 [SCORE] : 1.0\n",
      "[952/1000]\n",
      "- [TRAIN] LOSS : 0.050855078579237066 [SCORE] : 0.5607760190963745\n",
      "[952/1000]\n",
      "- [VAL] LOSS : 0.036003198474645615 [SCORE] : 1.0\n",
      "[953/1000]\n",
      "- [TRAIN] LOSS : 0.0508530979976058 [SCORE] : 0.5607760190963745\n",
      "[953/1000]\n",
      "- [VAL] LOSS : 0.03599992021918297 [SCORE] : 1.0\n",
      "[954/1000]\n",
      "- [TRAIN] LOSS : 0.050851113985603054 [SCORE] : 0.5607760190963745\n",
      "[954/1000]\n",
      "- [VAL] LOSS : 0.03599671646952629 [SCORE] : 1.0\n",
      "[955/1000]\n",
      "- [TRAIN] LOSS : 0.0508490229335924 [SCORE] : 0.5607760190963745\n",
      "[955/1000]\n",
      "- [VAL] LOSS : 0.03599340468645096 [SCORE] : 1.0\n",
      "[956/1000]\n",
      "- [TRAIN] LOSS : 0.05084710566637417 [SCORE] : 0.5607760190963745\n",
      "[956/1000]\n",
      "- [VAL] LOSS : 0.03599023446440697 [SCORE] : 1.0\n",
      "[957/1000]\n",
      "- [TRAIN] LOSS : 0.050845107932885485 [SCORE] : 0.5607760190963745\n",
      "[957/1000]\n",
      "- [VAL] LOSS : 0.03598698601126671 [SCORE] : 1.0\n",
      "[958/1000]\n",
      "- [TRAIN] LOSS : 0.0508430190384388 [SCORE] : 0.5607760190963745\n",
      "[958/1000]\n",
      "- [VAL] LOSS : 0.03598374128341675 [SCORE] : 1.0\n",
      "[959/1000]\n",
      "- [TRAIN] LOSS : 0.0508410918371131 [SCORE] : 0.5607760190963745\n",
      "[959/1000]\n",
      "- [VAL] LOSS : 0.035980500280857086 [SCORE] : 1.0\n",
      "[960/1000]\n",
      "- [TRAIN] LOSS : 0.0508391337779661 [SCORE] : 0.5607760190963745\n",
      "[960/1000]\n",
      "- [VAL] LOSS : 0.035977382212877274 [SCORE] : 1.0\n",
      "[961/1000]\n",
      "- [TRAIN] LOSS : 0.05083706970326603 [SCORE] : 0.5607760190963745\n",
      "[961/1000]\n",
      "- [VAL] LOSS : 0.03597412258386612 [SCORE] : 1.0\n",
      "[962/1000]\n",
      "- [TRAIN] LOSS : 0.05083513522210221 [SCORE] : 0.5607760190963745\n",
      "[962/1000]\n",
      "- [VAL] LOSS : 0.03597095608711243 [SCORE] : 1.0\n",
      "[963/1000]\n",
      "- [TRAIN] LOSS : 0.05083317323587835 [SCORE] : 0.5607760190963745\n",
      "[963/1000]\n",
      "- [VAL] LOSS : 0.03596777468919754 [SCORE] : 1.0\n",
      "[964/1000]\n",
      "- [TRAIN] LOSS : 0.050831165025010706 [SCORE] : 0.5607760190963745\n",
      "[964/1000]\n",
      "- [VAL] LOSS : 0.03596466779708862 [SCORE] : 1.0\n",
      "[965/1000]\n",
      "- [TRAIN] LOSS : 0.05082912850193679 [SCORE] : 0.5607760190963745\n",
      "[965/1000]\n",
      "- [VAL] LOSS : 0.03596142679452896 [SCORE] : 1.0\n",
      "[966/1000]\n",
      "- [TRAIN] LOSS : 0.05082725683848063 [SCORE] : 0.5607760190963745\n",
      "[966/1000]\n",
      "- [VAL] LOSS : 0.035958290100097656 [SCORE] : 1.0\n",
      "[967/1000]\n",
      "- [TRAIN] LOSS : 0.050825275992974636 [SCORE] : 0.5607760190963745\n",
      "[967/1000]\n",
      "- [VAL] LOSS : 0.035955172032117844 [SCORE] : 1.0\n",
      "[968/1000]\n",
      "- [TRAIN] LOSS : 0.05082324820881089 [SCORE] : 0.5607760190963745\n",
      "[968/1000]\n",
      "- [VAL] LOSS : 0.03595196455717087 [SCORE] : 1.0\n",
      "[969/1000]\n",
      "- [TRAIN] LOSS : 0.05082136687512199 [SCORE] : 0.5607760190963745\n",
      "[969/1000]\n",
      "- [VAL] LOSS : 0.03594889119267464 [SCORE] : 1.0\n",
      "[970/1000]\n",
      "- [TRAIN] LOSS : 0.05081942581261198 [SCORE] : 0.5607760190963745\n",
      "[970/1000]\n",
      "- [VAL] LOSS : 0.03594573214650154 [SCORE] : 1.0\n",
      "[971/1000]\n",
      "- [TRAIN] LOSS : 0.0508174653009822 [SCORE] : 0.5607760190963745\n",
      "[971/1000]\n",
      "- [VAL] LOSS : 0.0359426774084568 [SCORE] : 1.0\n",
      "[972/1000]\n",
      "- [TRAIN] LOSS : 0.05081540841298799 [SCORE] : 0.5607760190963745\n",
      "[972/1000]\n",
      "- [VAL] LOSS : 0.035939522087574005 [SCORE] : 1.0\n",
      "[973/1000]\n",
      "- [TRAIN] LOSS : 0.0508135583717376 [SCORE] : 0.5607760190963745\n",
      "[973/1000]\n",
      "- [VAL] LOSS : 0.03593641519546509 [SCORE] : 1.0\n",
      "[974/1000]\n",
      "- [TRAIN] LOSS : 0.05081161819398403 [SCORE] : 0.5607760190963745\n",
      "[974/1000]\n",
      "- [VAL] LOSS : 0.035933371633291245 [SCORE] : 1.0\n",
      "[975/1000]\n",
      "- [TRAIN] LOSS : 0.050809663037459055 [SCORE] : 0.5607760190963745\n",
      "[975/1000]\n",
      "- [VAL] LOSS : 0.03593031316995621 [SCORE] : 1.0\n",
      "[976/1000]\n",
      "- [TRAIN] LOSS : 0.050807642998794714 [SCORE] : 0.5607760190963745\n",
      "[976/1000]\n",
      "- [VAL] LOSS : 0.03592720627784729 [SCORE] : 1.0\n",
      "[977/1000]\n",
      "- [TRAIN] LOSS : 0.050805801541234055 [SCORE] : 0.5607760190963745\n",
      "[977/1000]\n",
      "- [VAL] LOSS : 0.03592413291335106 [SCORE] : 1.0\n",
      "[978/1000]\n",
      "- [TRAIN] LOSS : 0.05080387643538416 [SCORE] : 0.5607760190963745\n",
      "[978/1000]\n",
      "- [VAL] LOSS : 0.03592107817530632 [SCORE] : 1.0\n",
      "[979/1000]\n",
      "- [TRAIN] LOSS : 0.05080191362649202 [SCORE] : 0.5607760190963745\n",
      "[979/1000]\n",
      "- [VAL] LOSS : 0.03591805696487427 [SCORE] : 1.0\n",
      "[980/1000]\n",
      "- [TRAIN] LOSS : 0.0507999483961612 [SCORE] : 0.5607760190963745\n",
      "[980/1000]\n",
      "- [VAL] LOSS : 0.035914961248636246 [SCORE] : 1.0\n",
      "[981/1000]\n",
      "- [TRAIN] LOSS : 0.050798099146535 [SCORE] : 0.5607760190963745\n",
      "[981/1000]\n",
      "- [VAL] LOSS : 0.03591189160943031 [SCORE] : 1.0\n",
      "[982/1000]\n",
      "- [TRAIN] LOSS : 0.05079619497992098 [SCORE] : 0.5607760190963745\n",
      "[982/1000]\n",
      "- [VAL] LOSS : 0.03590891510248184 [SCORE] : 1.0\n",
      "[983/1000]\n",
      "- [TRAIN] LOSS : 0.050794243393465874 [SCORE] : 0.5607760190963745\n",
      "[983/1000]\n",
      "- [VAL] LOSS : 0.03590591996908188 [SCORE] : 1.0\n",
      "[984/1000]\n",
      "- [TRAIN] LOSS : 0.05079230590102573 [SCORE] : 0.5607760190963745\n",
      "[984/1000]\n",
      "- [VAL] LOSS : 0.03590290993452072 [SCORE] : 1.0\n",
      "[985/1000]\n",
      "- [TRAIN] LOSS : 0.05079033627795677 [SCORE] : 0.5607760190963745\n",
      "[985/1000]\n",
      "- [VAL] LOSS : 0.03589988872408867 [SCORE] : 1.0\n",
      "[986/1000]\n",
      "- [TRAIN] LOSS : 0.05078857772362729 [SCORE] : 0.5607760190963745\n",
      "[986/1000]\n",
      "- [VAL] LOSS : 0.03589686006307602 [SCORE] : 1.0\n",
      "[987/1000]\n",
      "- [TRAIN] LOSS : 0.0507866772202154 [SCORE] : 0.5607760190963745\n",
      "[987/1000]\n",
      "- [VAL] LOSS : 0.03589388728141785 [SCORE] : 1.0\n",
      "[988/1000]\n",
      "- [TRAIN] LOSS : 0.05078473609561721 [SCORE] : 0.5607760190963745\n",
      "[988/1000]\n",
      "- [VAL] LOSS : 0.03589098900556564 [SCORE] : 1.0\n",
      "[989/1000]\n",
      "- [TRAIN] LOSS : 0.050782779200623435 [SCORE] : 0.5607760190963745\n",
      "[989/1000]\n",
      "- [VAL] LOSS : 0.03588791936635971 [SCORE] : 1.0\n",
      "[990/1000]\n",
      "- [TRAIN] LOSS : 0.0507809734903276 [SCORE] : 0.5607760190963745\n",
      "[990/1000]\n",
      "- [VAL] LOSS : 0.03588494285941124 [SCORE] : 1.0\n",
      "[991/1000]\n",
      "- [TRAIN] LOSS : 0.050779114663600924 [SCORE] : 0.5607760190963745\n",
      "[991/1000]\n",
      "- [VAL] LOSS : 0.03588200360536575 [SCORE] : 1.0\n",
      "[992/1000]\n",
      "- [TRAIN] LOSS : 0.050777180151393014 [SCORE] : 0.5607760190963745\n",
      "[992/1000]\n",
      "- [VAL] LOSS : 0.035879068076610565 [SCORE] : 1.0\n",
      "[993/1000]\n",
      "- [TRAIN] LOSS : 0.05077527595373491 [SCORE] : 0.5607760190963745\n",
      "[993/1000]\n",
      "- [VAL] LOSS : 0.035876158624887466 [SCORE] : 1.0\n",
      "[994/1000]\n",
      "- [TRAIN] LOSS : 0.05077332264433305 [SCORE] : 0.5607760190963745\n",
      "[994/1000]\n",
      "- [VAL] LOSS : 0.03587315231561661 [SCORE] : 1.0\n",
      "[995/1000]\n",
      "- [TRAIN] LOSS : 0.0507715898565948 [SCORE] : 0.5607760190963745\n",
      "[995/1000]\n",
      "- [VAL] LOSS : 0.035870250314474106 [SCORE] : 1.0\n",
      "[996/1000]\n",
      "- [TRAIN] LOSS : 0.05076968447926144 [SCORE] : 0.5607760190963745\n",
      "[996/1000]\n",
      "- [VAL] LOSS : 0.03586731106042862 [SCORE] : 1.0\n",
      "[997/1000]\n",
      "- [TRAIN] LOSS : 0.05076778139919043 [SCORE] : 0.5607760190963745\n",
      "[997/1000]\n",
      "- [VAL] LOSS : 0.035864442586898804 [SCORE] : 1.0\n",
      "[998/1000]\n",
      "- [TRAIN] LOSS : 0.050765884046753244 [SCORE] : 0.5607760190963745\n",
      "[998/1000]\n",
      "- [VAL] LOSS : 0.03586151823401451 [SCORE] : 1.0\n",
      "[999/1000]\n",
      "- [TRAIN] LOSS : 0.050764075480401516 [SCORE] : 0.5607760190963745\n",
      "[999/1000]\n",
      "- [VAL] LOSS : 0.035858578979969025 [SCORE] : 1.0\n",
      "[1000/1000]\n",
      "- [TRAIN] LOSS : 0.05076224538497627 [SCORE] : 0.5607760190963745\n",
      "[1000/1000]\n",
      "- [VAL] LOSS : 0.035855721682310104 [SCORE] : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습의 효과 확인 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTROY=[[],[]], [[],[]]\n",
    "\n",
    "for epoch in range(1,EPOCH+1):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "    # 배치크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0, 0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산 : nn.CrossEntropyLoss 요구사항 : 정답/타겟은 0D 또는 1D, 타입은 long\n",
    "        loss=crossLoss(pre_y, targetTS.reshape(-1).long())\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능평가 계산\n",
    "        score=MulticlassF1Score(num_classes=3)(pre_y, targetTS.reshape(-1))\n",
    "        score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "        # 추론/평가\n",
    "        pre_val=model(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=crossLoss(pre_val, val_targetTS.reshape(-1).long())\n",
    "\n",
    "        # 성능평가\n",
    "        score_val=MulticlassF1Score(num_classes=3)(pre_val, val_targetTS.reshape(-1))\n",
    "    \n",
    "    # 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/BATCH_CNT)\n",
    "    SCORE_HISTROY[0].append(score_total/BATCH_CNT)\n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTROY[1].append(score_val)\n",
    "\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [TRAIN] LOSS : {LOSS_HISTORY[0][-1]} [SCORE] : {SCORE_HISTROY[0][-1]}')\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [VAL] LOSS : {LOSS_HISTORY[1][-1]} [SCORE] : {SCORE_HISTROY[1][-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습결과 체크 => 학습과 검증의 Loss 변화, 성능 변화 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 15.6163,  -3.4228, -21.1802],\n",
      "        [ -4.2448,   3.4137,  -5.1100],\n",
      "        [ -7.6574,   3.3994,  -3.1550],\n",
      "        [ 13.6484,  -2.6841, -19.0557],\n",
      "        [-10.5730,  -0.4619,   1.5384],\n",
      "        [ -8.0491,   1.9777,  -1.4329],\n",
      "        [ -9.6717,  -1.3541,   2.6089],\n",
      "        [ 10.6162,  -1.4338, -16.6660],\n",
      "        [ 10.7275,  -1.3010, -16.3484],\n",
      "        [-10.2335,  -2.6209,   4.1451],\n",
      "        [ -7.1453,   2.2379,  -1.7554],\n",
      "        [ 12.1558,  -2.0151, -18.0375],\n",
      "        [-10.2762,  -2.3715,   3.8441],\n",
      "        [ -7.7720,   2.8312,  -2.4670],\n",
      "        [ -7.7666,   1.6648,  -1.0572],\n",
      "        [ 11.1193,  -1.7015, -16.3767],\n",
      "        [ -6.8959,   3.2399,  -2.9688],\n",
      "        [ -7.6203,   1.2616,  -0.5711],\n",
      "        [ 11.6273,  -1.8348, -17.4159],\n",
      "        [ 12.5349,  -2.2381, -17.8967],\n",
      "        [ -7.2106,   1.8227,  -1.2529],\n",
      "        [ -7.5648,   0.9646,  -0.2126],\n",
      "        [ -8.7054,   0.8606,  -0.0767],\n",
      "        [ 12.4668,  -2.2051, -17.8347],\n",
      "        [ -9.9098,  -0.8546,   2.0072],\n",
      "        [ -7.0384,   2.8201,  -2.4602],\n",
      "        [ 14.8411,  -3.0486, -20.4720],\n",
      "        [ 12.6278,  -2.1516, -18.1844],\n",
      "        [ -7.6053,   2.3664,  -1.9067],\n",
      "        [ -9.0525,  -1.5072,   2.7885],\n",
      "        [ -7.7175,   2.1711,  -1.6696],\n",
      "        [-10.9239,  -2.7862,   4.3511],\n",
      "        [ -6.6350,   3.4049,  -3.1707],\n",
      "        [ -9.8538,  -3.0637,   4.6771],\n",
      "        [ -9.7813,  -3.0578,   4.6694],\n",
      "        [ 13.1526,  -2.2895, -18.8423],\n",
      "        [ -7.0594,   1.8121,  -1.2415],\n",
      "        [ 12.6780,  -2.1517, -18.2677]])\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증 모드 설정\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 검증 데이터셋\n",
    "    test_featureTS=torch.FloatTensor(testDS.featureDF.values)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values)\n",
    "\n",
    "    # 추론/평가\n",
    "    pre_val=model(test_featureTS)\n",
    "    print(pre_val)\n",
    "\n",
    "    # 손실\n",
    "    loss_test=crossLoss(pre_val, test_targetTS.reshape(-1).long())\n",
    "\n",
    "    # 성능평가\n",
    "    score_test=MulticlassF1Score(num_classes=3)(pre_val, test_targetTS.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
