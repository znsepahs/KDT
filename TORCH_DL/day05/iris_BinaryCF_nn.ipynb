{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN 기반 이진분류 모델 구현\n",
    "- 데이터셋 : iris.csv\n",
    "- Feature : 4개 Sepal_Length, Sepal_Width, Petal_Length, Petal_Width\n",
    "- Target : 1개 Setosa와 나머지\n",
    "- 학습-방법 : 지도학습 > 분류 > 이진분류\n",
    "- 알고리즘 : 인공신경망(ANN) => MLP, DNN : 은닉층이 많은 구성\n",
    "- 프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 관련 모듈 로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import F1Score, BinaryF1Score\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "from torchinfo import summary\n",
    "\n",
    "# Data 관련 모듈 로딩\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch V. 2.4.1\n",
      "Pandas V. 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크 => 사용자 정의 함수로 구현하기\n",
    "print(f'Pytorch V. {torch.__version__}')\n",
    "print(f'Pandas V. {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "DATA_FILE='../data/iris.csv'\n",
    "\n",
    "# CSV => DataFrame\n",
    "irisDF=pd.read_csv(DATA_FILE)\n",
    "\n",
    "# 데이터 확인\n",
    "irisDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Versicolor', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 변경 => 정수화, 클래스 3개 => 2개\n",
    "irisDF['variety'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDF['variety']=(irisDF['variety']=='Setosa')\n",
    "irisDF['variety']=irisDF['variety'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유값 : [1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        1\n",
       "1           4.9          3.0           1.4          0.2        1\n",
       "2           4.7          3.2           1.3          0.2        1\n",
       "3           4.6          3.1           1.5          0.2        1\n",
       "4           5.0          3.6           1.4          0.2        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'고유값 : {irisDF[\"variety\"].unique()}')\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의<hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론 목적 \n",
    "- 클래스이름 : IrisBCFModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개변수 : 층별 입출력 개수 고정하기때문에 필요 없음\n",
    "- 속성필드 : \n",
    "- 기능역할 : __init__() : 모델 구조, forward() : 순방향 학습 <= 오버라이딩\n",
    "- 클래스구조\n",
    "    * 입력층 : 입력  4개(피처)  출력 10개(퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개        출력 5개(퍼셉트론/뉴런 5개 존재)\n",
    "    * 출력층 : 입력  5개        출력 1개(퍼셉트론/뉴런 1개 존재 : 2진분류)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스형태 => nn.MESLoss, nn.ReLU => __init__() 메서드\n",
    "    * 함수형태 => torch.nn.fuctional 아래에 => forward() 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisBCFModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer=nn.Linear(4,10)\n",
    "        self.hd_layer=nn.Linear(10,5)\n",
    "        self.out_layer=nn.Linear(5,1)\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, x):\n",
    "        y=F.relu(self.in_layer(x))\n",
    "        y=F.relu(self.hd_layer(y))\n",
    "        return F.sigmoid(self.out_layer(y)) # 2진 분류 출력층은 시그모이드가 국룰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisBCFModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hd_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model=IrisBCFModel()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "IrisBCFModel                             [100, 1]                  --\n",
       "├─Linear: 1-1                            [100, 10]                 50\n",
       "├─Linear: 1-2                            [100, 5]                  55\n",
       "├─Linear: 1-3                            [100, 1]                  6\n",
       "==========================================================================================\n",
       "Total params: 111\n",
       "Trainable params: 111\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(100,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의<hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐개수 : 4개\n",
    "- 타겟개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드\n",
    "    * __init__(self) : 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * __len__(self) : 데이터의 개수 반환\n",
    "    * __getitem__(self, index) : 특정 인덱스의 피쳐와 타겟 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 넘파이를 텐서로\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3-1] 데이터셋 인스턴스 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF => (150, 4), targetDF => (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐, 타겟 추출\n",
    "featureDF, targetDF=irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1:]]\n",
    "print(f'featureDF => {featureDF.shape}, targetDF => {targetDF.shape}')\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n",
    "- 학습 횟수 : EPOCH <= 처음부터 끝까지 학습하는 단위\n",
    "- 배치 크기 : BATCH_SIZE <= 한번에 학습할 데이터셋 양\n",
    "- 위치 지정 : DEVICE <= 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학습률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 진행 관련 설정\n",
    "EPOCH=1000\n",
    "BATCH_SIZE=10\n",
    "BATCH_CNT=irisDF.shape[0]/BATCH_SIZE\n",
    "DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화 (+ 손실함수, 성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 4) (38, 4) (28, 4)\n",
      "(84, 1) (38, 1) (28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스\n",
    "model=IrisBCFModel()\n",
    "\n",
    "# 데이터셋 인스턴스\n",
    "\n",
    "# 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_test, y_train, y_test=train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'{X_train.shape} {X_test.shape} {X_val.shape}')\n",
    "print(f'{y_train.shape} {y_test.shape} {y_val.shape}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터로드 인스턴스\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화, 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W, b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 이진분류 BinaryCrossEntropyLoss => BCELoss\n",
    "#                            예측값은 확률값으로 전달 => sigmoid() AF 처리 후 전달\n",
    "regLoss=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDL), trainDL.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000]\n",
      "- [TRAIN] LOSS : 0.4438331961631775 [SCORE] : 0.26263071099917096\n",
      "[1/1000]\n",
      "- [VAL] LOSS : 0.7040457129478455 [SCORE] : 0.6000000238418579\n",
      "[2/1000]\n",
      "- [TRAIN] LOSS : 0.4339338819185893 [SCORE] : 0.26263071099917096\n",
      "[2/1000]\n",
      "- [VAL] LOSS : 0.6923796534538269 [SCORE] : 0.6000000238418579\n",
      "[3/1000]\n",
      "- [TRAIN] LOSS : 0.4233763337135315 [SCORE] : 0.26263071099917096\n",
      "[3/1000]\n",
      "- [VAL] LOSS : 0.6807275414466858 [SCORE] : 0.6000000238418579\n",
      "[4/1000]\n",
      "- [TRAIN] LOSS : 0.41240705251693727 [SCORE] : 0.29925408562024436\n",
      "[4/1000]\n",
      "- [VAL] LOSS : 0.6689311265945435 [SCORE] : 0.8571428656578064\n",
      "[5/1000]\n",
      "- [TRAIN] LOSS : 0.4009498953819275 [SCORE] : 0.47022607127825417\n",
      "[5/1000]\n",
      "- [VAL] LOSS : 0.6569541096687317 [SCORE] : 0.9599999785423279\n",
      "[6/1000]\n",
      "- [TRAIN] LOSS : 0.38907274007797243 [SCORE] : 0.5365079402923584\n",
      "[6/1000]\n",
      "- [VAL] LOSS : 0.6450248956680298 [SCORE] : 0.5882353186607361\n",
      "[7/1000]\n",
      "- [TRAIN] LOSS : 0.37694911162058514 [SCORE] : 0.10666666825612386\n",
      "[7/1000]\n",
      "- [VAL] LOSS : 0.6334837079048157 [SCORE] : 0.0\n",
      "[8/1000]\n",
      "- [TRAIN] LOSS : 0.364822252591451 [SCORE] : 0.0\n",
      "[8/1000]\n",
      "- [VAL] LOSS : 0.6227089762687683 [SCORE] : 0.0\n",
      "[9/1000]\n",
      "- [TRAIN] LOSS : 0.35298696756362913 [SCORE] : 0.0\n",
      "[9/1000]\n",
      "- [VAL] LOSS : 0.6130824089050293 [SCORE] : 0.0\n",
      "[10/1000]\n",
      "- [TRAIN] LOSS : 0.34175273180007937 [SCORE] : 0.0\n",
      "[10/1000]\n",
      "- [VAL] LOSS : 0.6049520373344421 [SCORE] : 0.0\n",
      "[11/1000]\n",
      "- [TRAIN] LOSS : 0.33140832583109536 [SCORE] : 0.0\n",
      "[11/1000]\n",
      "- [VAL] LOSS : 0.5984966158866882 [SCORE] : 0.0\n",
      "[12/1000]\n",
      "- [TRAIN] LOSS : 0.32217669288317363 [SCORE] : 0.0\n",
      "[12/1000]\n",
      "- [VAL] LOSS : 0.5937736630439758 [SCORE] : 0.0\n",
      "[13/1000]\n",
      "- [TRAIN] LOSS : 0.3141761759916941 [SCORE] : 0.0\n",
      "[13/1000]\n",
      "- [VAL] LOSS : 0.5906237959861755 [SCORE] : 0.0\n",
      "[14/1000]\n",
      "- [TRAIN] LOSS : 0.3074243108431498 [SCORE] : 0.0\n",
      "[14/1000]\n",
      "- [VAL] LOSS : 0.5887007713317871 [SCORE] : 0.0\n",
      "[15/1000]\n",
      "- [TRAIN] LOSS : 0.30181957681973776 [SCORE] : 0.0\n",
      "[15/1000]\n",
      "- [VAL] LOSS : 0.5875405669212341 [SCORE] : 0.0\n",
      "[16/1000]\n",
      "- [TRAIN] LOSS : 0.2971796731154124 [SCORE] : 0.0\n",
      "[16/1000]\n",
      "- [VAL] LOSS : 0.5866686105728149 [SCORE] : 0.0\n",
      "[17/1000]\n",
      "- [TRAIN] LOSS : 0.29328705271085104 [SCORE] : 0.0\n",
      "[17/1000]\n",
      "- [VAL] LOSS : 0.5856806635856628 [SCORE] : 0.0\n",
      "[18/1000]\n",
      "- [TRAIN] LOSS : 0.2899265170097351 [SCORE] : 0.0\n",
      "[18/1000]\n",
      "- [VAL] LOSS : 0.5842800140380859 [SCORE] : 0.0\n",
      "[19/1000]\n",
      "- [TRAIN] LOSS : 0.2869130512078603 [SCORE] : 0.0\n",
      "[19/1000]\n",
      "- [VAL] LOSS : 0.5822941660881042 [SCORE] : 0.0\n",
      "[20/1000]\n",
      "- [TRAIN] LOSS : 0.2841040015220642 [SCORE] : 0.0\n",
      "[20/1000]\n",
      "- [VAL] LOSS : 0.5796559453010559 [SCORE] : 0.0\n",
      "[21/1000]\n",
      "- [TRAIN] LOSS : 0.2813968141873678 [SCORE] : 0.0\n",
      "[21/1000]\n",
      "- [VAL] LOSS : 0.5763711333274841 [SCORE] : 0.0\n",
      "[22/1000]\n",
      "- [TRAIN] LOSS : 0.2787216524283091 [SCORE] : 0.0\n",
      "[22/1000]\n",
      "- [VAL] LOSS : 0.5724859833717346 [SCORE] : 0.0\n",
      "[23/1000]\n",
      "- [TRAIN] LOSS : 0.2760323345661163 [SCORE] : 0.0\n",
      "[23/1000]\n",
      "- [VAL] LOSS : 0.5680625438690186 [SCORE] : 0.0\n",
      "[24/1000]\n",
      "- [TRAIN] LOSS : 0.2732982913653056 [SCORE] : 0.0\n",
      "[24/1000]\n",
      "- [VAL] LOSS : 0.5631617307662964 [SCORE] : 0.0\n",
      "[25/1000]\n",
      "- [TRAIN] LOSS : 0.27049864331881207 [SCORE] : 0.0\n",
      "[25/1000]\n",
      "- [VAL] LOSS : 0.5578355193138123 [SCORE] : 0.0\n",
      "[26/1000]\n",
      "- [TRAIN] LOSS : 0.2676179846127828 [SCORE] : 0.0\n",
      "[26/1000]\n",
      "- [VAL] LOSS : 0.5521228313446045 [SCORE] : 0.0\n",
      "[27/1000]\n",
      "- [TRAIN] LOSS : 0.26464428901672366 [SCORE] : 0.0\n",
      "[27/1000]\n",
      "- [VAL] LOSS : 0.5460501313209534 [SCORE] : 0.0\n",
      "[28/1000]\n",
      "- [TRAIN] LOSS : 0.2615678389867147 [SCORE] : 0.0\n",
      "[28/1000]\n",
      "- [VAL] LOSS : 0.5396323800086975 [SCORE] : 0.0\n",
      "[29/1000]\n",
      "- [TRAIN] LOSS : 0.2583785315354665 [SCORE] : 0.0\n",
      "[29/1000]\n",
      "- [VAL] LOSS : 0.5328746438026428 [SCORE] : 0.0\n",
      "[30/1000]\n",
      "- [TRAIN] LOSS : 0.25506918827692665 [SCORE] : 0.0\n",
      "[30/1000]\n",
      "- [VAL] LOSS : 0.5257896184921265 [SCORE] : 0.0\n",
      "[31/1000]\n",
      "- [TRAIN] LOSS : 0.25163347919782003 [SCORE] : 0.0\n",
      "[31/1000]\n",
      "- [VAL] LOSS : 0.51836758852005 [SCORE] : 0.0\n",
      "[32/1000]\n",
      "- [TRAIN] LOSS : 0.24806579152743022 [SCORE] : 0.0\n",
      "[32/1000]\n",
      "- [VAL] LOSS : 0.5105963349342346 [SCORE] : 0.0\n",
      "[33/1000]\n",
      "- [TRAIN] LOSS : 0.24435829619566599 [SCORE] : 0.0\n",
      "[33/1000]\n",
      "- [VAL] LOSS : 0.5024672150611877 [SCORE] : 0.0\n",
      "[34/1000]\n",
      "- [TRAIN] LOSS : 0.24052223563194275 [SCORE] : 0.0\n",
      "[34/1000]\n",
      "- [VAL] LOSS : 0.49398714303970337 [SCORE] : 0.0\n",
      "[35/1000]\n",
      "- [TRAIN] LOSS : 0.2365472028652827 [SCORE] : 0.0\n",
      "[35/1000]\n",
      "- [VAL] LOSS : 0.48513931035995483 [SCORE] : 0.0\n",
      "[36/1000]\n",
      "- [TRAIN] LOSS : 0.23242011268933613 [SCORE] : 0.0\n",
      "[36/1000]\n",
      "- [VAL] LOSS : 0.4759112000465393 [SCORE] : 0.0\n",
      "[37/1000]\n",
      "- [TRAIN] LOSS : 0.22813500861326855 [SCORE] : 0.0\n",
      "[37/1000]\n",
      "- [VAL] LOSS : 0.46628955006599426 [SCORE] : 0.0\n",
      "[38/1000]\n",
      "- [TRAIN] LOSS : 0.22368576526641845 [SCORE] : 0.0\n",
      "[38/1000]\n",
      "- [VAL] LOSS : 0.4563594460487366 [SCORE] : 0.0\n",
      "[39/1000]\n",
      "- [TRAIN] LOSS : 0.21906706988811492 [SCORE] : 0.0\n",
      "[39/1000]\n",
      "- [VAL] LOSS : 0.4464602470397949 [SCORE] : 0.0\n",
      "[40/1000]\n",
      "- [TRAIN] LOSS : 0.21429971754550933 [SCORE] : 0.0\n",
      "[40/1000]\n",
      "- [VAL] LOSS : 0.4362807273864746 [SCORE] : 0.0\n",
      "[41/1000]\n",
      "- [TRAIN] LOSS : 0.2095132271448771 [SCORE] : 0.0\n",
      "[41/1000]\n",
      "- [VAL] LOSS : 0.426173597574234 [SCORE] : 0.0\n",
      "[42/1000]\n",
      "- [TRAIN] LOSS : 0.20468354324499766 [SCORE] : 0.0\n",
      "[42/1000]\n",
      "- [VAL] LOSS : 0.4163486957550049 [SCORE] : 0.0\n",
      "[43/1000]\n",
      "- [TRAIN] LOSS : 0.19983135362466176 [SCORE] : 0.0\n",
      "[43/1000]\n",
      "- [VAL] LOSS : 0.40669217705726624 [SCORE] : 0.0\n",
      "[44/1000]\n",
      "- [TRAIN] LOSS : 0.19494124948978425 [SCORE] : 0.0\n",
      "[44/1000]\n",
      "- [VAL] LOSS : 0.39678338170051575 [SCORE] : 0.0\n",
      "[45/1000]\n",
      "- [TRAIN] LOSS : 0.18994780083497365 [SCORE] : 0.026666667064030966\n",
      "[45/1000]\n",
      "- [VAL] LOSS : 0.38671642541885376 [SCORE] : 0.1538461595773697\n",
      "[46/1000]\n",
      "- [TRAIN] LOSS : 0.18488150238990783 [SCORE] : 0.026666667064030966\n",
      "[46/1000]\n",
      "- [VAL] LOSS : 0.37641414999961853 [SCORE] : 0.1538461595773697\n",
      "[47/1000]\n",
      "- [TRAIN] LOSS : 0.17987227141857148 [SCORE] : 0.026666667064030966\n",
      "[47/1000]\n",
      "- [VAL] LOSS : 0.36618176102638245 [SCORE] : 0.1538461595773697\n",
      "[48/1000]\n",
      "- [TRAIN] LOSS : 0.1750214884678523 [SCORE] : 0.10888889034589132\n",
      "[48/1000]\n",
      "- [VAL] LOSS : 0.3563951551914215 [SCORE] : 0.5\n",
      "[49/1000]\n",
      "- [TRAIN] LOSS : 0.1702987492084503 [SCORE] : 0.30666667024294536\n",
      "[49/1000]\n",
      "- [VAL] LOSS : 0.34698477387428284 [SCORE] : 0.8571428656578064\n",
      "[50/1000]\n",
      "- [TRAIN] LOSS : 0.1656367301940918 [SCORE] : 0.32444444894790647\n",
      "[50/1000]\n",
      "- [VAL] LOSS : 0.3381630480289459 [SCORE] : 0.9090909361839294\n",
      "[51/1000]\n",
      "- [TRAIN] LOSS : 0.16108567615350086 [SCORE] : 0.45079365571339924\n",
      "[51/1000]\n",
      "- [VAL] LOSS : 0.32989615201950073 [SCORE] : 0.9090909361839294\n",
      "[52/1000]\n",
      "- [TRAIN] LOSS : 0.15686487257480622 [SCORE] : 0.5174603223800659\n",
      "[52/1000]\n",
      "- [VAL] LOSS : 0.32214635610580444 [SCORE] : 0.9090909361839294\n",
      "[53/1000]\n",
      "- [TRAIN] LOSS : 0.15271055301030476 [SCORE] : 0.5523809552192688\n",
      "[53/1000]\n",
      "- [VAL] LOSS : 0.3145653307437897 [SCORE] : 0.9090909361839294\n",
      "[54/1000]\n",
      "- [TRAIN] LOSS : 0.1486202379067739 [SCORE] : 0.561904764175415\n",
      "[54/1000]\n",
      "- [VAL] LOSS : 0.30700281262397766 [SCORE] : 0.95652174949646\n",
      "[55/1000]\n",
      "- [TRAIN] LOSS : 0.14449687997500102 [SCORE] : 0.5833333333333334\n",
      "[55/1000]\n",
      "- [VAL] LOSS : 0.29844537377357483 [SCORE] : 0.95652174949646\n",
      "[56/1000]\n",
      "- [TRAIN] LOSS : 0.13977866818507512 [SCORE] : 0.5833333333333334\n",
      "[56/1000]\n",
      "- [VAL] LOSS : 0.2878856658935547 [SCORE] : 1.0\n",
      "[57/1000]\n",
      "- [TRAIN] LOSS : 0.13444491724173227 [SCORE] : 0.5833333333333334\n",
      "[57/1000]\n",
      "- [VAL] LOSS : 0.2767395079135895 [SCORE] : 1.0\n",
      "[58/1000]\n",
      "- [TRAIN] LOSS : 0.12927640825510026 [SCORE] : 0.6\n",
      "[58/1000]\n",
      "- [VAL] LOSS : 0.26595965027809143 [SCORE] : 1.0\n",
      "[59/1000]\n",
      "- [TRAIN] LOSS : 0.12403535197178522 [SCORE] : 0.6\n",
      "[59/1000]\n",
      "- [VAL] LOSS : 0.2553441822528839 [SCORE] : 1.0\n",
      "[60/1000]\n",
      "- [TRAIN] LOSS : 0.1188812663157781 [SCORE] : 0.6\n",
      "[60/1000]\n",
      "- [VAL] LOSS : 0.24465525150299072 [SCORE] : 1.0\n",
      "[61/1000]\n",
      "- [TRAIN] LOSS : 0.1138437752922376 [SCORE] : 0.6\n",
      "[61/1000]\n",
      "- [VAL] LOSS : 0.234623521566391 [SCORE] : 1.0\n",
      "[62/1000]\n",
      "- [TRAIN] LOSS : 0.10865481793880463 [SCORE] : 0.6\n",
      "[62/1000]\n",
      "- [VAL] LOSS : 0.22397124767303467 [SCORE] : 1.0\n",
      "[63/1000]\n",
      "- [TRAIN] LOSS : 0.10293882389863332 [SCORE] : 0.6\n",
      "[63/1000]\n",
      "- [VAL] LOSS : 0.21203657984733582 [SCORE] : 1.0\n",
      "[64/1000]\n",
      "- [TRAIN] LOSS : 0.09667506416638692 [SCORE] : 0.6\n",
      "[64/1000]\n",
      "- [VAL] LOSS : 0.19859625399112701 [SCORE] : 1.0\n",
      "[65/1000]\n",
      "- [TRAIN] LOSS : 0.08986962934335073 [SCORE] : 0.6\n",
      "[65/1000]\n",
      "- [VAL] LOSS : 0.1838194578886032 [SCORE] : 1.0\n",
      "[66/1000]\n",
      "- [TRAIN] LOSS : 0.08269459158182144 [SCORE] : 0.6\n",
      "[66/1000]\n",
      "- [VAL] LOSS : 0.16780129075050354 [SCORE] : 1.0\n",
      "[67/1000]\n",
      "- [TRAIN] LOSS : 0.0753221295773983 [SCORE] : 0.6\n",
      "[67/1000]\n",
      "- [VAL] LOSS : 0.15111468732357025 [SCORE] : 1.0\n",
      "[68/1000]\n",
      "- [TRAIN] LOSS : 0.06790561651190122 [SCORE] : 0.6\n",
      "[68/1000]\n",
      "- [VAL] LOSS : 0.13450458645820618 [SCORE] : 1.0\n",
      "[69/1000]\n",
      "- [TRAIN] LOSS : 0.06060933445890745 [SCORE] : 0.6\n",
      "[69/1000]\n",
      "- [VAL] LOSS : 0.11835379153490067 [SCORE] : 1.0\n",
      "[70/1000]\n",
      "- [TRAIN] LOSS : 0.053637860467036565 [SCORE] : 0.6\n",
      "[70/1000]\n",
      "- [VAL] LOSS : 0.10323091596364975 [SCORE] : 1.0\n",
      "[71/1000]\n",
      "- [TRAIN] LOSS : 0.04718631108601888 [SCORE] : 0.6\n",
      "[71/1000]\n",
      "- [VAL] LOSS : 0.08951062709093094 [SCORE] : 1.0\n",
      "[72/1000]\n",
      "- [TRAIN] LOSS : 0.04136922607819239 [SCORE] : 0.6\n",
      "[72/1000]\n",
      "- [VAL] LOSS : 0.07734374701976776 [SCORE] : 1.0\n",
      "[73/1000]\n",
      "- [TRAIN] LOSS : 0.03626808983584245 [SCORE] : 0.6\n",
      "[73/1000]\n",
      "- [VAL] LOSS : 0.06687067449092865 [SCORE] : 1.0\n",
      "[74/1000]\n",
      "- [TRAIN] LOSS : 0.03187432313958804 [SCORE] : 0.6\n",
      "[74/1000]\n",
      "- [VAL] LOSS : 0.05806010589003563 [SCORE] : 1.0\n",
      "[75/1000]\n",
      "- [TRAIN] LOSS : 0.028130913525819777 [SCORE] : 0.6\n",
      "[75/1000]\n",
      "- [VAL] LOSS : 0.05069177597761154 [SCORE] : 1.0\n",
      "[76/1000]\n",
      "- [TRAIN] LOSS : 0.024961386745174726 [SCORE] : 0.6\n",
      "[76/1000]\n",
      "- [VAL] LOSS : 0.044530417770147324 [SCORE] : 1.0\n",
      "[77/1000]\n",
      "- [TRAIN] LOSS : 0.02226898359755675 [SCORE] : 0.6\n",
      "[77/1000]\n",
      "- [VAL] LOSS : 0.0393909215927124 [SCORE] : 1.0\n",
      "[78/1000]\n",
      "- [TRAIN] LOSS : 0.019992409522334734 [SCORE] : 0.6\n",
      "[78/1000]\n",
      "- [VAL] LOSS : 0.03507750853896141 [SCORE] : 1.0\n",
      "[79/1000]\n",
      "- [TRAIN] LOSS : 0.018021625901261964 [SCORE] : 0.6\n",
      "[79/1000]\n",
      "- [VAL] LOSS : 0.03135671839118004 [SCORE] : 1.0\n",
      "[80/1000]\n",
      "- [TRAIN] LOSS : 0.016359593843420346 [SCORE] : 0.6\n",
      "[80/1000]\n",
      "- [VAL] LOSS : 0.028223205357789993 [SCORE] : 1.0\n",
      "[81/1000]\n",
      "- [TRAIN] LOSS : 0.014933179629345735 [SCORE] : 0.6\n",
      "[81/1000]\n",
      "- [VAL] LOSS : 0.025560349225997925 [SCORE] : 1.0\n",
      "[82/1000]\n",
      "- [TRAIN] LOSS : 0.013698626744250457 [SCORE] : 0.6\n",
      "[82/1000]\n",
      "- [VAL] LOSS : 0.0232815183699131 [SCORE] : 1.0\n",
      "[83/1000]\n",
      "- [TRAIN] LOSS : 0.012619308630625407 [SCORE] : 0.6\n",
      "[83/1000]\n",
      "- [VAL] LOSS : 0.02131226658821106 [SCORE] : 1.0\n",
      "[84/1000]\n",
      "- [TRAIN] LOSS : 0.011665885088344414 [SCORE] : 0.6\n",
      "[84/1000]\n",
      "- [VAL] LOSS : 0.01958426833152771 [SCORE] : 1.0\n",
      "[85/1000]\n",
      "- [TRAIN] LOSS : 0.010827677448590596 [SCORE] : 0.6\n",
      "[85/1000]\n",
      "- [VAL] LOSS : 0.018064245581626892 [SCORE] : 1.0\n",
      "[86/1000]\n",
      "- [TRAIN] LOSS : 0.01009434536099434 [SCORE] : 0.6\n",
      "[86/1000]\n",
      "- [VAL] LOSS : 0.016748305410146713 [SCORE] : 1.0\n",
      "[87/1000]\n",
      "- [TRAIN] LOSS : 0.00943961584319671 [SCORE] : 0.6\n",
      "[87/1000]\n",
      "- [VAL] LOSS : 0.015588711015880108 [SCORE] : 1.0\n",
      "[88/1000]\n",
      "- [TRAIN] LOSS : 0.00884933831791083 [SCORE] : 0.6\n",
      "[88/1000]\n",
      "- [VAL] LOSS : 0.014554082415997982 [SCORE] : 1.0\n",
      "[89/1000]\n",
      "- [TRAIN] LOSS : 0.008318347421785196 [SCORE] : 0.6\n",
      "[89/1000]\n",
      "- [VAL] LOSS : 0.013624991290271282 [SCORE] : 1.0\n",
      "[90/1000]\n",
      "- [TRAIN] LOSS : 0.007836652578165133 [SCORE] : 0.6\n",
      "[90/1000]\n",
      "- [VAL] LOSS : 0.012787285260856152 [SCORE] : 1.0\n",
      "[91/1000]\n",
      "- [TRAIN] LOSS : 0.007400611725946267 [SCORE] : 0.6\n",
      "[91/1000]\n",
      "- [VAL] LOSS : 0.012033090926706791 [SCORE] : 1.0\n",
      "[92/1000]\n",
      "- [TRAIN] LOSS : 0.007002765499055386 [SCORE] : 0.6\n",
      "[92/1000]\n",
      "- [VAL] LOSS : 0.011351694352924824 [SCORE] : 1.0\n",
      "[93/1000]\n",
      "- [TRAIN] LOSS : 0.006636015294740598 [SCORE] : 0.6\n",
      "[93/1000]\n",
      "- [VAL] LOSS : 0.010728688910603523 [SCORE] : 1.0\n",
      "[94/1000]\n",
      "- [TRAIN] LOSS : 0.006300428602844477 [SCORE] : 0.6\n",
      "[94/1000]\n",
      "- [VAL] LOSS : 0.010154656134545803 [SCORE] : 1.0\n",
      "[95/1000]\n",
      "- [TRAIN] LOSS : 0.005990670528262854 [SCORE] : 0.6\n",
      "[95/1000]\n",
      "- [VAL] LOSS : 0.00962580181658268 [SCORE] : 1.0\n",
      "[96/1000]\n",
      "- [TRAIN] LOSS : 0.005707283038645983 [SCORE] : 0.6\n",
      "[96/1000]\n",
      "- [VAL] LOSS : 0.009141401387751102 [SCORE] : 1.0\n",
      "[97/1000]\n",
      "- [TRAIN] LOSS : 0.0054457798600196835 [SCORE] : 0.6\n",
      "[97/1000]\n",
      "- [VAL] LOSS : 0.008697002194821835 [SCORE] : 1.0\n",
      "[98/1000]\n",
      "- [TRAIN] LOSS : 0.005203483098496994 [SCORE] : 0.6\n",
      "[98/1000]\n",
      "- [VAL] LOSS : 0.008288035169243813 [SCORE] : 1.0\n",
      "[99/1000]\n",
      "- [TRAIN] LOSS : 0.004977615394939979 [SCORE] : 0.6\n",
      "[99/1000]\n",
      "- [VAL] LOSS : 0.007910097949206829 [SCORE] : 1.0\n",
      "[100/1000]\n",
      "- [TRAIN] LOSS : 0.004766903724521399 [SCORE] : 0.6\n",
      "[100/1000]\n",
      "- [VAL] LOSS : 0.007559819612652063 [SCORE] : 1.0\n",
      "[101/1000]\n",
      "- [TRAIN] LOSS : 0.004569974293311437 [SCORE] : 0.6\n",
      "[101/1000]\n",
      "- [VAL] LOSS : 0.007234266493469477 [SCORE] : 1.0\n",
      "[102/1000]\n",
      "- [TRAIN] LOSS : 0.0043849502379695576 [SCORE] : 0.6\n",
      "[102/1000]\n",
      "- [VAL] LOSS : 0.006930029951035976 [SCORE] : 1.0\n",
      "[103/1000]\n",
      "- [TRAIN] LOSS : 0.004211063714077075 [SCORE] : 0.6\n",
      "[103/1000]\n",
      "- [VAL] LOSS : 0.0066438158974051476 [SCORE] : 1.0\n",
      "[104/1000]\n",
      "- [TRAIN] LOSS : 0.004047838039696217 [SCORE] : 0.6\n",
      "[104/1000]\n",
      "- [VAL] LOSS : 0.0063739377073943615 [SCORE] : 1.0\n",
      "[105/1000]\n",
      "- [TRAIN] LOSS : 0.0038953003318359454 [SCORE] : 0.6\n",
      "[105/1000]\n",
      "- [VAL] LOSS : 0.006120866630226374 [SCORE] : 1.0\n",
      "[106/1000]\n",
      "- [TRAIN] LOSS : 0.0037525995013614494 [SCORE] : 0.6\n",
      "[106/1000]\n",
      "- [VAL] LOSS : 0.0058843232691287994 [SCORE] : 1.0\n",
      "[107/1000]\n",
      "- [TRAIN] LOSS : 0.0036184827021012705 [SCORE] : 0.6\n",
      "[107/1000]\n",
      "- [VAL] LOSS : 0.0056630889885127544 [SCORE] : 1.0\n",
      "[108/1000]\n",
      "- [TRAIN] LOSS : 0.0034914714594682056 [SCORE] : 0.6\n",
      "[108/1000]\n",
      "- [VAL] LOSS : 0.005454920697957277 [SCORE] : 1.0\n",
      "[109/1000]\n",
      "- [TRAIN] LOSS : 0.003371546231210232 [SCORE] : 0.6\n",
      "[109/1000]\n",
      "- [VAL] LOSS : 0.005259155295789242 [SCORE] : 1.0\n",
      "[110/1000]\n",
      "- [TRAIN] LOSS : 0.003257154378419121 [SCORE] : 0.6\n",
      "[110/1000]\n",
      "- [VAL] LOSS : 0.005073643755167723 [SCORE] : 1.0\n",
      "[111/1000]\n",
      "- [TRAIN] LOSS : 0.003149119609345992 [SCORE] : 0.6\n",
      "[111/1000]\n",
      "- [VAL] LOSS : 0.004898027051240206 [SCORE] : 1.0\n",
      "[112/1000]\n",
      "- [TRAIN] LOSS : 0.0030470788634071747 [SCORE] : 0.6\n",
      "[112/1000]\n",
      "- [VAL] LOSS : 0.004732191096991301 [SCORE] : 1.0\n",
      "[113/1000]\n",
      "- [TRAIN] LOSS : 0.0029503317394604287 [SCORE] : 0.6\n",
      "[113/1000]\n",
      "- [VAL] LOSS : 0.004575270228087902 [SCORE] : 1.0\n",
      "[114/1000]\n",
      "- [TRAIN] LOSS : 0.002858045743778348 [SCORE] : 0.6\n",
      "[114/1000]\n",
      "- [VAL] LOSS : 0.004426432773470879 [SCORE] : 1.0\n",
      "[115/1000]\n",
      "- [TRAIN] LOSS : 0.0027702357775221268 [SCORE] : 0.6\n",
      "[115/1000]\n",
      "- [VAL] LOSS : 0.00428512180224061 [SCORE] : 1.0\n",
      "[116/1000]\n",
      "- [TRAIN] LOSS : 0.0026866252068430186 [SCORE] : 0.6\n",
      "[116/1000]\n",
      "- [VAL] LOSS : 0.004150946158915758 [SCORE] : 1.0\n",
      "[117/1000]\n",
      "- [TRAIN] LOSS : 0.002606884421159824 [SCORE] : 0.6\n",
      "[117/1000]\n",
      "- [VAL] LOSS : 0.004023250658065081 [SCORE] : 1.0\n",
      "[118/1000]\n",
      "- [TRAIN] LOSS : 0.002530526323243976 [SCORE] : 0.6\n",
      "[118/1000]\n",
      "- [VAL] LOSS : 0.0039014131762087345 [SCORE] : 1.0\n",
      "[119/1000]\n",
      "- [TRAIN] LOSS : 0.002457632248600324 [SCORE] : 0.6\n",
      "[119/1000]\n",
      "- [VAL] LOSS : 0.0037851452361792326 [SCORE] : 1.0\n",
      "[120/1000]\n",
      "- [TRAIN] LOSS : 0.002387942016745607 [SCORE] : 0.6\n",
      "[120/1000]\n",
      "- [VAL] LOSS : 0.0036742433439940214 [SCORE] : 1.0\n",
      "[121/1000]\n",
      "- [TRAIN] LOSS : 0.002320433221757412 [SCORE] : 0.6\n",
      "[121/1000]\n",
      "- [VAL] LOSS : 0.0035675542894750834 [SCORE] : 1.0\n",
      "[122/1000]\n",
      "- [TRAIN] LOSS : 0.002256701871131857 [SCORE] : 0.6\n",
      "[122/1000]\n",
      "- [VAL] LOSS : 0.003465495305135846 [SCORE] : 1.0\n",
      "[123/1000]\n",
      "- [TRAIN] LOSS : 0.0021960167214274406 [SCORE] : 0.6\n",
      "[123/1000]\n",
      "- [VAL] LOSS : 0.003368089674040675 [SCORE] : 1.0\n",
      "[124/1000]\n",
      "- [TRAIN] LOSS : 0.0021378431003540753 [SCORE] : 0.6\n",
      "[124/1000]\n",
      "- [VAL] LOSS : 0.003274977905675769 [SCORE] : 1.0\n",
      "[125/1000]\n",
      "- [TRAIN] LOSS : 0.002081951576595505 [SCORE] : 0.6\n",
      "[125/1000]\n",
      "- [VAL] LOSS : 0.0031857730355113745 [SCORE] : 1.0\n",
      "[126/1000]\n",
      "- [TRAIN] LOSS : 0.0020282266195863485 [SCORE] : 0.6\n",
      "[126/1000]\n",
      "- [VAL] LOSS : 0.0031002715695649385 [SCORE] : 1.0\n",
      "[127/1000]\n",
      "- [TRAIN] LOSS : 0.0019767249546324213 [SCORE] : 0.6\n",
      "[127/1000]\n",
      "- [VAL] LOSS : 0.003018370596691966 [SCORE] : 1.0\n",
      "[128/1000]\n",
      "- [TRAIN] LOSS : 0.0019272703677415848 [SCORE] : 0.6\n",
      "[128/1000]\n",
      "- [VAL] LOSS : 0.0029398431070148945 [SCORE] : 1.0\n",
      "[129/1000]\n",
      "- [TRAIN] LOSS : 0.0018795307958498597 [SCORE] : 0.6\n",
      "[129/1000]\n",
      "- [VAL] LOSS : 0.0028644618578255177 [SCORE] : 1.0\n",
      "[130/1000]\n",
      "- [TRAIN] LOSS : 0.001833602498906354 [SCORE] : 0.6\n",
      "[130/1000]\n",
      "- [VAL] LOSS : 0.002792011946439743 [SCORE] : 1.0\n",
      "[131/1000]\n",
      "- [TRAIN] LOSS : 0.001789409783668816 [SCORE] : 0.6\n",
      "[131/1000]\n",
      "- [VAL] LOSS : 0.002722393488511443 [SCORE] : 1.0\n",
      "[132/1000]\n",
      "- [TRAIN] LOSS : 0.001746837499861916 [SCORE] : 0.6\n",
      "[132/1000]\n",
      "- [VAL] LOSS : 0.002655397867783904 [SCORE] : 1.0\n",
      "[133/1000]\n",
      "- [TRAIN] LOSS : 0.0017055106349289418 [SCORE] : 0.6\n",
      "[133/1000]\n",
      "- [VAL] LOSS : 0.0025905799120664597 [SCORE] : 1.0\n",
      "[134/1000]\n",
      "- [TRAIN] LOSS : 0.0016656650230288505 [SCORE] : 0.6\n",
      "[134/1000]\n",
      "- [VAL] LOSS : 0.002528138691559434 [SCORE] : 1.0\n",
      "[135/1000]\n",
      "- [TRAIN] LOSS : 0.0016277572140097618 [SCORE] : 0.6\n",
      "[135/1000]\n",
      "- [VAL] LOSS : 0.0024681861978024244 [SCORE] : 1.0\n",
      "[136/1000]\n",
      "- [TRAIN] LOSS : 0.0015908215194940568 [SCORE] : 0.6\n",
      "[136/1000]\n",
      "- [VAL] LOSS : 0.0024102143943309784 [SCORE] : 1.0\n",
      "[137/1000]\n",
      "- [TRAIN] LOSS : 0.001554852941383918 [SCORE] : 0.6\n",
      "[137/1000]\n",
      "- [VAL] LOSS : 0.002354233991354704 [SCORE] : 1.0\n",
      "[138/1000]\n",
      "- [TRAIN] LOSS : 0.00152050390218695 [SCORE] : 0.6\n",
      "[138/1000]\n",
      "- [VAL] LOSS : 0.0023001539520919323 [SCORE] : 1.0\n",
      "[139/1000]\n",
      "- [TRAIN] LOSS : 0.001487120264209807 [SCORE] : 0.6\n",
      "[139/1000]\n",
      "- [VAL] LOSS : 0.0022480350453406572 [SCORE] : 1.0\n",
      "[140/1000]\n",
      "- [TRAIN] LOSS : 0.0014552157372236252 [SCORE] : 0.6\n",
      "[140/1000]\n",
      "- [VAL] LOSS : 0.002197901951149106 [SCORE] : 1.0\n",
      "[141/1000]\n",
      "- [TRAIN] LOSS : 0.001424053745965163 [SCORE] : 0.6\n",
      "[141/1000]\n",
      "- [VAL] LOSS : 0.002149269450455904 [SCORE] : 1.0\n",
      "[142/1000]\n",
      "- [TRAIN] LOSS : 0.0013929256858925025 [SCORE] : 0.6\n",
      "[142/1000]\n",
      "- [VAL] LOSS : 0.0021018562838435173 [SCORE] : 1.0\n",
      "[143/1000]\n",
      "- [TRAIN] LOSS : 0.0013641623314470052 [SCORE] : 0.6\n",
      "[143/1000]\n",
      "- [VAL] LOSS : 0.0020563025027513504 [SCORE] : 1.0\n",
      "[144/1000]\n",
      "- [TRAIN] LOSS : 0.0013359838010122379 [SCORE] : 0.6\n",
      "[144/1000]\n",
      "- [VAL] LOSS : 0.002012324519455433 [SCORE] : 1.0\n",
      "[145/1000]\n",
      "- [TRAIN] LOSS : 0.0013085389044135809 [SCORE] : 0.6\n",
      "[145/1000]\n",
      "- [VAL] LOSS : 0.001969708362594247 [SCORE] : 1.0\n",
      "[146/1000]\n",
      "- [TRAIN] LOSS : 0.001281909163420399 [SCORE] : 0.6\n",
      "[146/1000]\n",
      "- [VAL] LOSS : 0.0019284908194094896 [SCORE] : 1.0\n",
      "[147/1000]\n",
      "- [TRAIN] LOSS : 0.0012563671916723251 [SCORE] : 0.6\n",
      "[147/1000]\n",
      "- [VAL] LOSS : 0.0018885873723775148 [SCORE] : 1.0\n",
      "[148/1000]\n",
      "- [TRAIN] LOSS : 0.001231423633483549 [SCORE] : 0.6\n",
      "[148/1000]\n",
      "- [VAL] LOSS : 0.0018499905709177256 [SCORE] : 1.0\n",
      "[149/1000]\n",
      "- [TRAIN] LOSS : 0.0012074336331958572 [SCORE] : 0.6\n",
      "[149/1000]\n",
      "- [VAL] LOSS : 0.001812604023143649 [SCORE] : 1.0\n",
      "[150/1000]\n",
      "- [TRAIN] LOSS : 0.0011842972443749508 [SCORE] : 0.6\n",
      "[150/1000]\n",
      "- [VAL] LOSS : 0.0017763319192454219 [SCORE] : 1.0\n",
      "[151/1000]\n",
      "- [TRAIN] LOSS : 0.0011612314187611143 [SCORE] : 0.6\n",
      "[151/1000]\n",
      "- [VAL] LOSS : 0.0017410714644938707 [SCORE] : 1.0\n",
      "[152/1000]\n",
      "- [TRAIN] LOSS : 0.0011391221002365153 [SCORE] : 0.6\n",
      "[152/1000]\n",
      "- [VAL] LOSS : 0.0017069164896383882 [SCORE] : 1.0\n",
      "[153/1000]\n",
      "- [TRAIN] LOSS : 0.0011177972541190685 [SCORE] : 0.6\n",
      "[153/1000]\n",
      "- [VAL] LOSS : 0.0016737611731514335 [SCORE] : 1.0\n",
      "[154/1000]\n",
      "- [TRAIN] LOSS : 0.0010967814247123896 [SCORE] : 0.6\n",
      "[154/1000]\n",
      "- [VAL] LOSS : 0.0016415397403761744 [SCORE] : 1.0\n",
      "[155/1000]\n",
      "- [TRAIN] LOSS : 0.0010765450463319818 [SCORE] : 0.6\n",
      "[155/1000]\n",
      "- [VAL] LOSS : 0.0016102761728689075 [SCORE] : 1.0\n",
      "[156/1000]\n",
      "- [TRAIN] LOSS : 0.0010570006677880883 [SCORE] : 0.6\n",
      "[156/1000]\n",
      "- [VAL] LOSS : 0.0015799161046743393 [SCORE] : 1.0\n",
      "[157/1000]\n",
      "- [TRAIN] LOSS : 0.001037671851615111 [SCORE] : 0.6\n",
      "[157/1000]\n",
      "- [VAL] LOSS : 0.0015503662871196866 [SCORE] : 1.0\n",
      "[158/1000]\n",
      "- [TRAIN] LOSS : 0.0010189635213464499 [SCORE] : 0.6\n",
      "[158/1000]\n",
      "- [VAL] LOSS : 0.0015216375468298793 [SCORE] : 1.0\n",
      "[159/1000]\n",
      "- [TRAIN] LOSS : 0.0010007970966398716 [SCORE] : 0.6\n",
      "[159/1000]\n",
      "- [VAL] LOSS : 0.0014936778461560607 [SCORE] : 1.0\n",
      "[160/1000]\n",
      "- [TRAIN] LOSS : 0.0009831212499799827 [SCORE] : 0.6\n",
      "[160/1000]\n",
      "- [VAL] LOSS : 0.0014665031339973211 [SCORE] : 1.0\n",
      "[161/1000]\n",
      "- [TRAIN] LOSS : 0.000965913311423113 [SCORE] : 0.6\n",
      "[161/1000]\n",
      "- [VAL] LOSS : 0.0014400805812329054 [SCORE] : 1.0\n",
      "[162/1000]\n",
      "- [TRAIN] LOSS : 0.0009491454227827489 [SCORE] : 0.6\n",
      "[162/1000]\n",
      "- [VAL] LOSS : 0.0014143435982987285 [SCORE] : 1.0\n",
      "[163/1000]\n",
      "- [TRAIN] LOSS : 0.0009328075063725313 [SCORE] : 0.6\n",
      "[163/1000]\n",
      "- [VAL] LOSS : 0.0013892940478399396 [SCORE] : 1.0\n",
      "[164/1000]\n",
      "- [TRAIN] LOSS : 0.0009168750955723226 [SCORE] : 0.6\n",
      "[164/1000]\n",
      "- [VAL] LOSS : 0.0013648936292156577 [SCORE] : 1.0\n",
      "[165/1000]\n",
      "- [TRAIN] LOSS : 0.0009013411356136203 [SCORE] : 0.6\n",
      "[165/1000]\n",
      "- [VAL] LOSS : 0.0013411013642325997 [SCORE] : 1.0\n",
      "[166/1000]\n",
      "- [TRAIN] LOSS : 0.0008861738839186728 [SCORE] : 0.6\n",
      "[166/1000]\n",
      "- [VAL] LOSS : 0.0013179238885641098 [SCORE] : 1.0\n",
      "[167/1000]\n",
      "- [TRAIN] LOSS : 0.0008713615980620186 [SCORE] : 0.6\n",
      "[167/1000]\n",
      "- [VAL] LOSS : 0.0012953262776136398 [SCORE] : 1.0\n",
      "[168/1000]\n",
      "- [TRAIN] LOSS : 0.0008569657414530715 [SCORE] : 0.6\n",
      "[168/1000]\n",
      "- [VAL] LOSS : 0.0012732862960547209 [SCORE] : 1.0\n",
      "[169/1000]\n",
      "- [TRAIN] LOSS : 0.0008428992393116156 [SCORE] : 0.6\n",
      "[169/1000]\n",
      "- [VAL] LOSS : 0.001251793117262423 [SCORE] : 1.0\n",
      "[170/1000]\n",
      "- [TRAIN] LOSS : 0.0008291562631105383 [SCORE] : 0.6\n",
      "[170/1000]\n",
      "- [VAL] LOSS : 0.0012308048317208886 [SCORE] : 1.0\n",
      "[171/1000]\n",
      "- [TRAIN] LOSS : 0.0008157385474381347 [SCORE] : 0.6\n",
      "[171/1000]\n",
      "- [VAL] LOSS : 0.0012103260960429907 [SCORE] : 1.0\n",
      "[172/1000]\n",
      "- [TRAIN] LOSS : 0.0008026077877730132 [SCORE] : 0.6\n",
      "[172/1000]\n",
      "- [VAL] LOSS : 0.0011903130216524005 [SCORE] : 1.0\n",
      "[173/1000]\n",
      "- [TRAIN] LOSS : 0.000789790682028979 [SCORE] : 0.6\n",
      "[173/1000]\n",
      "- [VAL] LOSS : 0.0011707550147548318 [SCORE] : 1.0\n",
      "[174/1000]\n",
      "- [TRAIN] LOSS : 0.0007773199584335088 [SCORE] : 0.6\n",
      "[174/1000]\n",
      "- [VAL] LOSS : 0.0011516554513946176 [SCORE] : 1.0\n",
      "[175/1000]\n",
      "- [TRAIN] LOSS : 0.0007651226090577742 [SCORE] : 0.6\n",
      "[175/1000]\n",
      "- [VAL] LOSS : 0.0011330146808177233 [SCORE] : 1.0\n",
      "[176/1000]\n",
      "- [TRAIN] LOSS : 0.0007531992276199162 [SCORE] : 0.6\n",
      "[176/1000]\n",
      "- [VAL] LOSS : 0.0011147985933348536 [SCORE] : 1.0\n",
      "[177/1000]\n",
      "- [TRAIN] LOSS : 0.0007415303882832328 [SCORE] : 0.6\n",
      "[177/1000]\n",
      "- [VAL] LOSS : 0.0010969970608130097 [SCORE] : 1.0\n",
      "[178/1000]\n",
      "- [TRAIN] LOSS : 0.0007301106272886197 [SCORE] : 0.6\n",
      "[178/1000]\n",
      "- [VAL] LOSS : 0.0010795993730425835 [SCORE] : 1.0\n",
      "[179/1000]\n",
      "- [TRAIN] LOSS : 0.0007189852185547352 [SCORE] : 0.6\n",
      "[179/1000]\n",
      "- [VAL] LOSS : 0.0010625823633745313 [SCORE] : 1.0\n",
      "[180/1000]\n",
      "- [TRAIN] LOSS : 0.0007080869322332243 [SCORE] : 0.6\n",
      "[180/1000]\n",
      "- [VAL] LOSS : 0.0010459633776918054 [SCORE] : 1.0\n",
      "[181/1000]\n",
      "- [TRAIN] LOSS : 0.0006974136961313585 [SCORE] : 0.6\n",
      "[181/1000]\n",
      "- [VAL] LOSS : 0.0010296967811882496 [SCORE] : 1.0\n",
      "[182/1000]\n",
      "- [TRAIN] LOSS : 0.0006869677104987204 [SCORE] : 0.6\n",
      "[182/1000]\n",
      "- [VAL] LOSS : 0.0010137788485735655 [SCORE] : 1.0\n",
      "[183/1000]\n",
      "- [TRAIN] LOSS : 0.0006767771129185955 [SCORE] : 0.6\n",
      "[183/1000]\n",
      "- [VAL] LOSS : 0.0009982181945815682 [SCORE] : 1.0\n",
      "[184/1000]\n",
      "- [TRAIN] LOSS : 0.0006667950539849699 [SCORE] : 0.6\n",
      "[184/1000]\n",
      "- [VAL] LOSS : 0.0009829953778535128 [SCORE] : 1.0\n",
      "[185/1000]\n",
      "- [TRAIN] LOSS : 0.0006570158565106491 [SCORE] : 0.6\n",
      "[185/1000]\n",
      "- [VAL] LOSS : 0.0009680978837423027 [SCORE] : 1.0\n",
      "[186/1000]\n",
      "- [TRAIN] LOSS : 0.0006474354925254981 [SCORE] : 0.6\n",
      "[186/1000]\n",
      "- [VAL] LOSS : 0.0009535257122479379 [SCORE] : 1.0\n",
      "[187/1000]\n",
      "- [TRAIN] LOSS : 0.0006380389677360654 [SCORE] : 0.6\n",
      "[187/1000]\n",
      "- [VAL] LOSS : 0.0009392420761287212 [SCORE] : 1.0\n",
      "[188/1000]\n",
      "- [TRAIN] LOSS : 0.0006288758246228099 [SCORE] : 0.6\n",
      "[188/1000]\n",
      "- [VAL] LOSS : 0.0009252828313037753 [SCORE] : 1.0\n",
      "[189/1000]\n",
      "- [TRAIN] LOSS : 0.0006198860666093727 [SCORE] : 0.6\n",
      "[189/1000]\n",
      "- [VAL] LOSS : 0.0009115951252169907 [SCORE] : 1.0\n",
      "[190/1000]\n",
      "- [TRAIN] LOSS : 0.0006110702912944058 [SCORE] : 0.6\n",
      "[190/1000]\n",
      "- [VAL] LOSS : 0.0008981970022432506 [SCORE] : 1.0\n",
      "[191/1000]\n",
      "- [TRAIN] LOSS : 0.0006024225847795605 [SCORE] : 0.6\n",
      "[191/1000]\n",
      "- [VAL] LOSS : 0.000885078392457217 [SCORE] : 1.0\n",
      "[192/1000]\n",
      "- [TRAIN] LOSS : 0.0005939756966351222 [SCORE] : 0.6\n",
      "[192/1000]\n",
      "- [VAL] LOSS : 0.0008722405764274299 [SCORE] : 1.0\n",
      "[193/1000]\n",
      "- [TRAIN] LOSS : 0.0005856912156256537 [SCORE] : 0.6\n",
      "[193/1000]\n",
      "- [VAL] LOSS : 0.0008596627158112824 [SCORE] : 1.0\n",
      "[194/1000]\n",
      "- [TRAIN] LOSS : 0.0005775651176615307 [SCORE] : 0.6\n",
      "[194/1000]\n",
      "- [VAL] LOSS : 0.0008473194320686162 [SCORE] : 1.0\n",
      "[195/1000]\n",
      "- [TRAIN] LOSS : 0.0005695912036268662 [SCORE] : 0.6\n",
      "[195/1000]\n",
      "- [VAL] LOSS : 0.000835239072330296 [SCORE] : 1.0\n",
      "[196/1000]\n",
      "- [TRAIN] LOSS : 0.0005617576593067497 [SCORE] : 0.6\n",
      "[196/1000]\n",
      "- [VAL] LOSS : 0.0008233967237174511 [SCORE] : 1.0\n",
      "[197/1000]\n",
      "- [TRAIN] LOSS : 0.0005541156860999763 [SCORE] : 0.6\n",
      "[197/1000]\n",
      "- [VAL] LOSS : 0.0008117863908410072 [SCORE] : 1.0\n",
      "[198/1000]\n",
      "- [TRAIN] LOSS : 0.0005466074837992589 [SCORE] : 0.6\n",
      "[198/1000]\n",
      "- [VAL] LOSS : 0.000800402311142534 [SCORE] : 1.0\n",
      "[199/1000]\n",
      "- [TRAIN] LOSS : 0.000539236954258134 [SCORE] : 0.6\n",
      "[199/1000]\n",
      "- [VAL] LOSS : 0.0007892391877248883 [SCORE] : 1.0\n",
      "[200/1000]\n",
      "- [TRAIN] LOSS : 0.0005320054847591867 [SCORE] : 0.6\n",
      "[200/1000]\n",
      "- [VAL] LOSS : 0.0007782881148159504 [SCORE] : 1.0\n",
      "[201/1000]\n",
      "- [TRAIN] LOSS : 0.0005248981295153498 [SCORE] : 0.6\n",
      "[201/1000]\n",
      "- [VAL] LOSS : 0.000767538498621434 [SCORE] : 1.0\n",
      "[202/1000]\n",
      "- [TRAIN] LOSS : 0.0005179218365810812 [SCORE] : 0.6\n",
      "[202/1000]\n",
      "- [VAL] LOSS : 0.0007571490132249892 [SCORE] : 1.0\n",
      "[203/1000]\n",
      "- [TRAIN] LOSS : 0.0005111115635372699 [SCORE] : 0.6\n",
      "[203/1000]\n",
      "- [VAL] LOSS : 0.0007471170974895358 [SCORE] : 1.0\n",
      "[204/1000]\n",
      "- [TRAIN] LOSS : 0.0005041343994283428 [SCORE] : 0.6\n",
      "[204/1000]\n",
      "- [VAL] LOSS : 0.0007366084610112011 [SCORE] : 1.0\n",
      "[205/1000]\n",
      "- [TRAIN] LOSS : 0.0004977744615947207 [SCORE] : 0.6\n",
      "[205/1000]\n",
      "- [VAL] LOSS : 0.0007267087348736823 [SCORE] : 1.0\n",
      "[206/1000]\n",
      "- [TRAIN] LOSS : 0.0004914411789892862 [SCORE] : 0.6\n",
      "[206/1000]\n",
      "- [VAL] LOSS : 0.0007169618038460612 [SCORE] : 1.0\n",
      "[207/1000]\n",
      "- [TRAIN] LOSS : 0.00048515022305461265 [SCORE] : 0.6\n",
      "[207/1000]\n",
      "- [VAL] LOSS : 0.0007077366462908685 [SCORE] : 1.0\n",
      "[208/1000]\n",
      "- [TRAIN] LOSS : 0.00047866420548719666 [SCORE] : 0.6\n",
      "[208/1000]\n",
      "- [VAL] LOSS : 0.0006981159676797688 [SCORE] : 1.0\n",
      "[209/1000]\n",
      "- [TRAIN] LOSS : 0.0004727760679088533 [SCORE] : 0.6\n",
      "[209/1000]\n",
      "- [VAL] LOSS : 0.0006889404030516744 [SCORE] : 1.0\n",
      "[210/1000]\n",
      "- [TRAIN] LOSS : 0.0004668933378222088 [SCORE] : 0.6\n",
      "[210/1000]\n",
      "- [VAL] LOSS : 0.0006800953997299075 [SCORE] : 1.0\n",
      "[211/1000]\n",
      "- [TRAIN] LOSS : 0.00046102698349083463 [SCORE] : 0.6\n",
      "[211/1000]\n",
      "- [VAL] LOSS : 0.0006716172792948782 [SCORE] : 1.0\n",
      "[212/1000]\n",
      "- [TRAIN] LOSS : 0.0004550303720558683 [SCORE] : 0.6\n",
      "[212/1000]\n",
      "- [VAL] LOSS : 0.0006625491078011692 [SCORE] : 1.0\n",
      "[213/1000]\n",
      "- [TRAIN] LOSS : 0.0004494820216981073 [SCORE] : 0.6\n",
      "[213/1000]\n",
      "- [VAL] LOSS : 0.0006541077164001763 [SCORE] : 1.0\n",
      "[214/1000]\n",
      "- [TRAIN] LOSS : 0.000443744077347219 [SCORE] : 0.6\n",
      "[214/1000]\n",
      "- [VAL] LOSS : 0.0006455834372900426 [SCORE] : 1.0\n",
      "[215/1000]\n",
      "- [TRAIN] LOSS : 0.00043848231628847617 [SCORE] : 0.6\n",
      "[215/1000]\n",
      "- [VAL] LOSS : 0.0006373616633936763 [SCORE] : 1.0\n",
      "[216/1000]\n",
      "- [TRAIN] LOSS : 0.00043317945091985165 [SCORE] : 0.6\n",
      "[216/1000]\n",
      "- [VAL] LOSS : 0.0006294592167250812 [SCORE] : 1.0\n",
      "[217/1000]\n",
      "- [TRAIN] LOSS : 0.00042765773444746933 [SCORE] : 0.6\n",
      "[217/1000]\n",
      "- [VAL] LOSS : 0.0006214031600393355 [SCORE] : 1.0\n",
      "[218/1000]\n",
      "- [TRAIN] LOSS : 0.000422633175427715 [SCORE] : 0.6\n",
      "[218/1000]\n",
      "- [VAL] LOSS : 0.0006135989679023623 [SCORE] : 1.0\n",
      "[219/1000]\n",
      "- [TRAIN] LOSS : 0.0004175875258321563 [SCORE] : 0.6\n",
      "[219/1000]\n",
      "- [VAL] LOSS : 0.0006062560132704675 [SCORE] : 1.0\n",
      "[220/1000]\n",
      "- [TRAIN] LOSS : 0.00041236691176891325 [SCORE] : 0.6\n",
      "[220/1000]\n",
      "- [VAL] LOSS : 0.0005984584568068385 [SCORE] : 1.0\n",
      "[221/1000]\n",
      "- [TRAIN] LOSS : 0.00040755379013717173 [SCORE] : 0.6\n",
      "[221/1000]\n",
      "- [VAL] LOSS : 0.0005912009510211647 [SCORE] : 1.0\n",
      "[222/1000]\n",
      "- [TRAIN] LOSS : 0.00040255022079994284 [SCORE] : 0.6\n",
      "[222/1000]\n",
      "- [VAL] LOSS : 0.0005838617798872292 [SCORE] : 1.0\n",
      "[223/1000]\n",
      "- [TRAIN] LOSS : 0.0003979538179313143 [SCORE] : 0.6\n",
      "[223/1000]\n",
      "- [VAL] LOSS : 0.0005767157999798656 [SCORE] : 1.0\n",
      "[224/1000]\n",
      "- [TRAIN] LOSS : 0.00039331331693877775 [SCORE] : 0.6\n",
      "[224/1000]\n",
      "- [VAL] LOSS : 0.000569964642636478 [SCORE] : 1.0\n",
      "[225/1000]\n",
      "- [TRAIN] LOSS : 0.0003885138857488831 [SCORE] : 0.6\n",
      "[225/1000]\n",
      "- [VAL] LOSS : 0.0005628391518257558 [SCORE] : 1.0\n",
      "[226/1000]\n",
      "- [TRAIN] LOSS : 0.00038406905368901787 [SCORE] : 0.6\n",
      "[226/1000]\n",
      "- [VAL] LOSS : 0.0005561872967518866 [SCORE] : 1.0\n",
      "[227/1000]\n",
      "- [TRAIN] LOSS : 0.00037947354139760136 [SCORE] : 0.6\n",
      "[227/1000]\n",
      "- [VAL] LOSS : 0.0005493903299793601 [SCORE] : 1.0\n",
      "[228/1000]\n",
      "- [TRAIN] LOSS : 0.00037522342948553464 [SCORE] : 0.6\n",
      "[228/1000]\n",
      "- [VAL] LOSS : 0.0005428488948382437 [SCORE] : 1.0\n",
      "[229/1000]\n",
      "- [TRAIN] LOSS : 0.0003707537097701182 [SCORE] : 0.6\n",
      "[229/1000]\n",
      "- [VAL] LOSS : 0.0005364333046600223 [SCORE] : 1.0\n",
      "[230/1000]\n",
      "- [TRAIN] LOSS : 0.00036665244648853936 [SCORE] : 0.6\n",
      "[230/1000]\n",
      "- [VAL] LOSS : 0.0005300673074088991 [SCORE] : 1.0\n",
      "[231/1000]\n",
      "- [TRAIN] LOSS : 0.0003625075080587218 [SCORE] : 0.6\n",
      "[231/1000]\n",
      "- [VAL] LOSS : 0.0005240755272097886 [SCORE] : 1.0\n",
      "[232/1000]\n",
      "- [TRAIN] LOSS : 0.00035822781501337886 [SCORE] : 0.6\n",
      "[232/1000]\n",
      "- [VAL] LOSS : 0.00051775889005512 [SCORE] : 1.0\n",
      "[233/1000]\n",
      "- [TRAIN] LOSS : 0.00035406696842983366 [SCORE] : 0.6\n",
      "[233/1000]\n",
      "- [VAL] LOSS : 0.0005117171676829457 [SCORE] : 1.0\n",
      "[234/1000]\n",
      "- [TRAIN] LOSS : 0.00035026907765616975 [SCORE] : 0.6\n",
      "[234/1000]\n",
      "- [VAL] LOSS : 0.0005057548405602574 [SCORE] : 1.0\n",
      "[235/1000]\n",
      "- [TRAIN] LOSS : 0.0003463995681765179 [SCORE] : 0.6\n",
      "[235/1000]\n",
      "- [VAL] LOSS : 0.0004999723169021308 [SCORE] : 1.0\n",
      "[236/1000]\n",
      "- [TRAIN] LOSS : 0.00034236205004466077 [SCORE] : 0.6\n",
      "[236/1000]\n",
      "- [VAL] LOSS : 0.000494118663482368 [SCORE] : 1.0\n",
      "[237/1000]\n",
      "- [TRAIN] LOSS : 0.0003386331596023714 [SCORE] : 0.6\n",
      "[237/1000]\n",
      "- [VAL] LOSS : 0.0004885575035586953 [SCORE] : 1.0\n",
      "[238/1000]\n",
      "- [TRAIN] LOSS : 0.0003347714625609418 [SCORE] : 0.6\n",
      "[238/1000]\n",
      "- [VAL] LOSS : 0.00048290035920217633 [SCORE] : 1.0\n",
      "[239/1000]\n",
      "- [TRAIN] LOSS : 0.0003311826711675773 [SCORE] : 0.6\n",
      "[239/1000]\n",
      "- [VAL] LOSS : 0.00047745127812959254 [SCORE] : 1.0\n",
      "[240/1000]\n",
      "- [TRAIN] LOSS : 0.0003274329433528086 [SCORE] : 0.6\n",
      "[240/1000]\n",
      "- [VAL] LOSS : 0.00047200973494909704 [SCORE] : 1.0\n",
      "[241/1000]\n",
      "- [TRAIN] LOSS : 0.0003239522794804846 [SCORE] : 0.6\n",
      "[241/1000]\n",
      "- [VAL] LOSS : 0.0004667244211304933 [SCORE] : 1.0\n",
      "[242/1000]\n",
      "- [TRAIN] LOSS : 0.00032031623801837363 [SCORE] : 0.6\n",
      "[242/1000]\n",
      "- [VAL] LOSS : 0.00046145636588335037 [SCORE] : 1.0\n",
      "[243/1000]\n",
      "- [TRAIN] LOSS : 0.0003169291904972245 [SCORE] : 0.6\n",
      "[243/1000]\n",
      "- [VAL] LOSS : 0.0004562945105135441 [SCORE] : 1.0\n",
      "[244/1000]\n",
      "- [TRAIN] LOSS : 0.00031339787625862906 [SCORE] : 0.6\n",
      "[244/1000]\n",
      "- [VAL] LOSS : 0.0004512250889092684 [SCORE] : 1.0\n",
      "[245/1000]\n",
      "- [TRAIN] LOSS : 0.000310121769628798 [SCORE] : 0.6\n",
      "[245/1000]\n",
      "- [VAL] LOSS : 0.0004461903008632362 [SCORE] : 1.0\n",
      "[246/1000]\n",
      "- [TRAIN] LOSS : 0.0003066928426657493 [SCORE] : 0.6\n",
      "[246/1000]\n",
      "- [VAL] LOSS : 0.00044127926230430603 [SCORE] : 1.0\n",
      "[247/1000]\n",
      "- [TRAIN] LOSS : 0.0003035108248392741 [SCORE] : 0.6\n",
      "[247/1000]\n",
      "- [VAL] LOSS : 0.0004364040505606681 [SCORE] : 1.0\n",
      "[248/1000]\n",
      "- [TRAIN] LOSS : 0.0003001832209217052 [SCORE] : 0.6\n",
      "[248/1000]\n",
      "- [VAL] LOSS : 0.00043164085946045816 [SCORE] : 1.0\n",
      "[249/1000]\n",
      "- [TRAIN] LOSS : 0.0002970882022054866 [SCORE] : 0.6\n",
      "[249/1000]\n",
      "- [VAL] LOSS : 0.00042693022987805307 [SCORE] : 1.0\n",
      "[250/1000]\n",
      "- [TRAIN] LOSS : 0.0002937677869340405 [SCORE] : 0.6\n",
      "[250/1000]\n",
      "- [VAL] LOSS : 0.00042234951979480684 [SCORE] : 1.0\n",
      "[251/1000]\n",
      "- [TRAIN] LOSS : 0.000290826236596331 [SCORE] : 0.6\n",
      "[251/1000]\n",
      "- [VAL] LOSS : 0.00041776237776502967 [SCORE] : 1.0\n",
      "[252/1000]\n",
      "- [TRAIN] LOSS : 0.0002877406950574368 [SCORE] : 0.6\n",
      "[252/1000]\n",
      "- [VAL] LOSS : 0.00041327005601488054 [SCORE] : 1.0\n",
      "[253/1000]\n",
      "- [TRAIN] LOSS : 0.00028472245903685687 [SCORE] : 0.6\n",
      "[253/1000]\n",
      "- [VAL] LOSS : 0.0004088729911018163 [SCORE] : 1.0\n",
      "[254/1000]\n",
      "- [TRAIN] LOSS : 0.0002817363313321645 [SCORE] : 0.6\n",
      "[254/1000]\n",
      "- [VAL] LOSS : 0.0004045687092002481 [SCORE] : 1.0\n",
      "[255/1000]\n",
      "- [TRAIN] LOSS : 0.0002789794671116397 [SCORE] : 0.6\n",
      "[255/1000]\n",
      "- [VAL] LOSS : 0.0004002080240752548 [SCORE] : 1.0\n",
      "[256/1000]\n",
      "- [TRAIN] LOSS : 0.00027604900242295116 [SCORE] : 0.6\n",
      "[256/1000]\n",
      "- [VAL] LOSS : 0.00039596232818439603 [SCORE] : 1.0\n",
      "[257/1000]\n",
      "- [TRAIN] LOSS : 0.00027305937934822094 [SCORE] : 0.6\n",
      "[257/1000]\n",
      "- [VAL] LOSS : 0.00039189093513414264 [SCORE] : 1.0\n",
      "[258/1000]\n",
      "- [TRAIN] LOSS : 0.00027044363184055935 [SCORE] : 0.6\n",
      "[258/1000]\n",
      "- [VAL] LOSS : 0.00038774037966504693 [SCORE] : 1.0\n",
      "[259/1000]\n",
      "- [TRAIN] LOSS : 0.00026763154407187056 [SCORE] : 0.6\n",
      "[259/1000]\n",
      "- [VAL] LOSS : 0.00038371136179193854 [SCORE] : 1.0\n",
      "[260/1000]\n",
      "- [TRAIN] LOSS : 0.00026503185605785496 [SCORE] : 0.6\n",
      "[260/1000]\n",
      "- [VAL] LOSS : 0.0003796398814301938 [SCORE] : 1.0\n",
      "[261/1000]\n",
      "- [TRAIN] LOSS : 0.0002621739152042816 [SCORE] : 0.6\n",
      "[261/1000]\n",
      "- [VAL] LOSS : 0.0003757579543162137 [SCORE] : 1.0\n",
      "[262/1000]\n",
      "- [TRAIN] LOSS : 0.00025967287947423754 [SCORE] : 0.6\n",
      "[262/1000]\n",
      "- [VAL] LOSS : 0.0003718482912518084 [SCORE] : 1.0\n",
      "[263/1000]\n",
      "- [TRAIN] LOSS : 0.0002569217758718878 [SCORE] : 0.6\n",
      "[263/1000]\n",
      "- [VAL] LOSS : 0.0003680828958749771 [SCORE] : 1.0\n",
      "[264/1000]\n",
      "- [TRAIN] LOSS : 0.0002545244535819317 [SCORE] : 0.6\n",
      "[264/1000]\n",
      "- [VAL] LOSS : 0.00036426595761440694 [SCORE] : 1.0\n",
      "[265/1000]\n",
      "- [TRAIN] LOSS : 0.0002519467884364227 [SCORE] : 0.6\n",
      "[265/1000]\n",
      "- [VAL] LOSS : 0.00036055335658602417 [SCORE] : 1.0\n",
      "[266/1000]\n",
      "- [TRAIN] LOSS : 0.0002493025579800208 [SCORE] : 0.6\n",
      "[266/1000]\n",
      "- [VAL] LOSS : 0.0003569937834981829 [SCORE] : 1.0\n",
      "[267/1000]\n",
      "- [TRAIN] LOSS : 0.00024704775035691757 [SCORE] : 0.6\n",
      "[267/1000]\n",
      "- [VAL] LOSS : 0.0003533255367074162 [SCORE] : 1.0\n",
      "[268/1000]\n",
      "- [TRAIN] LOSS : 0.00024457248606874296 [SCORE] : 0.6\n",
      "[268/1000]\n",
      "- [VAL] LOSS : 0.00034971945569850504 [SCORE] : 1.0\n",
      "[269/1000]\n",
      "- [TRAIN] LOSS : 0.00024212824743396292 [SCORE] : 0.6\n",
      "[269/1000]\n",
      "- [VAL] LOSS : 0.00034620403312146664 [SCORE] : 1.0\n",
      "[270/1000]\n",
      "- [TRAIN] LOSS : 0.00023966448788996785 [SCORE] : 0.6\n",
      "[270/1000]\n",
      "- [VAL] LOSS : 0.00034283840795978904 [SCORE] : 1.0\n",
      "[271/1000]\n",
      "- [TRAIN] LOSS : 0.00023753828330275913 [SCORE] : 0.6\n",
      "[271/1000]\n",
      "- [VAL] LOSS : 0.0003393632359802723 [SCORE] : 1.0\n",
      "[272/1000]\n",
      "- [TRAIN] LOSS : 0.00023527227943607917 [SCORE] : 0.6\n",
      "[272/1000]\n",
      "- [VAL] LOSS : 0.00033590293605811894 [SCORE] : 1.0\n",
      "[273/1000]\n",
      "- [TRAIN] LOSS : 0.00023285307397600264 [SCORE] : 0.6\n",
      "[273/1000]\n",
      "- [VAL] LOSS : 0.00033257465111091733 [SCORE] : 1.0\n",
      "[274/1000]\n",
      "- [TRAIN] LOSS : 0.0002305166427201281 [SCORE] : 0.6\n",
      "[274/1000]\n",
      "- [VAL] LOSS : 0.0003294068737886846 [SCORE] : 1.0\n",
      "[275/1000]\n",
      "- [TRAIN] LOSS : 0.00022848070754359165 [SCORE] : 0.6\n",
      "[275/1000]\n",
      "- [VAL] LOSS : 0.0003261295787524432 [SCORE] : 1.0\n",
      "[276/1000]\n",
      "- [TRAIN] LOSS : 0.0002261514726948614 [SCORE] : 0.6\n",
      "[276/1000]\n",
      "- [VAL] LOSS : 0.00032299989834427834 [SCORE] : 1.0\n",
      "[277/1000]\n",
      "- [TRAIN] LOSS : 0.0002241590293124318 [SCORE] : 0.6\n",
      "[277/1000]\n",
      "- [VAL] LOSS : 0.00031976422178559005 [SCORE] : 1.0\n",
      "[278/1000]\n",
      "- [TRAIN] LOSS : 0.00022188269649632276 [SCORE] : 0.6\n",
      "[278/1000]\n",
      "- [VAL] LOSS : 0.0003167126269545406 [SCORE] : 1.0\n",
      "[279/1000]\n",
      "- [TRAIN] LOSS : 0.00021980066182247053 [SCORE] : 0.6\n",
      "[279/1000]\n",
      "- [VAL] LOSS : 0.0003136753512080759 [SCORE] : 1.0\n",
      "[280/1000]\n",
      "- [TRAIN] LOSS : 0.00021787131360421577 [SCORE] : 0.6\n",
      "[280/1000]\n",
      "- [VAL] LOSS : 0.0003105499781668186 [SCORE] : 1.0\n",
      "[281/1000]\n",
      "- [TRAIN] LOSS : 0.00021569915018820513 [SCORE] : 0.6\n",
      "[281/1000]\n",
      "- [VAL] LOSS : 0.00030761241214349866 [SCORE] : 1.0\n",
      "[282/1000]\n",
      "- [TRAIN] LOSS : 0.00021357408550102264 [SCORE] : 0.6\n",
      "[282/1000]\n",
      "- [VAL] LOSS : 0.000304762099403888 [SCORE] : 1.0\n",
      "[283/1000]\n",
      "- [TRAIN] LOSS : 0.00021178240422159433 [SCORE] : 0.6\n",
      "[283/1000]\n",
      "- [VAL] LOSS : 0.00030177980079315603 [SCORE] : 1.0\n",
      "[284/1000]\n",
      "- [TRAIN] LOSS : 0.00020965873845852913 [SCORE] : 0.6\n",
      "[284/1000]\n",
      "- [VAL] LOSS : 0.00029896441265009344 [SCORE] : 1.0\n",
      "[285/1000]\n",
      "- [TRAIN] LOSS : 0.00020785303301333138 [SCORE] : 0.6\n",
      "[285/1000]\n",
      "- [VAL] LOSS : 0.00029602969880215824 [SCORE] : 1.0\n",
      "[286/1000]\n",
      "- [TRAIN] LOSS : 0.00020581944069514673 [SCORE] : 0.6\n",
      "[286/1000]\n",
      "- [VAL] LOSS : 0.0002932676870841533 [SCORE] : 1.0\n",
      "[287/1000]\n",
      "- [TRAIN] LOSS : 0.00020383227771768967 [SCORE] : 0.6\n",
      "[287/1000]\n",
      "- [VAL] LOSS : 0.0002905979927163571 [SCORE] : 1.0\n",
      "[288/1000]\n",
      "- [TRAIN] LOSS : 0.00020216155292776723 [SCORE] : 0.6\n",
      "[288/1000]\n",
      "- [VAL] LOSS : 0.00028779605054296553 [SCORE] : 1.0\n",
      "[289/1000]\n",
      "- [TRAIN] LOSS : 0.0002002499211812392 [SCORE] : 0.6\n",
      "[289/1000]\n",
      "- [VAL] LOSS : 0.00028505767113529146 [SCORE] : 1.0\n",
      "[290/1000]\n",
      "- [TRAIN] LOSS : 0.00019832379087650527 [SCORE] : 0.6\n",
      "[290/1000]\n",
      "- [VAL] LOSS : 0.00028245654539205134 [SCORE] : 1.0\n",
      "[291/1000]\n",
      "- [TRAIN] LOSS : 0.0001965742383617908 [SCORE] : 0.6\n",
      "[291/1000]\n",
      "- [VAL] LOSS : 0.0002798181667458266 [SCORE] : 1.0\n",
      "[292/1000]\n",
      "- [TRAIN] LOSS : 0.00019479921514478822 [SCORE] : 0.6\n",
      "[292/1000]\n",
      "- [VAL] LOSS : 0.00027720758225768805 [SCORE] : 1.0\n",
      "[293/1000]\n",
      "- [TRAIN] LOSS : 0.00019294841428442547 [SCORE] : 0.6\n",
      "[293/1000]\n",
      "- [VAL] LOSS : 0.0002747119578998536 [SCORE] : 1.0\n",
      "[294/1000]\n",
      "- [TRAIN] LOSS : 0.00019134133666132887 [SCORE] : 0.6\n",
      "[294/1000]\n",
      "- [VAL] LOSS : 0.0002720846969168633 [SCORE] : 1.0\n",
      "[295/1000]\n",
      "- [TRAIN] LOSS : 0.00018951962410937995 [SCORE] : 0.6\n",
      "[295/1000]\n",
      "- [VAL] LOSS : 0.0002696137235034257 [SCORE] : 1.0\n",
      "[296/1000]\n",
      "- [TRAIN] LOSS : 0.00018776614063729843 [SCORE] : 0.6\n",
      "[296/1000]\n",
      "- [VAL] LOSS : 0.000267227238509804 [SCORE] : 1.0\n",
      "[297/1000]\n",
      "- [TRAIN] LOSS : 0.0001862530164847461 [SCORE] : 0.6\n",
      "[297/1000]\n",
      "- [VAL] LOSS : 0.0002646971261128783 [SCORE] : 1.0\n",
      "[298/1000]\n",
      "- [TRAIN] LOSS : 0.0001844776813716938 [SCORE] : 0.6\n",
      "[298/1000]\n",
      "- [VAL] LOSS : 0.0002623138134367764 [SCORE] : 1.0\n",
      "[299/1000]\n",
      "- [TRAIN] LOSS : 0.00018277163423287371 [SCORE] : 0.6\n",
      "[299/1000]\n",
      "- [VAL] LOSS : 0.0002600081206765026 [SCORE] : 1.0\n",
      "[300/1000]\n",
      "- [TRAIN] LOSS : 0.0001813185711701711 [SCORE] : 0.6\n",
      "[300/1000]\n",
      "- [VAL] LOSS : 0.0002575567632447928 [SCORE] : 1.0\n",
      "[301/1000]\n",
      "- [TRAIN] LOSS : 0.00017960969174358373 [SCORE] : 0.6\n",
      "[301/1000]\n",
      "- [VAL] LOSS : 0.00025525636738166213 [SCORE] : 1.0\n",
      "[302/1000]\n",
      "- [TRAIN] LOSS : 0.0001779640141952162 [SCORE] : 0.6\n",
      "[302/1000]\n",
      "- [VAL] LOSS : 0.00025303472648374736 [SCORE] : 1.0\n",
      "[303/1000]\n",
      "- [TRAIN] LOSS : 0.00017655319776774074 [SCORE] : 0.6\n",
      "[303/1000]\n",
      "- [VAL] LOSS : 0.0002506676537450403 [SCORE] : 1.0\n",
      "[304/1000]\n",
      "- [TRAIN] LOSS : 0.00017492476957462106 [SCORE] : 0.6\n",
      "[304/1000]\n",
      "- [VAL] LOSS : 0.000248436292167753 [SCORE] : 1.0\n",
      "[305/1000]\n",
      "- [TRAIN] LOSS : 0.00017332460217100258 [SCORE] : 0.6\n",
      "[305/1000]\n",
      "- [VAL] LOSS : 0.0002462931734044105 [SCORE] : 1.0\n",
      "[306/1000]\n",
      "- [TRAIN] LOSS : 0.00017185862379847093 [SCORE] : 0.6\n",
      "[306/1000]\n",
      "- [VAL] LOSS : 0.00024410570040345192 [SCORE] : 1.0\n",
      "[307/1000]\n",
      "- [TRAIN] LOSS : 0.00017039226077031344 [SCORE] : 0.6\n",
      "[307/1000]\n",
      "- [VAL] LOSS : 0.0002419248194200918 [SCORE] : 1.0\n",
      "[308/1000]\n",
      "- [TRAIN] LOSS : 0.00016893610154511407 [SCORE] : 0.6\n",
      "[308/1000]\n",
      "- [VAL] LOSS : 0.00023972123744897544 [SCORE] : 1.0\n",
      "[309/1000]\n",
      "- [TRAIN] LOSS : 0.00016740210655067736 [SCORE] : 0.6\n",
      "[309/1000]\n",
      "- [VAL] LOSS : 0.00023763265926390886 [SCORE] : 1.0\n",
      "[310/1000]\n",
      "- [TRAIN] LOSS : 0.0001659222374049326 [SCORE] : 0.6\n",
      "[310/1000]\n",
      "- [VAL] LOSS : 0.00023561435227748007 [SCORE] : 1.0\n",
      "[311/1000]\n",
      "- [TRAIN] LOSS : 0.0001645490798788766 [SCORE] : 0.6\n",
      "[311/1000]\n",
      "- [VAL] LOSS : 0.0002335512253921479 [SCORE] : 1.0\n",
      "[312/1000]\n",
      "- [TRAIN] LOSS : 0.00016317727034523462 [SCORE] : 0.6\n",
      "[312/1000]\n",
      "- [VAL] LOSS : 0.00023144808073993772 [SCORE] : 1.0\n",
      "[313/1000]\n",
      "- [TRAIN] LOSS : 0.00016171248959532628 [SCORE] : 0.6\n",
      "[313/1000]\n",
      "- [VAL] LOSS : 0.000229460492846556 [SCORE] : 1.0\n",
      "[314/1000]\n",
      "- [TRAIN] LOSS : 0.00016029063942066084 [SCORE] : 0.6\n",
      "[314/1000]\n",
      "- [VAL] LOSS : 0.00022753432858735323 [SCORE] : 1.0\n",
      "[315/1000]\n",
      "- [TRAIN] LOSS : 0.00015907626608774688 [SCORE] : 0.6\n",
      "[315/1000]\n",
      "- [VAL] LOSS : 0.00022545523825101554 [SCORE] : 1.0\n",
      "[316/1000]\n",
      "- [TRAIN] LOSS : 0.00015764020354254172 [SCORE] : 0.6\n",
      "[316/1000]\n",
      "- [VAL] LOSS : 0.00022350838116835803 [SCORE] : 1.0\n",
      "[317/1000]\n",
      "- [TRAIN] LOSS : 0.0001562525882036425 [SCORE] : 0.6\n",
      "[317/1000]\n",
      "- [VAL] LOSS : 0.00022164281108416617 [SCORE] : 1.0\n",
      "[318/1000]\n",
      "- [TRAIN] LOSS : 0.00015498261054744945 [SCORE] : 0.6\n",
      "[318/1000]\n",
      "- [VAL] LOSS : 0.00021971786918584257 [SCORE] : 1.0\n",
      "[319/1000]\n",
      "- [TRAIN] LOSS : 0.00015364877132621282 [SCORE] : 0.6\n",
      "[319/1000]\n",
      "- [VAL] LOSS : 0.00021787321020383388 [SCORE] : 1.0\n",
      "[320/1000]\n",
      "- [TRAIN] LOSS : 0.00015231770812533795 [SCORE] : 0.6\n",
      "[320/1000]\n",
      "- [VAL] LOSS : 0.00021607095550280064 [SCORE] : 1.0\n",
      "[321/1000]\n",
      "- [TRAIN] LOSS : 0.0001511761355989923 [SCORE] : 0.6\n",
      "[321/1000]\n",
      "- [VAL] LOSS : 0.00021411935449577868 [SCORE] : 1.0\n",
      "[322/1000]\n",
      "- [TRAIN] LOSS : 0.0001498340260392676 [SCORE] : 0.6\n",
      "[322/1000]\n",
      "- [VAL] LOSS : 0.0002122842997778207 [SCORE] : 1.0\n",
      "[323/1000]\n",
      "- [TRAIN] LOSS : 0.00014854709055119505 [SCORE] : 0.6\n",
      "[323/1000]\n",
      "- [VAL] LOSS : 0.00021053159434814006 [SCORE] : 1.0\n",
      "[324/1000]\n",
      "- [TRAIN] LOSS : 0.00014728579165724416 [SCORE] : 0.6\n",
      "[324/1000]\n",
      "- [VAL] LOSS : 0.00020881861564703286 [SCORE] : 1.0\n",
      "[325/1000]\n",
      "- [TRAIN] LOSS : 0.00014619474968640133 [SCORE] : 0.6\n",
      "[325/1000]\n",
      "- [VAL] LOSS : 0.00020693782425951213 [SCORE] : 1.0\n",
      "[326/1000]\n",
      "- [TRAIN] LOSS : 0.00014491747715510427 [SCORE] : 0.6\n",
      "[326/1000]\n",
      "- [VAL] LOSS : 0.00020518232486210763 [SCORE] : 1.0\n",
      "[327/1000]\n",
      "- [TRAIN] LOSS : 0.0001436701655620709 [SCORE] : 0.6\n",
      "[327/1000]\n",
      "- [VAL] LOSS : 0.00020350060367491096 [SCORE] : 1.0\n",
      "[328/1000]\n",
      "- [TRAIN] LOSS : 0.00014246569965810826 [SCORE] : 0.6\n",
      "[328/1000]\n",
      "- [VAL] LOSS : 0.00020184808818157762 [SCORE] : 1.0\n",
      "[329/1000]\n",
      "- [TRAIN] LOSS : 0.00014135340170469136 [SCORE] : 0.6\n",
      "[329/1000]\n",
      "- [VAL] LOSS : 0.00020015575864817947 [SCORE] : 1.0\n",
      "[330/1000]\n",
      "- [TRAIN] LOSS : 0.00014016590333388497 [SCORE] : 0.6\n",
      "[330/1000]\n",
      "- [VAL] LOSS : 0.0001985139533644542 [SCORE] : 1.0\n",
      "[331/1000]\n",
      "- [TRAIN] LOSS : 0.00013899128340805572 [SCORE] : 0.6\n",
      "[331/1000]\n",
      "- [VAL] LOSS : 0.00019691057968884706 [SCORE] : 1.0\n",
      "[332/1000]\n",
      "- [TRAIN] LOSS : 0.00013797642410888025 [SCORE] : 0.6\n",
      "[332/1000]\n",
      "- [VAL] LOSS : 0.00019515803433023393 [SCORE] : 1.0\n",
      "[333/1000]\n",
      "- [TRAIN] LOSS : 0.0001367857345030643 [SCORE] : 0.6\n",
      "[333/1000]\n",
      "- [VAL] LOSS : 0.00019352759409230202 [SCORE] : 1.0\n",
      "[334/1000]\n",
      "- [TRAIN] LOSS : 0.0001356442783920405 [SCORE] : 0.6\n",
      "[334/1000]\n",
      "- [VAL] LOSS : 0.00019195170898456126 [SCORE] : 1.0\n",
      "[335/1000]\n",
      "- [TRAIN] LOSS : 0.0001345209030356879 [SCORE] : 0.6\n",
      "[335/1000]\n",
      "- [VAL] LOSS : 0.00019042387430090457 [SCORE] : 1.0\n",
      "[336/1000]\n",
      "- [TRAIN] LOSS : 0.00013342989501931394 [SCORE] : 0.6\n",
      "[336/1000]\n",
      "- [VAL] LOSS : 0.00018890331557486206 [SCORE] : 1.0\n",
      "[337/1000]\n",
      "- [TRAIN] LOSS : 0.00013239218678791077 [SCORE] : 0.6\n",
      "[337/1000]\n",
      "- [VAL] LOSS : 0.00018734850164037198 [SCORE] : 1.0\n",
      "[338/1000]\n",
      "- [TRAIN] LOSS : 0.0001313608712128674 [SCORE] : 0.6\n",
      "[338/1000]\n",
      "- [VAL] LOSS : 0.00018573809938970953 [SCORE] : 1.0\n",
      "[339/1000]\n",
      "- [TRAIN] LOSS : 0.00013026493882838016 [SCORE] : 0.6\n",
      "[339/1000]\n",
      "- [VAL] LOSS : 0.00018421800632495433 [SCORE] : 1.0\n",
      "[340/1000]\n",
      "- [TRAIN] LOSS : 0.000129198780147514 [SCORE] : 0.6\n",
      "[340/1000]\n",
      "- [VAL] LOSS : 0.00018274845206178725 [SCORE] : 1.0\n",
      "[341/1000]\n",
      "- [TRAIN] LOSS : 0.0001281608536373824 [SCORE] : 0.6\n",
      "[341/1000]\n",
      "- [VAL] LOSS : 0.00018130560056306422 [SCORE] : 1.0\n",
      "[342/1000]\n",
      "- [TRAIN] LOSS : 0.00012712001868446046 [SCORE] : 0.6\n",
      "[342/1000]\n",
      "- [VAL] LOSS : 0.00017987324099522084 [SCORE] : 1.0\n",
      "[343/1000]\n",
      "- [TRAIN] LOSS : 0.00012615778978215532 [SCORE] : 0.6\n",
      "[343/1000]\n",
      "- [VAL] LOSS : 0.0001784048945410177 [SCORE] : 1.0\n",
      "[344/1000]\n",
      "- [TRAIN] LOSS : 0.00012512608324565614 [SCORE] : 0.6\n",
      "[344/1000]\n",
      "- [VAL] LOSS : 0.000176968882442452 [SCORE] : 1.0\n",
      "[345/1000]\n",
      "- [TRAIN] LOSS : 0.00012412917179365952 [SCORE] : 0.6\n",
      "[345/1000]\n",
      "- [VAL] LOSS : 0.00017558214312884957 [SCORE] : 1.0\n",
      "[346/1000]\n",
      "- [TRAIN] LOSS : 0.00012320944952080027 [SCORE] : 0.6\n",
      "[346/1000]\n",
      "- [VAL] LOSS : 0.0001741132145980373 [SCORE] : 1.0\n",
      "[347/1000]\n",
      "- [TRAIN] LOSS : 0.0001221954478144956 [SCORE] : 0.6\n",
      "[347/1000]\n",
      "- [VAL] LOSS : 0.00017270565149374306 [SCORE] : 1.0\n",
      "[348/1000]\n",
      "- [TRAIN] LOSS : 0.0001212075600051321 [SCORE] : 0.6\n",
      "[348/1000]\n",
      "- [VAL] LOSS : 0.0001713558885967359 [SCORE] : 1.0\n",
      "[349/1000]\n",
      "- [TRAIN] LOSS : 0.00012029663630528376 [SCORE] : 0.6\n",
      "[349/1000]\n",
      "- [VAL] LOSS : 0.00016996181511785835 [SCORE] : 1.0\n",
      "[350/1000]\n",
      "- [TRAIN] LOSS : 0.00011932152847293764 [SCORE] : 0.6\n",
      "[350/1000]\n",
      "- [VAL] LOSS : 0.0001686143659753725 [SCORE] : 1.0\n",
      "[351/1000]\n",
      "- [TRAIN] LOSS : 0.00011837589991046116 [SCORE] : 0.6\n",
      "[351/1000]\n",
      "- [VAL] LOSS : 0.0001673132792348042 [SCORE] : 1.0\n",
      "[352/1000]\n",
      "- [TRAIN] LOSS : 0.00011744372604880483 [SCORE] : 0.6\n",
      "[352/1000]\n",
      "- [VAL] LOSS : 0.0001660193520365283 [SCORE] : 1.0\n",
      "[353/1000]\n",
      "- [TRAIN] LOSS : 0.00011657966048611949 [SCORE] : 0.6\n",
      "[353/1000]\n",
      "- [VAL] LOSS : 0.00016466299712192267 [SCORE] : 1.0\n",
      "[354/1000]\n",
      "- [TRAIN] LOSS : 0.0001156446606425258 [SCORE] : 0.6\n",
      "[354/1000]\n",
      "- [VAL] LOSS : 0.000163370743393898 [SCORE] : 1.0\n",
      "[355/1000]\n",
      "- [TRAIN] LOSS : 0.00011473097935474167 [SCORE] : 0.6\n",
      "[355/1000]\n",
      "- [VAL] LOSS : 0.0001621140690986067 [SCORE] : 1.0\n",
      "[356/1000]\n",
      "- [TRAIN] LOSS : 0.00011383567471057177 [SCORE] : 0.6\n",
      "[356/1000]\n",
      "- [VAL] LOSS : 0.00016086599498521537 [SCORE] : 1.0\n",
      "[357/1000]\n",
      "- [TRAIN] LOSS : 0.0001130242157766285 [SCORE] : 0.6\n",
      "[357/1000]\n",
      "- [VAL] LOSS : 0.00015953984984662384 [SCORE] : 1.0\n",
      "[358/1000]\n",
      "- [TRAIN] LOSS : 0.00011211821984034032 [SCORE] : 0.6\n",
      "[358/1000]\n",
      "- [VAL] LOSS : 0.000158281676704064 [SCORE] : 1.0\n",
      "[359/1000]\n",
      "- [TRAIN] LOSS : 0.00011123161918173234 [SCORE] : 0.6\n",
      "[359/1000]\n",
      "- [VAL] LOSS : 0.0001570610620547086 [SCORE] : 1.0\n",
      "[360/1000]\n",
      "- [TRAIN] LOSS : 0.0001103712449548766 [SCORE] : 0.6\n",
      "[360/1000]\n",
      "- [VAL] LOSS : 0.00015586381778120995 [SCORE] : 1.0\n",
      "[361/1000]\n",
      "- [TRAIN] LOSS : 0.00010956429468933493 [SCORE] : 0.6\n",
      "[361/1000]\n",
      "- [VAL] LOSS : 0.00015460990834981203 [SCORE] : 1.0\n",
      "[362/1000]\n",
      "- [TRAIN] LOSS : 0.00010870712576434016 [SCORE] : 0.6\n",
      "[362/1000]\n",
      "- [VAL] LOSS : 0.00015340973914135247 [SCORE] : 1.0\n",
      "[363/1000]\n",
      "- [TRAIN] LOSS : 0.00010786354590284949 [SCORE] : 0.6\n",
      "[363/1000]\n",
      "- [VAL] LOSS : 0.00015224590606521815 [SCORE] : 1.0\n",
      "[364/1000]\n",
      "- [TRAIN] LOSS : 0.0001070401286900354 [SCORE] : 0.6\n",
      "[364/1000]\n",
      "- [VAL] LOSS : 0.00015110106323845685 [SCORE] : 1.0\n",
      "[365/1000]\n",
      "- [TRAIN] LOSS : 0.00010622264502065566 [SCORE] : 0.6\n",
      "[365/1000]\n",
      "- [VAL] LOSS : 0.00014995377568993717 [SCORE] : 1.0\n",
      "[366/1000]\n",
      "- [TRAIN] LOSS : 0.0001054249233372199 [SCORE] : 0.6\n",
      "[366/1000]\n",
      "- [VAL] LOSS : 0.00014881175593473017 [SCORE] : 1.0\n",
      "[367/1000]\n",
      "- [TRAIN] LOSS : 0.00010465998445094252 [SCORE] : 0.6\n",
      "[367/1000]\n",
      "- [VAL] LOSS : 0.00014762827777303755 [SCORE] : 1.0\n",
      "[368/1000]\n",
      "- [TRAIN] LOSS : 0.00010384691898555806 [SCORE] : 0.6\n",
      "[368/1000]\n",
      "- [VAL] LOSS : 0.00014648782962467521 [SCORE] : 1.0\n",
      "[369/1000]\n",
      "- [TRAIN] LOSS : 0.00010305069105622048 [SCORE] : 0.6\n",
      "[369/1000]\n",
      "- [VAL] LOSS : 0.00014538632240146399 [SCORE] : 1.0\n",
      "[370/1000]\n",
      "- [TRAIN] LOSS : 0.0001022720362622446 [SCORE] : 0.6\n",
      "[370/1000]\n",
      "- [VAL] LOSS : 0.00014428864233195782 [SCORE] : 1.0\n",
      "[371/1000]\n",
      "- [TRAIN] LOSS : 0.00010149750936155518 [SCORE] : 0.6\n",
      "[371/1000]\n",
      "- [VAL] LOSS : 0.00014321219350676984 [SCORE] : 1.0\n",
      "[372/1000]\n",
      "- [TRAIN] LOSS : 0.00010078456640864412 [SCORE] : 0.6\n",
      "[372/1000]\n",
      "- [VAL] LOSS : 0.00014205485058482736 [SCORE] : 1.0\n",
      "[373/1000]\n",
      "- [TRAIN] LOSS : 0.00010000616093748249 [SCORE] : 0.6\n",
      "[373/1000]\n",
      "- [VAL] LOSS : 0.0001409561518812552 [SCORE] : 1.0\n",
      "[374/1000]\n",
      "- [TRAIN] LOSS : 9.924464878470947e-05 [SCORE] : 0.6\n",
      "[374/1000]\n",
      "- [VAL] LOSS : 0.00013989463332109153 [SCORE] : 1.0\n",
      "[375/1000]\n",
      "- [TRAIN] LOSS : 9.849718238304679e-05 [SCORE] : 0.6\n",
      "[375/1000]\n",
      "- [VAL] LOSS : 0.00013885686348658055 [SCORE] : 1.0\n",
      "[376/1000]\n",
      "- [TRAIN] LOSS : 9.77596348093357e-05 [SCORE] : 0.6\n",
      "[376/1000]\n",
      "- [VAL] LOSS : 0.0001378220913466066 [SCORE] : 1.0\n",
      "[377/1000]\n",
      "- [TRAIN] LOSS : 9.704326415279259e-05 [SCORE] : 0.6\n",
      "[377/1000]\n",
      "- [VAL] LOSS : 0.00013679104449693114 [SCORE] : 1.0\n",
      "[378/1000]\n",
      "- [TRAIN] LOSS : 9.63151275451916e-05 [SCORE] : 0.6\n",
      "[378/1000]\n",
      "- [VAL] LOSS : 0.00013577639765571803 [SCORE] : 1.0\n",
      "[379/1000]\n",
      "- [TRAIN] LOSS : 9.56425275944639e-05 [SCORE] : 0.6\n",
      "[379/1000]\n",
      "- [VAL] LOSS : 0.00013470198609866202 [SCORE] : 1.0\n",
      "[380/1000]\n",
      "- [TRAIN] LOSS : 9.491206001257523e-05 [SCORE] : 0.6\n",
      "[380/1000]\n",
      "- [VAL] LOSS : 0.00013368367217481136 [SCORE] : 1.0\n",
      "[381/1000]\n",
      "- [TRAIN] LOSS : 9.420150066337858e-05 [SCORE] : 0.6\n",
      "[381/1000]\n",
      "- [VAL] LOSS : 0.00013269133341964334 [SCORE] : 1.0\n",
      "[382/1000]\n",
      "- [TRAIN] LOSS : 9.350199034088291e-05 [SCORE] : 0.6\n",
      "[382/1000]\n",
      "- [VAL] LOSS : 0.00013171751925256103 [SCORE] : 1.0\n",
      "[383/1000]\n",
      "- [TRAIN] LOSS : 9.281228218848507e-05 [SCORE] : 0.6\n",
      "[383/1000]\n",
      "- [VAL] LOSS : 0.00013074812886770815 [SCORE] : 1.0\n",
      "[384/1000]\n",
      "- [TRAIN] LOSS : 9.21316316331892e-05 [SCORE] : 0.6\n",
      "[384/1000]\n",
      "- [VAL] LOSS : 0.00012977831647731364 [SCORE] : 1.0\n",
      "[385/1000]\n",
      "- [TRAIN] LOSS : 9.146431499781707e-05 [SCORE] : 0.6\n",
      "[385/1000]\n",
      "- [VAL] LOSS : 0.0001288172061322257 [SCORE] : 1.0\n",
      "[386/1000]\n",
      "- [TRAIN] LOSS : 9.079047182846504e-05 [SCORE] : 0.6\n",
      "[386/1000]\n",
      "- [VAL] LOSS : 0.00012788349704351276 [SCORE] : 1.0\n",
      "[387/1000]\n",
      "- [TRAIN] LOSS : 9.012552084944522e-05 [SCORE] : 0.6\n",
      "[387/1000]\n",
      "- [VAL] LOSS : 0.00012694191536866128 [SCORE] : 1.0\n",
      "[388/1000]\n",
      "- [TRAIN] LOSS : 8.946956319656844e-05 [SCORE] : 0.6\n",
      "[388/1000]\n",
      "- [VAL] LOSS : 0.00012600363697856665 [SCORE] : 1.0\n",
      "[389/1000]\n",
      "- [TRAIN] LOSS : 8.881748435669578e-05 [SCORE] : 0.6\n",
      "[389/1000]\n",
      "- [VAL] LOSS : 0.0001250876666745171 [SCORE] : 1.0\n",
      "[390/1000]\n",
      "- [TRAIN] LOSS : 8.820560785049262e-05 [SCORE] : 0.6\n",
      "[390/1000]\n",
      "- [VAL] LOSS : 0.00012411409988999367 [SCORE] : 1.0\n",
      "[391/1000]\n",
      "- [TRAIN] LOSS : 8.755154703976586e-05 [SCORE] : 0.6\n",
      "[391/1000]\n",
      "- [VAL] LOSS : 0.00012318782682996243 [SCORE] : 1.0\n",
      "[392/1000]\n",
      "- [TRAIN] LOSS : 8.69073638265642e-05 [SCORE] : 0.6\n",
      "[392/1000]\n",
      "- [VAL] LOSS : 0.00012227226397953928 [SCORE] : 1.0\n",
      "[393/1000]\n",
      "- [TRAIN] LOSS : 8.62731098701867e-05 [SCORE] : 0.6\n",
      "[393/1000]\n",
      "- [VAL] LOSS : 0.00012138907186454162 [SCORE] : 1.0\n",
      "[394/1000]\n",
      "- [TRAIN] LOSS : 8.564722472025703e-05 [SCORE] : 0.6\n",
      "[394/1000]\n",
      "- [VAL] LOSS : 0.00012050687655573711 [SCORE] : 1.0\n",
      "[395/1000]\n",
      "- [TRAIN] LOSS : 8.503177765912066e-05 [SCORE] : 0.6\n",
      "[395/1000]\n",
      "- [VAL] LOSS : 0.00011962834105361253 [SCORE] : 1.0\n",
      "[396/1000]\n",
      "- [TRAIN] LOSS : 8.442515051380421e-05 [SCORE] : 0.6\n",
      "[396/1000]\n",
      "- [VAL] LOSS : 0.0001187615780509077 [SCORE] : 1.0\n",
      "[397/1000]\n",
      "- [TRAIN] LOSS : 8.381473938546454e-05 [SCORE] : 0.6\n",
      "[397/1000]\n",
      "- [VAL] LOSS : 0.00011789630661951378 [SCORE] : 1.0\n",
      "[398/1000]\n",
      "- [TRAIN] LOSS : 8.321276764036156e-05 [SCORE] : 0.6\n",
      "[398/1000]\n",
      "- [VAL] LOSS : 0.00011703627387760207 [SCORE] : 1.0\n",
      "[399/1000]\n",
      "- [TRAIN] LOSS : 8.261694189665529e-05 [SCORE] : 0.6\n",
      "[399/1000]\n",
      "- [VAL] LOSS : 0.00011620174336712807 [SCORE] : 1.0\n",
      "[400/1000]\n",
      "- [TRAIN] LOSS : 8.20291349858356e-05 [SCORE] : 0.6\n",
      "[400/1000]\n",
      "- [VAL] LOSS : 0.00011535441444721073 [SCORE] : 1.0\n",
      "[401/1000]\n",
      "- [TRAIN] LOSS : 8.144314027352569e-05 [SCORE] : 0.6\n",
      "[401/1000]\n",
      "- [VAL] LOSS : 0.00011451893078628927 [SCORE] : 1.0\n",
      "[402/1000]\n",
      "- [TRAIN] LOSS : 8.086205828779687e-05 [SCORE] : 0.6\n",
      "[402/1000]\n",
      "- [VAL] LOSS : 0.00011370141146471724 [SCORE] : 1.0\n",
      "[403/1000]\n",
      "- [TRAIN] LOSS : 8.028630230304165e-05 [SCORE] : 0.6\n",
      "[403/1000]\n",
      "- [VAL] LOSS : 0.00011288506357232109 [SCORE] : 1.0\n",
      "[404/1000]\n",
      "- [TRAIN] LOSS : 7.971576827306611e-05 [SCORE] : 0.6\n",
      "[404/1000]\n",
      "- [VAL] LOSS : 0.0001120740344049409 [SCORE] : 1.0\n",
      "[405/1000]\n",
      "- [TRAIN] LOSS : 7.91528293727121e-05 [SCORE] : 0.6\n",
      "[405/1000]\n",
      "- [VAL] LOSS : 0.00011126095341751352 [SCORE] : 1.0\n",
      "[406/1000]\n",
      "- [TRAIN] LOSS : 7.859865072532557e-05 [SCORE] : 0.6\n",
      "[406/1000]\n",
      "- [VAL] LOSS : 0.00011046072177123278 [SCORE] : 1.0\n",
      "[407/1000]\n",
      "- [TRAIN] LOSS : 7.80409473615388e-05 [SCORE] : 0.6\n",
      "[407/1000]\n",
      "- [VAL] LOSS : 0.00010966577247017995 [SCORE] : 1.0\n",
      "[408/1000]\n",
      "- [TRAIN] LOSS : 7.748645948595368e-05 [SCORE] : 0.6\n",
      "[408/1000]\n",
      "- [VAL] LOSS : 0.00010887680400628597 [SCORE] : 1.0\n",
      "[409/1000]\n",
      "- [TRAIN] LOSS : 7.694150068952392e-05 [SCORE] : 0.6\n",
      "[409/1000]\n",
      "- [VAL] LOSS : 0.00010809737432282418 [SCORE] : 1.0\n",
      "[410/1000]\n",
      "- [TRAIN] LOSS : 7.639960870922854e-05 [SCORE] : 0.6\n",
      "[410/1000]\n",
      "- [VAL] LOSS : 0.0001073274906957522 [SCORE] : 1.0\n",
      "[411/1000]\n",
      "- [TRAIN] LOSS : 7.586453575640917e-05 [SCORE] : 0.6\n",
      "[411/1000]\n",
      "- [VAL] LOSS : 0.00010655763617251068 [SCORE] : 1.0\n",
      "[412/1000]\n",
      "- [TRAIN] LOSS : 7.533196282262603e-05 [SCORE] : 0.6\n",
      "[412/1000]\n",
      "- [VAL] LOSS : 0.00010580266825854778 [SCORE] : 1.0\n",
      "[413/1000]\n",
      "- [TRAIN] LOSS : 7.480417189071886e-05 [SCORE] : 0.6\n",
      "[413/1000]\n",
      "- [VAL] LOSS : 0.00010504962847335264 [SCORE] : 1.0\n",
      "[414/1000]\n",
      "- [TRAIN] LOSS : 7.428021732872973e-05 [SCORE] : 0.6\n",
      "[414/1000]\n",
      "- [VAL] LOSS : 0.00010429420945001766 [SCORE] : 1.0\n",
      "[415/1000]\n",
      "- [TRAIN] LOSS : 7.376363889003794e-05 [SCORE] : 0.6\n",
      "[415/1000]\n",
      "- [VAL] LOSS : 0.00010355380072724074 [SCORE] : 1.0\n",
      "[416/1000]\n",
      "- [TRAIN] LOSS : 7.324943968948598e-05 [SCORE] : 0.6\n",
      "[416/1000]\n",
      "- [VAL] LOSS : 0.00010281963477609679 [SCORE] : 1.0\n",
      "[417/1000]\n",
      "- [TRAIN] LOSS : 7.273715042780775e-05 [SCORE] : 0.6\n",
      "[417/1000]\n",
      "- [VAL] LOSS : 0.0001020877025439404 [SCORE] : 1.0\n",
      "[418/1000]\n",
      "- [TRAIN] LOSS : 7.223272987175733e-05 [SCORE] : 0.6\n",
      "[418/1000]\n",
      "- [VAL] LOSS : 0.0001013705477816984 [SCORE] : 1.0\n",
      "[419/1000]\n",
      "- [TRAIN] LOSS : 7.172853608305256e-05 [SCORE] : 0.6\n",
      "[419/1000]\n",
      "- [VAL] LOSS : 0.00010064895468531176 [SCORE] : 1.0\n",
      "[420/1000]\n",
      "- [TRAIN] LOSS : 7.12395854255495e-05 [SCORE] : 0.6\n",
      "[420/1000]\n",
      "- [VAL] LOSS : 9.992567356675863e-05 [SCORE] : 1.0\n",
      "[421/1000]\n",
      "- [TRAIN] LOSS : 7.074250703832755e-05 [SCORE] : 0.6\n",
      "[421/1000]\n",
      "- [VAL] LOSS : 9.921936725731939e-05 [SCORE] : 1.0\n",
      "[422/1000]\n",
      "- [TRAIN] LOSS : 7.025316493430485e-05 [SCORE] : 0.6\n",
      "[422/1000]\n",
      "- [VAL] LOSS : 9.852352377492934e-05 [SCORE] : 1.0\n",
      "[423/1000]\n",
      "- [TRAIN] LOSS : 6.976664153626188e-05 [SCORE] : 0.6\n",
      "[423/1000]\n",
      "- [VAL] LOSS : 9.78301468421705e-05 [SCORE] : 1.0\n",
      "[424/1000]\n",
      "- [TRAIN] LOSS : 6.928617052229432e-05 [SCORE] : 0.6\n",
      "[424/1000]\n",
      "- [VAL] LOSS : 9.714561747387052e-05 [SCORE] : 1.0\n",
      "[425/1000]\n",
      "- [TRAIN] LOSS : 6.880896520063591e-05 [SCORE] : 0.6\n",
      "[425/1000]\n",
      "- [VAL] LOSS : 9.647229308029637e-05 [SCORE] : 1.0\n",
      "[426/1000]\n",
      "- [TRAIN] LOSS : 6.833297108338835e-05 [SCORE] : 0.6\n",
      "[426/1000]\n",
      "- [VAL] LOSS : 9.58141972660087e-05 [SCORE] : 1.0\n",
      "[427/1000]\n",
      "- [TRAIN] LOSS : 6.786637192514414e-05 [SCORE] : 0.6\n",
      "[427/1000]\n",
      "- [VAL] LOSS : 9.51542315306142e-05 [SCORE] : 1.0\n",
      "[428/1000]\n",
      "- [TRAIN] LOSS : 6.739963549383295e-05 [SCORE] : 0.6\n",
      "[428/1000]\n",
      "- [VAL] LOSS : 9.449672506889328e-05 [SCORE] : 1.0\n",
      "[429/1000]\n",
      "- [TRAIN] LOSS : 6.694178761487516e-05 [SCORE] : 0.6\n",
      "[429/1000]\n",
      "- [VAL] LOSS : 9.38373850658536e-05 [SCORE] : 1.0\n",
      "[430/1000]\n",
      "- [TRAIN] LOSS : 6.648180351476185e-05 [SCORE] : 0.6\n",
      "[430/1000]\n",
      "- [VAL] LOSS : 9.319745731772855e-05 [SCORE] : 1.0\n",
      "[431/1000]\n",
      "- [TRAIN] LOSS : 6.602828313286105e-05 [SCORE] : 0.6\n",
      "[431/1000]\n",
      "- [VAL] LOSS : 9.255991608370095e-05 [SCORE] : 1.0\n",
      "[432/1000]\n",
      "- [TRAIN] LOSS : 6.557736390580734e-05 [SCORE] : 0.6\n",
      "[432/1000]\n",
      "- [VAL] LOSS : 9.192898869514465e-05 [SCORE] : 1.0\n",
      "[433/1000]\n",
      "- [TRAIN] LOSS : 6.513413051531339e-05 [SCORE] : 0.6\n",
      "[433/1000]\n",
      "- [VAL] LOSS : 9.129200043389574e-05 [SCORE] : 1.0\n",
      "[434/1000]\n",
      "- [TRAIN] LOSS : 6.468756425116832e-05 [SCORE] : 0.6\n",
      "[434/1000]\n",
      "- [VAL] LOSS : 9.066588972928002e-05 [SCORE] : 1.0\n",
      "[435/1000]\n",
      "- [TRAIN] LOSS : 6.424739064338306e-05 [SCORE] : 0.6\n",
      "[435/1000]\n",
      "- [VAL] LOSS : 9.005051833810285e-05 [SCORE] : 1.0\n",
      "[436/1000]\n",
      "- [TRAIN] LOSS : 6.381369118268291e-05 [SCORE] : 0.6\n",
      "[436/1000]\n",
      "- [VAL] LOSS : 8.944907312979922e-05 [SCORE] : 1.0\n",
      "[437/1000]\n",
      "- [TRAIN] LOSS : 6.338763026481805e-05 [SCORE] : 0.6\n",
      "[437/1000]\n",
      "- [VAL] LOSS : 8.883707778295502e-05 [SCORE] : 1.0\n",
      "[438/1000]\n",
      "- [TRAIN] LOSS : 6.295414398967598e-05 [SCORE] : 0.6\n",
      "[438/1000]\n",
      "- [VAL] LOSS : 8.823288226267323e-05 [SCORE] : 1.0\n",
      "[439/1000]\n",
      "- [TRAIN] LOSS : 6.252985209963905e-05 [SCORE] : 0.6\n",
      "[439/1000]\n",
      "- [VAL] LOSS : 8.763701043790206e-05 [SCORE] : 1.0\n",
      "[440/1000]\n",
      "- [TRAIN] LOSS : 6.210739156813361e-05 [SCORE] : 0.6\n",
      "[440/1000]\n",
      "- [VAL] LOSS : 8.704717765795067e-05 [SCORE] : 1.0\n",
      "[441/1000]\n",
      "- [TRAIN] LOSS : 6.168947050658366e-05 [SCORE] : 0.6\n",
      "[441/1000]\n",
      "- [VAL] LOSS : 8.645603520562872e-05 [SCORE] : 1.0\n",
      "[442/1000]\n",
      "- [TRAIN] LOSS : 6.127087908680551e-05 [SCORE] : 0.6\n",
      "[442/1000]\n",
      "- [VAL] LOSS : 8.587575575802475e-05 [SCORE] : 1.0\n",
      "[443/1000]\n",
      "- [TRAIN] LOSS : 6.085961625406829e-05 [SCORE] : 0.6\n",
      "[443/1000]\n",
      "- [VAL] LOSS : 8.52934826980345e-05 [SCORE] : 1.0\n",
      "[444/1000]\n",
      "- [TRAIN] LOSS : 6.045150269831841e-05 [SCORE] : 0.6\n",
      "[444/1000]\n",
      "- [VAL] LOSS : 8.471338514937088e-05 [SCORE] : 1.0\n",
      "[445/1000]\n",
      "- [TRAIN] LOSS : 6.00449537159875e-05 [SCORE] : 0.6\n",
      "[445/1000]\n",
      "- [VAL] LOSS : 8.414810145040974e-05 [SCORE] : 1.0\n",
      "[446/1000]\n",
      "- [TRAIN] LOSS : 5.964464338224691e-05 [SCORE] : 0.6\n",
      "[446/1000]\n",
      "- [VAL] LOSS : 8.35848695714958e-05 [SCORE] : 1.0\n",
      "[447/1000]\n",
      "- [TRAIN] LOSS : 5.924300712649711e-05 [SCORE] : 0.6\n",
      "[447/1000]\n",
      "- [VAL] LOSS : 8.30195567687042e-05 [SCORE] : 1.0\n",
      "[448/1000]\n",
      "- [TRAIN] LOSS : 5.884925764500319e-05 [SCORE] : 0.6\n",
      "[448/1000]\n",
      "- [VAL] LOSS : 8.246053039329126e-05 [SCORE] : 1.0\n",
      "[449/1000]\n",
      "- [TRAIN] LOSS : 5.8458886996959336e-05 [SCORE] : 0.6\n",
      "[449/1000]\n",
      "- [VAL] LOSS : 8.190366497728974e-05 [SCORE] : 1.0\n",
      "[450/1000]\n",
      "- [TRAIN] LOSS : 5.806649229877318e-05 [SCORE] : 0.6\n",
      "[450/1000]\n",
      "- [VAL] LOSS : 8.136156247928739e-05 [SCORE] : 1.0\n",
      "[451/1000]\n",
      "- [TRAIN] LOSS : 5.7681076941662465e-05 [SCORE] : 0.6\n",
      "[451/1000]\n",
      "- [VAL] LOSS : 8.08088734629564e-05 [SCORE] : 1.0\n",
      "[452/1000]\n",
      "- [TRAIN] LOSS : 5.729793823168924e-05 [SCORE] : 0.6\n",
      "[452/1000]\n",
      "- [VAL] LOSS : 8.027091826079413e-05 [SCORE] : 1.0\n",
      "[453/1000]\n",
      "- [TRAIN] LOSS : 5.6916554603958504e-05 [SCORE] : 0.6\n",
      "[453/1000]\n",
      "- [VAL] LOSS : 7.973425817908719e-05 [SCORE] : 1.0\n",
      "[454/1000]\n",
      "- [TRAIN] LOSS : 5.654559960627618e-05 [SCORE] : 0.6\n",
      "[454/1000]\n",
      "- [VAL] LOSS : 7.921310316305608e-05 [SCORE] : 1.0\n",
      "[455/1000]\n",
      "- [TRAIN] LOSS : 5.616733081600008e-05 [SCORE] : 0.6\n",
      "[455/1000]\n",
      "- [VAL] LOSS : 7.86899690865539e-05 [SCORE] : 1.0\n",
      "[456/1000]\n",
      "- [TRAIN] LOSS : 5.5793245216288294e-05 [SCORE] : 0.6\n",
      "[456/1000]\n",
      "- [VAL] LOSS : 7.816393917892128e-05 [SCORE] : 1.0\n",
      "[457/1000]\n",
      "- [TRAIN] LOSS : 5.542471299122553e-05 [SCORE] : 0.6\n",
      "[457/1000]\n",
      "- [VAL] LOSS : 7.764338079141453e-05 [SCORE] : 1.0\n",
      "[458/1000]\n",
      "- [TRAIN] LOSS : 5.5060677307968335e-05 [SCORE] : 0.6\n",
      "[458/1000]\n",
      "- [VAL] LOSS : 7.712747174082324e-05 [SCORE] : 1.0\n",
      "[459/1000]\n",
      "- [TRAIN] LOSS : 5.4695199166114133e-05 [SCORE] : 0.6\n",
      "[459/1000]\n",
      "- [VAL] LOSS : 7.662003918085247e-05 [SCORE] : 1.0\n",
      "[460/1000]\n",
      "- [TRAIN] LOSS : 5.4333585285348815e-05 [SCORE] : 0.6\n",
      "[460/1000]\n",
      "- [VAL] LOSS : 7.611653563799337e-05 [SCORE] : 1.0\n",
      "[461/1000]\n",
      "- [TRAIN] LOSS : 5.397877321229316e-05 [SCORE] : 0.6\n",
      "[461/1000]\n",
      "- [VAL] LOSS : 7.561493839602917e-05 [SCORE] : 1.0\n",
      "[462/1000]\n",
      "- [TRAIN] LOSS : 5.3623642694825925e-05 [SCORE] : 0.6\n",
      "[462/1000]\n",
      "- [VAL] LOSS : 7.51151965232566e-05 [SCORE] : 1.0\n",
      "[463/1000]\n",
      "- [TRAIN] LOSS : 5.3273390706939e-05 [SCORE] : 0.6\n",
      "[463/1000]\n",
      "- [VAL] LOSS : 7.462153735104948e-05 [SCORE] : 1.0\n",
      "[464/1000]\n",
      "- [TRAIN] LOSS : 5.292665688709045e-05 [SCORE] : 0.6\n",
      "[464/1000]\n",
      "- [VAL] LOSS : 7.412119157379493e-05 [SCORE] : 1.0\n",
      "[465/1000]\n",
      "- [TRAIN] LOSS : 5.2577278499181075e-05 [SCORE] : 0.6\n",
      "[465/1000]\n",
      "- [VAL] LOSS : 7.364392513409257e-05 [SCORE] : 1.0\n",
      "[466/1000]\n",
      "- [TRAIN] LOSS : 5.223497792030685e-05 [SCORE] : 0.6\n",
      "[466/1000]\n",
      "- [VAL] LOSS : 7.315139373531565e-05 [SCORE] : 1.0\n",
      "[467/1000]\n",
      "- [TRAIN] LOSS : 5.189347684790846e-05 [SCORE] : 0.6\n",
      "[467/1000]\n",
      "- [VAL] LOSS : 7.26777216186747e-05 [SCORE] : 1.0\n",
      "[468/1000]\n",
      "- [TRAIN] LOSS : 5.1554417829417314e-05 [SCORE] : 0.6\n",
      "[468/1000]\n",
      "- [VAL] LOSS : 7.220148108899593e-05 [SCORE] : 1.0\n",
      "[469/1000]\n",
      "- [TRAIN] LOSS : 5.121756573013651e-05 [SCORE] : 0.6\n",
      "[469/1000]\n",
      "- [VAL] LOSS : 7.172241748776287e-05 [SCORE] : 1.0\n",
      "[470/1000]\n",
      "- [TRAIN] LOSS : 5.088866540366629e-05 [SCORE] : 0.6\n",
      "[470/1000]\n",
      "- [VAL] LOSS : 7.125914271455258e-05 [SCORE] : 1.0\n",
      "[471/1000]\n",
      "- [TRAIN] LOSS : 5.055523652117699e-05 [SCORE] : 0.6\n",
      "[471/1000]\n",
      "- [VAL] LOSS : 7.08014631527476e-05 [SCORE] : 1.0\n",
      "[472/1000]\n",
      "- [TRAIN] LOSS : 5.022482461451242e-05 [SCORE] : 0.6\n",
      "[472/1000]\n",
      "- [VAL] LOSS : 7.033164001768455e-05 [SCORE] : 1.0\n",
      "[473/1000]\n",
      "- [TRAIN] LOSS : 4.989777080481872e-05 [SCORE] : 0.6\n",
      "[473/1000]\n",
      "- [VAL] LOSS : 6.988614040892571e-05 [SCORE] : 1.0\n",
      "[474/1000]\n",
      "- [TRAIN] LOSS : 4.957487957047609e-05 [SCORE] : 0.6\n",
      "[474/1000]\n",
      "- [VAL] LOSS : 6.942143954802305e-05 [SCORE] : 1.0\n",
      "[475/1000]\n",
      "- [TRAIN] LOSS : 4.9252231959447576e-05 [SCORE] : 0.6\n",
      "[475/1000]\n",
      "- [VAL] LOSS : 6.896712147863582e-05 [SCORE] : 1.0\n",
      "[476/1000]\n",
      "- [TRAIN] LOSS : 4.8935587619780564e-05 [SCORE] : 0.6\n",
      "[476/1000]\n",
      "- [VAL] LOSS : 6.85101404087618e-05 [SCORE] : 1.0\n",
      "[477/1000]\n",
      "- [TRAIN] LOSS : 4.8619951606572916e-05 [SCORE] : 0.6\n",
      "[477/1000]\n",
      "- [VAL] LOSS : 6.807185854995623e-05 [SCORE] : 1.0\n",
      "[478/1000]\n",
      "- [TRAIN] LOSS : 4.8307366038595014e-05 [SCORE] : 0.6\n",
      "[478/1000]\n",
      "- [VAL] LOSS : 6.762242264812812e-05 [SCORE] : 1.0\n",
      "[479/1000]\n",
      "- [TRAIN] LOSS : 4.799384769285098e-05 [SCORE] : 0.6\n",
      "[479/1000]\n",
      "- [VAL] LOSS : 6.718729855492711e-05 [SCORE] : 1.0\n",
      "[480/1000]\n",
      "- [TRAIN] LOSS : 4.7684819340550653e-05 [SCORE] : 0.6\n",
      "[480/1000]\n",
      "- [VAL] LOSS : 6.675368786090985e-05 [SCORE] : 1.0\n",
      "[481/1000]\n",
      "- [TRAIN] LOSS : 4.737718627438881e-05 [SCORE] : 0.6\n",
      "[481/1000]\n",
      "- [VAL] LOSS : 6.631739961449057e-05 [SCORE] : 1.0\n",
      "[482/1000]\n",
      "- [TRAIN] LOSS : 4.7075316736785074e-05 [SCORE] : 0.6\n",
      "[482/1000]\n",
      "- [VAL] LOSS : 6.589962140424177e-05 [SCORE] : 1.0\n",
      "[483/1000]\n",
      "- [TRAIN] LOSS : 4.677196423775361e-05 [SCORE] : 0.6\n",
      "[483/1000]\n",
      "- [VAL] LOSS : 6.547912198584527e-05 [SCORE] : 1.0\n",
      "[484/1000]\n",
      "- [TRAIN] LOSS : 4.6472326236350155e-05 [SCORE] : 0.6\n",
      "[484/1000]\n",
      "- [VAL] LOSS : 6.505598867079243e-05 [SCORE] : 1.0\n",
      "[485/1000]\n",
      "- [TRAIN] LOSS : 4.617816121026408e-05 [SCORE] : 0.6\n",
      "[485/1000]\n",
      "- [VAL] LOSS : 6.463636236730963e-05 [SCORE] : 1.0\n",
      "[486/1000]\n",
      "- [TRAIN] LOSS : 4.5878814732229026e-05 [SCORE] : 0.6\n",
      "[486/1000]\n",
      "- [VAL] LOSS : 6.422551814466715e-05 [SCORE] : 1.0\n",
      "[487/1000]\n",
      "- [TRAIN] LOSS : 4.5584465503149356e-05 [SCORE] : 0.6\n",
      "[487/1000]\n",
      "- [VAL] LOSS : 6.379999831551686e-05 [SCORE] : 1.0\n",
      "[488/1000]\n",
      "- [TRAIN] LOSS : 4.52906377176987e-05 [SCORE] : 0.6\n",
      "[488/1000]\n",
      "- [VAL] LOSS : 6.338771345326677e-05 [SCORE] : 1.0\n",
      "[489/1000]\n",
      "- [TRAIN] LOSS : 4.500658481750482e-05 [SCORE] : 0.6\n",
      "[489/1000]\n",
      "- [VAL] LOSS : 6.298163498286158e-05 [SCORE] : 1.0\n",
      "[490/1000]\n",
      "- [TRAIN] LOSS : 4.471665112456928e-05 [SCORE] : 0.6\n",
      "[490/1000]\n",
      "- [VAL] LOSS : 6.258566281758249e-05 [SCORE] : 1.0\n",
      "[491/1000]\n",
      "- [TRAIN] LOSS : 4.443248678095794e-05 [SCORE] : 0.6\n",
      "[491/1000]\n",
      "- [VAL] LOSS : 6.218680209713057e-05 [SCORE] : 1.0\n",
      "[492/1000]\n",
      "- [TRAIN] LOSS : 4.415074096565756e-05 [SCORE] : 0.6\n",
      "[492/1000]\n",
      "- [VAL] LOSS : 6.178944022394717e-05 [SCORE] : 1.0\n",
      "[493/1000]\n",
      "- [TRAIN] LOSS : 4.386869538090347e-05 [SCORE] : 0.6\n",
      "[493/1000]\n",
      "- [VAL] LOSS : 6.138910976005718e-05 [SCORE] : 1.0\n",
      "[494/1000]\n",
      "- [TRAIN] LOSS : 4.3591414456993034e-05 [SCORE] : 0.6\n",
      "[494/1000]\n",
      "- [VAL] LOSS : 6.1002963775536045e-05 [SCORE] : 1.0\n",
      "[495/1000]\n",
      "- [TRAIN] LOSS : 4.3314894962046914e-05 [SCORE] : 0.6\n",
      "[495/1000]\n",
      "- [VAL] LOSS : 6.061385647626594e-05 [SCORE] : 1.0\n",
      "[496/1000]\n",
      "- [TRAIN] LOSS : 4.3041583800610776e-05 [SCORE] : 0.6\n",
      "[496/1000]\n",
      "- [VAL] LOSS : 6.0217611462576315e-05 [SCORE] : 1.0\n",
      "[497/1000]\n",
      "- [TRAIN] LOSS : 4.276667399002084e-05 [SCORE] : 0.6\n",
      "[497/1000]\n",
      "- [VAL] LOSS : 5.983545634080656e-05 [SCORE] : 1.0\n",
      "[498/1000]\n",
      "- [TRAIN] LOSS : 4.249608682584949e-05 [SCORE] : 0.6\n",
      "[498/1000]\n",
      "- [VAL] LOSS : 5.9459376643644646e-05 [SCORE] : 1.0\n",
      "[499/1000]\n",
      "- [TRAIN] LOSS : 4.223202013236005e-05 [SCORE] : 0.6\n",
      "[499/1000]\n",
      "- [VAL] LOSS : 5.90827148698736e-05 [SCORE] : 1.0\n",
      "[500/1000]\n",
      "- [TRAIN] LOSS : 4.196324298391119e-05 [SCORE] : 0.6\n",
      "[500/1000]\n",
      "- [VAL] LOSS : 5.871415123692714e-05 [SCORE] : 1.0\n",
      "[501/1000]\n",
      "- [TRAIN] LOSS : 4.169760747269417e-05 [SCORE] : 0.6\n",
      "[501/1000]\n",
      "- [VAL] LOSS : 5.833269824506715e-05 [SCORE] : 1.0\n",
      "[502/1000]\n",
      "- [TRAIN] LOSS : 4.143734331591986e-05 [SCORE] : 0.6\n",
      "[502/1000]\n",
      "- [VAL] LOSS : 5.796209370600991e-05 [SCORE] : 1.0\n",
      "[503/1000]\n",
      "- [TRAIN] LOSS : 4.117317221243866e-05 [SCORE] : 0.6\n",
      "[503/1000]\n",
      "- [VAL] LOSS : 5.7597404520493e-05 [SCORE] : 1.0\n",
      "[504/1000]\n",
      "- [TRAIN] LOSS : 4.091558233388544e-05 [SCORE] : 0.6\n",
      "[504/1000]\n",
      "- [VAL] LOSS : 5.7229921367252246e-05 [SCORE] : 1.0\n",
      "[505/1000]\n",
      "- [TRAIN] LOSS : 4.0657266921092136e-05 [SCORE] : 0.6\n",
      "[505/1000]\n",
      "- [VAL] LOSS : 5.687218435923569e-05 [SCORE] : 1.0\n",
      "[506/1000]\n",
      "- [TRAIN] LOSS : 4.040361345687415e-05 [SCORE] : 0.6\n",
      "[506/1000]\n",
      "- [VAL] LOSS : 5.651176979881711e-05 [SCORE] : 1.0\n",
      "[507/1000]\n",
      "- [TRAIN] LOSS : 4.014854287864485e-05 [SCORE] : 0.6\n",
      "[507/1000]\n",
      "- [VAL] LOSS : 5.6152784964069724e-05 [SCORE] : 1.0\n",
      "[508/1000]\n",
      "- [TRAIN] LOSS : 3.989585869324704e-05 [SCORE] : 0.6\n",
      "[508/1000]\n",
      "- [VAL] LOSS : 5.579931166721508e-05 [SCORE] : 1.0\n",
      "[509/1000]\n",
      "- [TRAIN] LOSS : 3.964625054019659e-05 [SCORE] : 0.6\n",
      "[509/1000]\n",
      "- [VAL] LOSS : 5.543839142774232e-05 [SCORE] : 1.0\n",
      "[510/1000]\n",
      "- [TRAIN] LOSS : 3.94003411201993e-05 [SCORE] : 0.6\n",
      "[510/1000]\n",
      "- [VAL] LOSS : 5.509571565198712e-05 [SCORE] : 1.0\n",
      "[511/1000]\n",
      "- [TRAIN] LOSS : 3.9153917411264655e-05 [SCORE] : 0.6\n",
      "[511/1000]\n",
      "- [VAL] LOSS : 5.474637873703614e-05 [SCORE] : 1.0\n",
      "[512/1000]\n",
      "- [TRAIN] LOSS : 3.891221131198108e-05 [SCORE] : 0.6\n",
      "[512/1000]\n",
      "- [VAL] LOSS : 5.440963650471531e-05 [SCORE] : 1.0\n",
      "[513/1000]\n",
      "- [TRAIN] LOSS : 3.8666695885088606e-05 [SCORE] : 0.6\n",
      "[513/1000]\n",
      "- [VAL] LOSS : 5.407177013694309e-05 [SCORE] : 1.0\n",
      "[514/1000]\n",
      "- [TRAIN] LOSS : 3.8427329491241836e-05 [SCORE] : 0.6\n",
      "[514/1000]\n",
      "- [VAL] LOSS : 5.373757812776603e-05 [SCORE] : 1.0\n",
      "[515/1000]\n",
      "- [TRAIN] LOSS : 3.818622972175945e-05 [SCORE] : 0.6\n",
      "[515/1000]\n",
      "- [VAL] LOSS : 5.338849587133154e-05 [SCORE] : 1.0\n",
      "[516/1000]\n",
      "- [TRAIN] LOSS : 3.7948540678674666e-05 [SCORE] : 0.6\n",
      "[516/1000]\n",
      "- [VAL] LOSS : 5.3062121878610924e-05 [SCORE] : 1.0\n",
      "[517/1000]\n",
      "- [TRAIN] LOSS : 3.7711313537632427e-05 [SCORE] : 0.6\n",
      "[517/1000]\n",
      "- [VAL] LOSS : 5.272423004498705e-05 [SCORE] : 1.0\n",
      "[518/1000]\n",
      "- [TRAIN] LOSS : 3.748072510158333e-05 [SCORE] : 0.6\n",
      "[518/1000]\n",
      "- [VAL] LOSS : 5.2400282584130764e-05 [SCORE] : 1.0\n",
      "[519/1000]\n",
      "- [TRAIN] LOSS : 3.724436137417797e-05 [SCORE] : 0.6\n",
      "[519/1000]\n",
      "- [VAL] LOSS : 5.20602916367352e-05 [SCORE] : 1.0\n",
      "[520/1000]\n",
      "- [TRAIN] LOSS : 3.701489088901629e-05 [SCORE] : 0.6\n",
      "[520/1000]\n",
      "- [VAL] LOSS : 5.1738366892095655e-05 [SCORE] : 1.0\n",
      "[521/1000]\n",
      "- [TRAIN] LOSS : 3.678789823122012e-05 [SCORE] : 0.6\n",
      "[521/1000]\n",
      "- [VAL] LOSS : 5.1421837270027027e-05 [SCORE] : 1.0\n",
      "[522/1000]\n",
      "- [TRAIN] LOSS : 3.655751340071826e-05 [SCORE] : 0.6\n",
      "[522/1000]\n",
      "- [VAL] LOSS : 5.1102058932883665e-05 [SCORE] : 1.0\n",
      "[523/1000]\n",
      "- [TRAIN] LOSS : 3.6331581820074156e-05 [SCORE] : 0.6\n",
      "[523/1000]\n",
      "- [VAL] LOSS : 5.078326285001822e-05 [SCORE] : 1.0\n",
      "[524/1000]\n",
      "- [TRAIN] LOSS : 3.610895122013365e-05 [SCORE] : 0.6\n",
      "[524/1000]\n",
      "- [VAL] LOSS : 5.0465525418985635e-05 [SCORE] : 1.0\n",
      "[525/1000]\n",
      "- [TRAIN] LOSS : 3.588639180331181e-05 [SCORE] : 0.6\n",
      "[525/1000]\n",
      "- [VAL] LOSS : 5.015405622543767e-05 [SCORE] : 1.0\n",
      "[526/1000]\n",
      "- [TRAIN] LOSS : 3.56679969020964e-05 [SCORE] : 0.6\n",
      "[526/1000]\n",
      "- [VAL] LOSS : 4.983846520190127e-05 [SCORE] : 1.0\n",
      "[527/1000]\n",
      "- [TRAIN] LOSS : 3.544318387866951e-05 [SCORE] : 0.6\n",
      "[527/1000]\n",
      "- [VAL] LOSS : 4.953821189701557e-05 [SCORE] : 1.0\n",
      "[528/1000]\n",
      "- [TRAIN] LOSS : 3.522438879978533e-05 [SCORE] : 0.6\n",
      "[528/1000]\n",
      "- [VAL] LOSS : 4.923270898871124e-05 [SCORE] : 1.0\n",
      "[529/1000]\n",
      "- [TRAIN] LOSS : 3.500673738017212e-05 [SCORE] : 0.6\n",
      "[529/1000]\n",
      "- [VAL] LOSS : 4.8924903239822015e-05 [SCORE] : 1.0\n",
      "[530/1000]\n",
      "- [TRAIN] LOSS : 3.4793124480832675e-05 [SCORE] : 0.6\n",
      "[530/1000]\n",
      "- [VAL] LOSS : 4.862057539867237e-05 [SCORE] : 1.0\n",
      "[531/1000]\n",
      "- [TRAIN] LOSS : 3.457986846721421e-05 [SCORE] : 0.6\n",
      "[531/1000]\n",
      "- [VAL] LOSS : 4.831097976421006e-05 [SCORE] : 1.0\n",
      "[532/1000]\n",
      "- [TRAIN] LOSS : 3.4369176501058976e-05 [SCORE] : 0.6\n",
      "[532/1000]\n",
      "- [VAL] LOSS : 4.8023717681644484e-05 [SCORE] : 1.0\n",
      "[533/1000]\n",
      "- [TRAIN] LOSS : 3.415896195898919e-05 [SCORE] : 0.6\n",
      "[533/1000]\n",
      "- [VAL] LOSS : 4.7724690375616774e-05 [SCORE] : 1.0\n",
      "[534/1000]\n",
      "- [TRAIN] LOSS : 3.3947665239490256e-05 [SCORE] : 0.6\n",
      "[534/1000]\n",
      "- [VAL] LOSS : 4.743087993119843e-05 [SCORE] : 1.0\n",
      "[535/1000]\n",
      "- [TRAIN] LOSS : 3.374037199440257e-05 [SCORE] : 0.6\n",
      "[535/1000]\n",
      "- [VAL] LOSS : 4.7133664338616654e-05 [SCORE] : 1.0\n",
      "[536/1000]\n",
      "- [TRAIN] LOSS : 3.353264073666651e-05 [SCORE] : 0.6\n",
      "[536/1000]\n",
      "- [VAL] LOSS : 4.685017484007403e-05 [SCORE] : 1.0\n",
      "[537/1000]\n",
      "- [TRAIN] LOSS : 3.333011324381611e-05 [SCORE] : 0.6\n",
      "[537/1000]\n",
      "- [VAL] LOSS : 4.655910743167624e-05 [SCORE] : 1.0\n",
      "[538/1000]\n",
      "- [TRAIN] LOSS : 3.312678957930378e-05 [SCORE] : 0.6\n",
      "[538/1000]\n",
      "- [VAL] LOSS : 4.6274421038106084e-05 [SCORE] : 1.0\n",
      "[539/1000]\n",
      "- [TRAIN] LOSS : 3.292781669491281e-05 [SCORE] : 0.6\n",
      "[539/1000]\n",
      "- [VAL] LOSS : 4.5990076614543796e-05 [SCORE] : 1.0\n",
      "[540/1000]\n",
      "- [TRAIN] LOSS : 3.272371153191974e-05 [SCORE] : 0.6\n",
      "[540/1000]\n",
      "- [VAL] LOSS : 4.5712102291872725e-05 [SCORE] : 1.0\n",
      "[541/1000]\n",
      "- [TRAIN] LOSS : 3.25263737977366e-05 [SCORE] : 0.6\n",
      "[541/1000]\n",
      "- [VAL] LOSS : 4.5432949264068156e-05 [SCORE] : 1.0\n",
      "[542/1000]\n",
      "- [TRAIN] LOSS : 3.2326902449616075e-05 [SCORE] : 0.6\n",
      "[542/1000]\n",
      "- [VAL] LOSS : 4.5155589759815484e-05 [SCORE] : 1.0\n",
      "[543/1000]\n",
      "- [TRAIN] LOSS : 3.213047572595921e-05 [SCORE] : 0.6\n",
      "[543/1000]\n",
      "- [VAL] LOSS : 4.487521437113173e-05 [SCORE] : 1.0\n",
      "[544/1000]\n",
      "- [TRAIN] LOSS : 3.193350839865161e-05 [SCORE] : 0.6\n",
      "[544/1000]\n",
      "- [VAL] LOSS : 4.460004493012093e-05 [SCORE] : 1.0\n",
      "[545/1000]\n",
      "- [TRAIN] LOSS : 3.174216271872865e-05 [SCORE] : 0.6\n",
      "[545/1000]\n",
      "- [VAL] LOSS : 4.4325792259769514e-05 [SCORE] : 1.0\n",
      "[546/1000]\n",
      "- [TRAIN] LOSS : 3.154882645806841e-05 [SCORE] : 0.6\n",
      "[546/1000]\n",
      "- [VAL] LOSS : 4.405668005347252e-05 [SCORE] : 1.0\n",
      "[547/1000]\n",
      "- [TRAIN] LOSS : 3.1357423540612214e-05 [SCORE] : 0.6\n",
      "[547/1000]\n",
      "- [VAL] LOSS : 4.3788404582301155e-05 [SCORE] : 1.0\n",
      "[548/1000]\n",
      "- [TRAIN] LOSS : 3.116399111604551e-05 [SCORE] : 0.6\n",
      "[548/1000]\n",
      "- [VAL] LOSS : 4.3516749428818e-05 [SCORE] : 1.0\n",
      "[549/1000]\n",
      "- [TRAIN] LOSS : 3.097805614136935e-05 [SCORE] : 0.6\n",
      "[549/1000]\n",
      "- [VAL] LOSS : 4.325015106587671e-05 [SCORE] : 1.0\n",
      "[550/1000]\n",
      "- [TRAIN] LOSS : 3.078965867947166e-05 [SCORE] : 0.6\n",
      "[550/1000]\n",
      "- [VAL] LOSS : 4.298437852412462e-05 [SCORE] : 1.0\n",
      "[551/1000]\n",
      "- [TRAIN] LOSS : 3.060631079279119e-05 [SCORE] : 0.6\n",
      "[551/1000]\n",
      "- [VAL] LOSS : 4.272082514944486e-05 [SCORE] : 1.0\n",
      "[552/1000]\n",
      "- [TRAIN] LOSS : 3.0423114246029097e-05 [SCORE] : 0.6\n",
      "[552/1000]\n",
      "- [VAL] LOSS : 4.24749159719795e-05 [SCORE] : 1.0\n",
      "[553/1000]\n",
      "- [TRAIN] LOSS : 3.0238902642546842e-05 [SCORE] : 0.6\n",
      "[553/1000]\n",
      "- [VAL] LOSS : 4.221358540235087e-05 [SCORE] : 1.0\n",
      "[554/1000]\n",
      "- [TRAIN] LOSS : 3.0054704014522336e-05 [SCORE] : 0.6\n",
      "[554/1000]\n",
      "- [VAL] LOSS : 4.195515066385269e-05 [SCORE] : 1.0\n",
      "[555/1000]\n",
      "- [TRAIN] LOSS : 2.9872089605002354e-05 [SCORE] : 0.6\n",
      "[555/1000]\n",
      "- [VAL] LOSS : 4.1698287532199174e-05 [SCORE] : 1.0\n",
      "[556/1000]\n",
      "- [TRAIN] LOSS : 2.9692396492464467e-05 [SCORE] : 0.6\n",
      "[556/1000]\n",
      "- [VAL] LOSS : 4.143406840739772e-05 [SCORE] : 1.0\n",
      "[557/1000]\n",
      "- [TRAIN] LOSS : 2.9513688483954564e-05 [SCORE] : 0.6\n",
      "[557/1000]\n",
      "- [VAL] LOSS : 4.119625737075694e-05 [SCORE] : 1.0\n",
      "[558/1000]\n",
      "- [TRAIN] LOSS : 2.933570018891866e-05 [SCORE] : 0.6\n",
      "[558/1000]\n",
      "- [VAL] LOSS : 4.094647374586202e-05 [SCORE] : 1.0\n",
      "[559/1000]\n",
      "- [TRAIN] LOSS : 2.915966724685859e-05 [SCORE] : 0.6\n",
      "[559/1000]\n",
      "- [VAL] LOSS : 4.0697526856092736e-05 [SCORE] : 1.0\n",
      "[560/1000]\n",
      "- [TRAIN] LOSS : 2.8985474576378085e-05 [SCORE] : 0.6\n",
      "[560/1000]\n",
      "- [VAL] LOSS : 4.044929664814845e-05 [SCORE] : 1.0\n",
      "[561/1000]\n",
      "- [TRAIN] LOSS : 2.8809549015325804e-05 [SCORE] : 0.6\n",
      "[561/1000]\n",
      "- [VAL] LOSS : 4.020604683319107e-05 [SCORE] : 1.0\n",
      "[562/1000]\n",
      "- [TRAIN] LOSS : 2.863746558432467e-05 [SCORE] : 0.6\n",
      "[562/1000]\n",
      "- [VAL] LOSS : 3.996785017079674e-05 [SCORE] : 1.0\n",
      "[563/1000]\n",
      "- [TRAIN] LOSS : 2.8466040081790803e-05 [SCORE] : 0.6\n",
      "[563/1000]\n",
      "- [VAL] LOSS : 3.972044214606285e-05 [SCORE] : 1.0\n",
      "[564/1000]\n",
      "- [TRAIN] LOSS : 2.8296486198087224e-05 [SCORE] : 0.6\n",
      "[564/1000]\n",
      "- [VAL] LOSS : 3.948223820771091e-05 [SCORE] : 1.0\n",
      "[565/1000]\n",
      "- [TRAIN] LOSS : 2.8131179290843042e-05 [SCORE] : 0.6\n",
      "[565/1000]\n",
      "- [VAL] LOSS : 3.926381396013312e-05 [SCORE] : 1.0\n",
      "[566/1000]\n",
      "- [TRAIN] LOSS : 2.795933675467192e-05 [SCORE] : 0.6\n",
      "[566/1000]\n",
      "- [VAL] LOSS : 3.903157630702481e-05 [SCORE] : 1.0\n",
      "[567/1000]\n",
      "- [TRAIN] LOSS : 2.7788777030461156e-05 [SCORE] : 0.6\n",
      "[567/1000]\n",
      "- [VAL] LOSS : 3.880100484821014e-05 [SCORE] : 1.0\n",
      "[568/1000]\n",
      "- [TRAIN] LOSS : 2.7624336507869884e-05 [SCORE] : 0.6\n",
      "[568/1000]\n",
      "- [VAL] LOSS : 3.8571572076762095e-05 [SCORE] : 1.0\n",
      "[569/1000]\n",
      "- [TRAIN] LOSS : 2.745833116932772e-05 [SCORE] : 0.6\n",
      "[569/1000]\n",
      "- [VAL] LOSS : 3.8338726881193e-05 [SCORE] : 1.0\n",
      "[570/1000]\n",
      "- [TRAIN] LOSS : 2.729518970833548e-05 [SCORE] : 0.6\n",
      "[570/1000]\n",
      "- [VAL] LOSS : 3.8115231291158125e-05 [SCORE] : 1.0\n",
      "[571/1000]\n",
      "- [TRAIN] LOSS : 2.713556762804122e-05 [SCORE] : 0.6\n",
      "[571/1000]\n",
      "- [VAL] LOSS : 3.78882214135956e-05 [SCORE] : 1.0\n",
      "[572/1000]\n",
      "- [TRAIN] LOSS : 2.6973803990889185e-05 [SCORE] : 0.6\n",
      "[572/1000]\n",
      "- [VAL] LOSS : 3.7666184653062373e-05 [SCORE] : 1.0\n",
      "[573/1000]\n",
      "- [TRAIN] LOSS : 2.6812670936730378e-05 [SCORE] : 0.6\n",
      "[573/1000]\n",
      "- [VAL] LOSS : 3.7440571759361774e-05 [SCORE] : 1.0\n",
      "[574/1000]\n",
      "- [TRAIN] LOSS : 2.6652901942725295e-05 [SCORE] : 0.6\n",
      "[574/1000]\n",
      "- [VAL] LOSS : 3.722418114193715e-05 [SCORE] : 1.0\n",
      "[575/1000]\n",
      "- [TRAIN] LOSS : 2.6492963782705678e-05 [SCORE] : 0.6\n",
      "[575/1000]\n",
      "- [VAL] LOSS : 3.7004236219218e-05 [SCORE] : 1.0\n",
      "[576/1000]\n",
      "- [TRAIN] LOSS : 2.6338733611434388e-05 [SCORE] : 0.6\n",
      "[576/1000]\n",
      "- [VAL] LOSS : 3.678789289551787e-05 [SCORE] : 1.0\n",
      "[577/1000]\n",
      "- [TRAIN] LOSS : 2.6181768043898045e-05 [SCORE] : 0.6\n",
      "[577/1000]\n",
      "- [VAL] LOSS : 3.6582940083462745e-05 [SCORE] : 1.0\n",
      "[578/1000]\n",
      "- [TRAIN] LOSS : 2.6026364381929548e-05 [SCORE] : 0.6\n",
      "[578/1000]\n",
      "- [VAL] LOSS : 3.63681283488404e-05 [SCORE] : 1.0\n",
      "[579/1000]\n",
      "- [TRAIN] LOSS : 2.5871089625676784e-05 [SCORE] : 0.6\n",
      "[579/1000]\n",
      "- [VAL] LOSS : 3.615063542383723e-05 [SCORE] : 1.0\n",
      "[580/1000]\n",
      "- [TRAIN] LOSS : 2.5717802661044212e-05 [SCORE] : 0.6\n",
      "[580/1000]\n",
      "- [VAL] LOSS : 3.594268491724506e-05 [SCORE] : 1.0\n",
      "[581/1000]\n",
      "- [TRAIN] LOSS : 2.5569267078632642e-05 [SCORE] : 0.6\n",
      "[581/1000]\n",
      "- [VAL] LOSS : 3.572708010324277e-05 [SCORE] : 1.0\n",
      "[582/1000]\n",
      "- [TRAIN] LOSS : 2.5414817173441406e-05 [SCORE] : 0.6\n",
      "[582/1000]\n",
      "- [VAL] LOSS : 3.5516448406269774e-05 [SCORE] : 1.0\n",
      "[583/1000]\n",
      "- [TRAIN] LOSS : 2.5263383031415286e-05 [SCORE] : 0.6\n",
      "[583/1000]\n",
      "- [VAL] LOSS : 3.5310724342707545e-05 [SCORE] : 1.0\n",
      "[584/1000]\n",
      "- [TRAIN] LOSS : 2.5114872490424506e-05 [SCORE] : 0.6\n",
      "[584/1000]\n",
      "- [VAL] LOSS : 3.5101373214274645e-05 [SCORE] : 1.0\n",
      "[585/1000]\n",
      "- [TRAIN] LOSS : 2.49680918083565e-05 [SCORE] : 0.6\n",
      "[585/1000]\n",
      "- [VAL] LOSS : 3.490120070637204e-05 [SCORE] : 1.0\n",
      "[586/1000]\n",
      "- [TRAIN] LOSS : 2.481909444516835e-05 [SCORE] : 0.6\n",
      "[586/1000]\n",
      "- [VAL] LOSS : 3.469315925030969e-05 [SCORE] : 1.0\n",
      "[587/1000]\n",
      "- [TRAIN] LOSS : 2.4673012800728125e-05 [SCORE] : 0.6\n",
      "[587/1000]\n",
      "- [VAL] LOSS : 3.4498512832215056e-05 [SCORE] : 1.0\n",
      "[588/1000]\n",
      "- [TRAIN] LOSS : 2.4527422465325798e-05 [SCORE] : 0.6\n",
      "[588/1000]\n",
      "- [VAL] LOSS : 3.42861567332875e-05 [SCORE] : 1.0\n",
      "[589/1000]\n",
      "- [TRAIN] LOSS : 2.4385583249871463e-05 [SCORE] : 0.6\n",
      "[589/1000]\n",
      "- [VAL] LOSS : 3.409374403418042e-05 [SCORE] : 1.0\n",
      "[590/1000]\n",
      "- [TRAIN] LOSS : 2.424170858527456e-05 [SCORE] : 0.6\n",
      "[590/1000]\n",
      "- [VAL] LOSS : 3.3904110750881955e-05 [SCORE] : 1.0\n",
      "[591/1000]\n",
      "- [TRAIN] LOSS : 2.409540878337187e-05 [SCORE] : 0.6\n",
      "[591/1000]\n",
      "- [VAL] LOSS : 3.369893238414079e-05 [SCORE] : 1.0\n",
      "[592/1000]\n",
      "- [TRAIN] LOSS : 2.3956938093760982e-05 [SCORE] : 0.6\n",
      "[592/1000]\n",
      "- [VAL] LOSS : 3.3511714718770236e-05 [SCORE] : 1.0\n",
      "[593/1000]\n",
      "- [TRAIN] LOSS : 2.3815532828545352e-05 [SCORE] : 0.6\n",
      "[593/1000]\n",
      "- [VAL] LOSS : 3.33082462020684e-05 [SCORE] : 1.0\n",
      "[594/1000]\n",
      "- [TRAIN] LOSS : 2.367451021806725e-05 [SCORE] : 0.6\n",
      "[594/1000]\n",
      "- [VAL] LOSS : 3.311819818918593e-05 [SCORE] : 1.0\n",
      "[595/1000]\n",
      "- [TRAIN] LOSS : 2.3539986614196096e-05 [SCORE] : 0.6\n",
      "[595/1000]\n",
      "- [VAL] LOSS : 3.2920190278673545e-05 [SCORE] : 1.0\n",
      "[596/1000]\n",
      "- [TRAIN] LOSS : 2.339765857565605e-05 [SCORE] : 0.6\n",
      "[596/1000]\n",
      "- [VAL] LOSS : 3.2735617423895746e-05 [SCORE] : 1.0\n",
      "[597/1000]\n",
      "- [TRAIN] LOSS : 2.326300558100532e-05 [SCORE] : 0.6\n",
      "[597/1000]\n",
      "- [VAL] LOSS : 3.254311377531849e-05 [SCORE] : 1.0\n",
      "[598/1000]\n",
      "- [TRAIN] LOSS : 2.3126864289224613e-05 [SCORE] : 0.6\n",
      "[598/1000]\n",
      "- [VAL] LOSS : 3.235545591451228e-05 [SCORE] : 1.0\n",
      "[599/1000]\n",
      "- [TRAIN] LOSS : 2.2991599568437474e-05 [SCORE] : 0.6\n",
      "[599/1000]\n",
      "- [VAL] LOSS : 3.217686389689334e-05 [SCORE] : 1.0\n",
      "[600/1000]\n",
      "- [TRAIN] LOSS : 2.2855210772831924e-05 [SCORE] : 0.6\n",
      "[600/1000]\n",
      "- [VAL] LOSS : 3.197753176209517e-05 [SCORE] : 1.0\n",
      "[601/1000]\n",
      "- [TRAIN] LOSS : 2.27244482327175e-05 [SCORE] : 0.6\n",
      "[601/1000]\n",
      "- [VAL] LOSS : 3.180317071382888e-05 [SCORE] : 1.0\n",
      "[602/1000]\n",
      "- [TRAIN] LOSS : 2.2594442452827933e-05 [SCORE] : 0.6\n",
      "[602/1000]\n",
      "- [VAL] LOSS : 3.161904896842316e-05 [SCORE] : 1.0\n",
      "[603/1000]\n",
      "- [TRAIN] LOSS : 2.2456585611507762e-05 [SCORE] : 0.6\n",
      "[603/1000]\n",
      "- [VAL] LOSS : 3.143318826914765e-05 [SCORE] : 1.0\n",
      "[604/1000]\n",
      "- [TRAIN] LOSS : 2.2326647134226126e-05 [SCORE] : 0.6\n",
      "[604/1000]\n",
      "- [VAL] LOSS : 3.124443901469931e-05 [SCORE] : 1.0\n",
      "[605/1000]\n",
      "- [TRAIN] LOSS : 2.2197233374754432e-05 [SCORE] : 0.6\n",
      "[605/1000]\n",
      "- [VAL] LOSS : 3.108208693447523e-05 [SCORE] : 1.0\n",
      "[606/1000]\n",
      "- [TRAIN] LOSS : 2.2066436091942402e-05 [SCORE] : 0.6\n",
      "[606/1000]\n",
      "- [VAL] LOSS : 3.089489837293513e-05 [SCORE] : 1.0\n",
      "[607/1000]\n",
      "- [TRAIN] LOSS : 2.1939874689754408e-05 [SCORE] : 0.6\n",
      "[607/1000]\n",
      "- [VAL] LOSS : 3.071683386224322e-05 [SCORE] : 1.0\n",
      "[608/1000]\n",
      "- [TRAIN] LOSS : 2.1810297706300238e-05 [SCORE] : 0.6\n",
      "[608/1000]\n",
      "- [VAL] LOSS : 3.053929322049953e-05 [SCORE] : 1.0\n",
      "[609/1000]\n",
      "- [TRAIN] LOSS : 2.168473462612989e-05 [SCORE] : 0.6\n",
      "[609/1000]\n",
      "- [VAL] LOSS : 3.036653833987657e-05 [SCORE] : 1.0\n",
      "[610/1000]\n",
      "- [TRAIN] LOSS : 2.1557639411184936e-05 [SCORE] : 0.6\n",
      "[610/1000]\n",
      "- [VAL] LOSS : 3.0190072720870376e-05 [SCORE] : 1.0\n",
      "[611/1000]\n",
      "- [TRAIN] LOSS : 2.143177850181625e-05 [SCORE] : 0.6\n",
      "[611/1000]\n",
      "- [VAL] LOSS : 3.001415461767465e-05 [SCORE] : 1.0\n",
      "[612/1000]\n",
      "- [TRAIN] LOSS : 2.1308359343189902e-05 [SCORE] : 0.6\n",
      "[612/1000]\n",
      "- [VAL] LOSS : 2.9842996809748e-05 [SCORE] : 1.0\n",
      "[613/1000]\n",
      "- [TRAIN] LOSS : 2.118256816174835e-05 [SCORE] : 0.6\n",
      "[613/1000]\n",
      "- [VAL] LOSS : 2.9679784347536042e-05 [SCORE] : 1.0\n",
      "[614/1000]\n",
      "- [TRAIN] LOSS : 2.106317951984238e-05 [SCORE] : 0.6\n",
      "[614/1000]\n",
      "- [VAL] LOSS : 2.9502551115001552e-05 [SCORE] : 1.0\n",
      "[615/1000]\n",
      "- [TRAIN] LOSS : 2.0942723131156528e-05 [SCORE] : 0.6\n",
      "[615/1000]\n",
      "- [VAL] LOSS : 2.9340493711060844e-05 [SCORE] : 1.0\n",
      "[616/1000]\n",
      "- [TRAIN] LOSS : 2.081771902642989e-05 [SCORE] : 0.6\n",
      "[616/1000]\n",
      "- [VAL] LOSS : 2.917547317338176e-05 [SCORE] : 1.0\n",
      "[617/1000]\n",
      "- [TRAIN] LOSS : 2.0697921718237923e-05 [SCORE] : 0.6\n",
      "[617/1000]\n",
      "- [VAL] LOSS : 2.900699109886773e-05 [SCORE] : 1.0\n",
      "[618/1000]\n",
      "- [TRAIN] LOSS : 2.0577033137669786e-05 [SCORE] : 0.6\n",
      "[618/1000]\n",
      "- [VAL] LOSS : 2.8830607334384695e-05 [SCORE] : 1.0\n",
      "[619/1000]\n",
      "- [TRAIN] LOSS : 2.0459497560902187e-05 [SCORE] : 0.6\n",
      "[619/1000]\n",
      "- [VAL] LOSS : 2.8667547667282633e-05 [SCORE] : 1.0\n",
      "[620/1000]\n",
      "- [TRAIN] LOSS : 2.0340897026471794e-05 [SCORE] : 0.6\n",
      "[620/1000]\n",
      "- [VAL] LOSS : 2.8500755433924496e-05 [SCORE] : 1.0\n",
      "[621/1000]\n",
      "- [TRAIN] LOSS : 2.0225102404462328e-05 [SCORE] : 0.6\n",
      "[621/1000]\n",
      "- [VAL] LOSS : 2.834721453837119e-05 [SCORE] : 1.0\n",
      "[622/1000]\n",
      "- [TRAIN] LOSS : 2.01069457034464e-05 [SCORE] : 0.6\n",
      "[622/1000]\n",
      "- [VAL] LOSS : 2.8194181140861474e-05 [SCORE] : 1.0\n",
      "[623/1000]\n",
      "- [TRAIN] LOSS : 1.9989993658479457e-05 [SCORE] : 0.6\n",
      "[623/1000]\n",
      "- [VAL] LOSS : 2.8020334866596386e-05 [SCORE] : 1.0\n",
      "[624/1000]\n",
      "- [TRAIN] LOSS : 1.9875416182912885e-05 [SCORE] : 0.6\n",
      "[624/1000]\n",
      "- [VAL] LOSS : 2.787145240290556e-05 [SCORE] : 1.0\n",
      "[625/1000]\n",
      "- [TRAIN] LOSS : 1.9762552013465515e-05 [SCORE] : 0.6\n",
      "[625/1000]\n",
      "- [VAL] LOSS : 2.771077743091155e-05 [SCORE] : 1.0\n",
      "[626/1000]\n",
      "- [TRAIN] LOSS : 1.9648740878134655e-05 [SCORE] : 0.6\n",
      "[626/1000]\n",
      "- [VAL] LOSS : 2.7558766305446625e-05 [SCORE] : 1.0\n",
      "[627/1000]\n",
      "- [TRAIN] LOSS : 1.953450052193754e-05 [SCORE] : 0.6\n",
      "[627/1000]\n",
      "- [VAL] LOSS : 2.739513001870364e-05 [SCORE] : 1.0\n",
      "[628/1000]\n",
      "- [TRAIN] LOSS : 1.942216604220448e-05 [SCORE] : 0.6\n",
      "[628/1000]\n",
      "- [VAL] LOSS : 2.7240757844992913e-05 [SCORE] : 1.0\n",
      "[629/1000]\n",
      "- [TRAIN] LOSS : 1.9308659526965737e-05 [SCORE] : 0.6\n",
      "[629/1000]\n",
      "- [VAL] LOSS : 2.7086984118795954e-05 [SCORE] : 1.0\n",
      "[630/1000]\n",
      "- [TRAIN] LOSS : 1.919930806858853e-05 [SCORE] : 0.6\n",
      "[630/1000]\n",
      "- [VAL] LOSS : 2.6933697881759144e-05 [SCORE] : 1.0\n",
      "[631/1000]\n",
      "- [TRAIN] LOSS : 1.9089200335050313e-05 [SCORE] : 0.6\n",
      "[631/1000]\n",
      "- [VAL] LOSS : 2.6772364435601048e-05 [SCORE] : 1.0\n",
      "[632/1000]\n",
      "- [TRAIN] LOSS : 1.8979909691552165e-05 [SCORE] : 0.6\n",
      "[632/1000]\n",
      "- [VAL] LOSS : 2.661999678821303e-05 [SCORE] : 1.0\n",
      "[633/1000]\n",
      "- [TRAIN] LOSS : 1.8868984989239833e-05 [SCORE] : 0.6\n",
      "[633/1000]\n",
      "- [VAL] LOSS : 2.6472351237316616e-05 [SCORE] : 1.0\n",
      "[634/1000]\n",
      "- [TRAIN] LOSS : 1.8761990759230684e-05 [SCORE] : 0.6\n",
      "[634/1000]\n",
      "- [VAL] LOSS : 2.6320876713725738e-05 [SCORE] : 1.0\n",
      "[635/1000]\n",
      "- [TRAIN] LOSS : 1.8654203086043707e-05 [SCORE] : 0.6\n",
      "[635/1000]\n",
      "- [VAL] LOSS : 2.6174146114499308e-05 [SCORE] : 1.0\n",
      "[636/1000]\n",
      "- [TRAIN] LOSS : 1.8548746569043337e-05 [SCORE] : 0.6\n",
      "[636/1000]\n",
      "- [VAL] LOSS : 2.6031100787804462e-05 [SCORE] : 1.0\n",
      "[637/1000]\n",
      "- [TRAIN] LOSS : 1.844117432483472e-05 [SCORE] : 0.6\n",
      "[637/1000]\n",
      "- [VAL] LOSS : 2.5878445740090683e-05 [SCORE] : 1.0\n",
      "[638/1000]\n",
      "- [TRAIN] LOSS : 1.8335870117880403e-05 [SCORE] : 0.6\n",
      "[638/1000]\n",
      "- [VAL] LOSS : 2.573639721958898e-05 [SCORE] : 1.0\n",
      "[639/1000]\n",
      "- [TRAIN] LOSS : 1.822910835471703e-05 [SCORE] : 0.6\n",
      "[639/1000]\n",
      "- [VAL] LOSS : 2.5595449187676422e-05 [SCORE] : 1.0\n",
      "[640/1000]\n",
      "- [TRAIN] LOSS : 1.812652778122962e-05 [SCORE] : 0.6\n",
      "[640/1000]\n",
      "- [VAL] LOSS : 2.5442439437028952e-05 [SCORE] : 1.0\n",
      "[641/1000]\n",
      "- [TRAIN] LOSS : 1.8021184041572268e-05 [SCORE] : 0.6\n",
      "[641/1000]\n",
      "- [VAL] LOSS : 2.530697383917868e-05 [SCORE] : 1.0\n",
      "[642/1000]\n",
      "- [TRAIN] LOSS : 1.7919932603642033e-05 [SCORE] : 0.6\n",
      "[642/1000]\n",
      "- [VAL] LOSS : 2.515922642487567e-05 [SCORE] : 1.0\n",
      "[643/1000]\n",
      "- [TRAIN] LOSS : 1.7817104435380315e-05 [SCORE] : 0.6\n",
      "[643/1000]\n",
      "- [VAL] LOSS : 2.502041206753347e-05 [SCORE] : 1.0\n",
      "[644/1000]\n",
      "- [TRAIN] LOSS : 1.7715058796360002e-05 [SCORE] : 0.6\n",
      "[644/1000]\n",
      "- [VAL] LOSS : 2.4886277969926596e-05 [SCORE] : 1.0\n",
      "[645/1000]\n",
      "- [TRAIN] LOSS : 1.761213570716791e-05 [SCORE] : 0.6\n",
      "[645/1000]\n",
      "- [VAL] LOSS : 2.4739772925386205e-05 [SCORE] : 1.0\n",
      "[646/1000]\n",
      "- [TRAIN] LOSS : 1.751390982462908e-05 [SCORE] : 0.6\n",
      "[646/1000]\n",
      "- [VAL] LOSS : 2.459794450260233e-05 [SCORE] : 1.0\n",
      "[647/1000]\n",
      "- [TRAIN] LOSS : 1.7414843205187937e-05 [SCORE] : 0.6\n",
      "[647/1000]\n",
      "- [VAL] LOSS : 2.4465052774758078e-05 [SCORE] : 1.0\n",
      "[648/1000]\n",
      "- [TRAIN] LOSS : 1.7314946974996324e-05 [SCORE] : 0.6\n",
      "[648/1000]\n",
      "- [VAL] LOSS : 2.4327422579517588e-05 [SCORE] : 1.0\n",
      "[649/1000]\n",
      "- [TRAIN] LOSS : 1.7218193291531256e-05 [SCORE] : 0.6\n",
      "[649/1000]\n",
      "- [VAL] LOSS : 2.4197233869927004e-05 [SCORE] : 1.0\n",
      "[650/1000]\n",
      "- [TRAIN] LOSS : 1.711741415419965e-05 [SCORE] : 0.6\n",
      "[650/1000]\n",
      "- [VAL] LOSS : 2.4051962100202218e-05 [SCORE] : 1.0\n",
      "[651/1000]\n",
      "- [TRAIN] LOSS : 1.7022154376415226e-05 [SCORE] : 0.6\n",
      "[651/1000]\n",
      "- [VAL] LOSS : 2.3924769266159274e-05 [SCORE] : 1.0\n",
      "[652/1000]\n",
      "- [TRAIN] LOSS : 1.6923034975964887e-05 [SCORE] : 0.6\n",
      "[652/1000]\n",
      "- [VAL] LOSS : 2.3789678380126134e-05 [SCORE] : 1.0\n",
      "[653/1000]\n",
      "- [TRAIN] LOSS : 1.6829813527389586e-05 [SCORE] : 0.6\n",
      "[653/1000]\n",
      "- [VAL] LOSS : 2.3655107725062408e-05 [SCORE] : 1.0\n",
      "[654/1000]\n",
      "- [TRAIN] LOSS : 1.67319126073077e-05 [SCORE] : 0.6\n",
      "[654/1000]\n",
      "- [VAL] LOSS : 2.3525208234786987e-05 [SCORE] : 1.0\n",
      "[655/1000]\n",
      "- [TRAIN] LOSS : 1.663797899406442e-05 [SCORE] : 0.6\n",
      "[655/1000]\n",
      "- [VAL] LOSS : 2.3387214241665788e-05 [SCORE] : 1.0\n",
      "[656/1000]\n",
      "- [TRAIN] LOSS : 1.654318742415247e-05 [SCORE] : 0.6\n",
      "[656/1000]\n",
      "- [VAL] LOSS : 2.3262397007783875e-05 [SCORE] : 1.0\n",
      "[657/1000]\n",
      "- [TRAIN] LOSS : 1.644676776777487e-05 [SCORE] : 0.6\n",
      "[657/1000]\n",
      "- [VAL] LOSS : 2.3137941752793267e-05 [SCORE] : 1.0\n",
      "[658/1000]\n",
      "- [TRAIN] LOSS : 1.6356155538232996e-05 [SCORE] : 0.6\n",
      "[658/1000]\n",
      "- [VAL] LOSS : 2.300533560628537e-05 [SCORE] : 1.0\n",
      "[659/1000]\n",
      "- [TRAIN] LOSS : 1.6260690851292264e-05 [SCORE] : 0.6\n",
      "[659/1000]\n",
      "- [VAL] LOSS : 2.2868842279422097e-05 [SCORE] : 1.0\n",
      "[660/1000]\n",
      "- [TRAIN] LOSS : 1.6172268199928416e-05 [SCORE] : 0.6\n",
      "[660/1000]\n",
      "- [VAL] LOSS : 2.2740379790775478e-05 [SCORE] : 1.0\n",
      "[661/1000]\n",
      "- [TRAIN] LOSS : 1.608033853699453e-05 [SCORE] : 0.6\n",
      "[661/1000]\n",
      "- [VAL] LOSS : 2.2615184207097627e-05 [SCORE] : 1.0\n",
      "[662/1000]\n",
      "- [TRAIN] LOSS : 1.5991614024339166e-05 [SCORE] : 0.6\n",
      "[662/1000]\n",
      "- [VAL] LOSS : 2.24961058847839e-05 [SCORE] : 1.0\n",
      "[663/1000]\n",
      "- [TRAIN] LOSS : 1.5899931167950853e-05 [SCORE] : 0.6\n",
      "[663/1000]\n",
      "- [VAL] LOSS : 2.2373735191649757e-05 [SCORE] : 1.0\n",
      "[664/1000]\n",
      "- [TRAIN] LOSS : 1.581069454914541e-05 [SCORE] : 0.6\n",
      "[664/1000]\n",
      "- [VAL] LOSS : 2.224769923486747e-05 [SCORE] : 1.0\n",
      "[665/1000]\n",
      "- [TRAIN] LOSS : 1.5717768898563616e-05 [SCORE] : 0.6\n",
      "[665/1000]\n",
      "- [VAL] LOSS : 2.2117854314274155e-05 [SCORE] : 1.0\n",
      "[666/1000]\n",
      "- [TRAIN] LOSS : 1.5628031602924843e-05 [SCORE] : 0.6\n",
      "[666/1000]\n",
      "- [VAL] LOSS : 2.200118251494132e-05 [SCORE] : 1.0\n",
      "[667/1000]\n",
      "- [TRAIN] LOSS : 1.55414042941023e-05 [SCORE] : 0.6\n",
      "[667/1000]\n",
      "- [VAL] LOSS : 2.1867852410650812e-05 [SCORE] : 1.0\n",
      "[668/1000]\n",
      "- [TRAIN] LOSS : 1.5454296377962843e-05 [SCORE] : 0.6\n",
      "[668/1000]\n",
      "- [VAL] LOSS : 2.1756144633400254e-05 [SCORE] : 1.0\n",
      "[669/1000]\n",
      "- [TRAIN] LOSS : 1.536708641651785e-05 [SCORE] : 0.6\n",
      "[669/1000]\n",
      "- [VAL] LOSS : 2.162779674108606e-05 [SCORE] : 1.0\n",
      "[670/1000]\n",
      "- [TRAIN] LOSS : 1.528057734200653e-05 [SCORE] : 0.6\n",
      "[670/1000]\n",
      "- [VAL] LOSS : 2.15125492104562e-05 [SCORE] : 1.0\n",
      "[671/1000]\n",
      "- [TRAIN] LOSS : 1.5193954095593653e-05 [SCORE] : 0.6\n",
      "[671/1000]\n",
      "- [VAL] LOSS : 2.1389161702245474e-05 [SCORE] : 1.0\n",
      "[672/1000]\n",
      "- [TRAIN] LOSS : 1.5107219890827158e-05 [SCORE] : 0.6\n",
      "[672/1000]\n",
      "- [VAL] LOSS : 2.1273774109431542e-05 [SCORE] : 1.0\n",
      "[673/1000]\n",
      "- [TRAIN] LOSS : 1.5026140893799796e-05 [SCORE] : 0.6\n",
      "[673/1000]\n",
      "- [VAL] LOSS : 2.1161702534300275e-05 [SCORE] : 1.0\n",
      "[674/1000]\n",
      "- [TRAIN] LOSS : 1.4939584919678358e-05 [SCORE] : 0.6\n",
      "[674/1000]\n",
      "- [VAL] LOSS : 2.104286068060901e-05 [SCORE] : 1.0\n",
      "[675/1000]\n",
      "- [TRAIN] LOSS : 1.4855069730401738e-05 [SCORE] : 0.6\n",
      "[675/1000]\n",
      "- [VAL] LOSS : 2.0920659153489396e-05 [SCORE] : 1.0\n",
      "[676/1000]\n",
      "- [TRAIN] LOSS : 1.4771711660917692e-05 [SCORE] : 0.6\n",
      "[676/1000]\n",
      "- [VAL] LOSS : 2.0807554392376915e-05 [SCORE] : 1.0\n",
      "[677/1000]\n",
      "- [TRAIN] LOSS : 1.46869899253943e-05 [SCORE] : 0.6\n",
      "[677/1000]\n",
      "- [VAL] LOSS : 2.0703371774288826e-05 [SCORE] : 1.0\n",
      "[678/1000]\n",
      "- [TRAIN] LOSS : 1.460705580029753e-05 [SCORE] : 0.6\n",
      "[678/1000]\n",
      "- [VAL] LOSS : 2.0578272597049363e-05 [SCORE] : 1.0\n",
      "[679/1000]\n",
      "- [TRAIN] LOSS : 1.45222585463974e-05 [SCORE] : 0.6\n",
      "[679/1000]\n",
      "- [VAL] LOSS : 2.0462010070332326e-05 [SCORE] : 1.0\n",
      "[680/1000]\n",
      "- [TRAIN] LOSS : 1.444449914439853e-05 [SCORE] : 0.6\n",
      "[680/1000]\n",
      "- [VAL] LOSS : 2.035459692706354e-05 [SCORE] : 1.0\n",
      "[681/1000]\n",
      "- [TRAIN] LOSS : 1.4361463126988382e-05 [SCORE] : 0.6\n",
      "[681/1000]\n",
      "- [VAL] LOSS : 2.0239016521372832e-05 [SCORE] : 1.0\n",
      "[682/1000]\n",
      "- [TRAIN] LOSS : 1.4280698026899093e-05 [SCORE] : 0.6\n",
      "[682/1000]\n",
      "- [VAL] LOSS : 2.0123776266700588e-05 [SCORE] : 1.0\n",
      "[683/1000]\n",
      "- [TRAIN] LOSS : 1.4200580699252896e-05 [SCORE] : 0.6\n",
      "[683/1000]\n",
      "- [VAL] LOSS : 2.0008039427921176e-05 [SCORE] : 1.0\n",
      "[684/1000]\n",
      "- [TRAIN] LOSS : 1.4122248164009458e-05 [SCORE] : 0.6\n",
      "[684/1000]\n",
      "- [VAL] LOSS : 1.9908426111214794e-05 [SCORE] : 1.0\n",
      "[685/1000]\n",
      "- [TRAIN] LOSS : 1.4042438366838421e-05 [SCORE] : 0.6\n",
      "[685/1000]\n",
      "- [VAL] LOSS : 1.980620982067194e-05 [SCORE] : 1.0\n",
      "[686/1000]\n",
      "- [TRAIN] LOSS : 1.3963710504564612e-05 [SCORE] : 0.6\n",
      "[686/1000]\n",
      "- [VAL] LOSS : 1.968776632566005e-05 [SCORE] : 1.0\n",
      "[687/1000]\n",
      "- [TRAIN] LOSS : 1.3886849016368312e-05 [SCORE] : 0.6\n",
      "[687/1000]\n",
      "- [VAL] LOSS : 1.9582657841965556e-05 [SCORE] : 1.0\n",
      "[688/1000]\n",
      "- [TRAIN] LOSS : 1.3806240682849117e-05 [SCORE] : 0.6\n",
      "[688/1000]\n",
      "- [VAL] LOSS : 1.9477945897961035e-05 [SCORE] : 1.0\n",
      "[689/1000]\n",
      "- [TRAIN] LOSS : 1.373039125004046e-05 [SCORE] : 0.6\n",
      "[689/1000]\n",
      "- [VAL] LOSS : 1.935653926921077e-05 [SCORE] : 1.0\n",
      "[690/1000]\n",
      "- [TRAIN] LOSS : 1.3654015492647887e-05 [SCORE] : 0.6\n",
      "[690/1000]\n",
      "- [VAL] LOSS : 1.9256754967500456e-05 [SCORE] : 1.0\n",
      "[691/1000]\n",
      "- [TRAIN] LOSS : 1.3576715112625e-05 [SCORE] : 0.6\n",
      "[691/1000]\n",
      "- [VAL] LOSS : 1.915298526000697e-05 [SCORE] : 1.0\n",
      "[692/1000]\n",
      "- [TRAIN] LOSS : 1.3499264878191752e-05 [SCORE] : 0.6\n",
      "[692/1000]\n",
      "- [VAL] LOSS : 1.9045244698645547e-05 [SCORE] : 1.0\n",
      "[693/1000]\n",
      "- [TRAIN] LOSS : 1.3427580173204963e-05 [SCORE] : 0.6\n",
      "[693/1000]\n",
      "- [VAL] LOSS : 1.8933569663204253e-05 [SCORE] : 1.0\n",
      "[694/1000]\n",
      "- [TRAIN] LOSS : 1.3351005297105682e-05 [SCORE] : 0.6\n",
      "[694/1000]\n",
      "- [VAL] LOSS : 1.8834969523595646e-05 [SCORE] : 1.0\n",
      "[695/1000]\n",
      "- [TRAIN] LOSS : 1.3277459887225026e-05 [SCORE] : 0.6\n",
      "[695/1000]\n",
      "- [VAL] LOSS : 1.8744458429864608e-05 [SCORE] : 1.0\n",
      "[696/1000]\n",
      "- [TRAIN] LOSS : 1.320382231521459e-05 [SCORE] : 0.6\n",
      "[696/1000]\n",
      "- [VAL] LOSS : 1.862753924797289e-05 [SCORE] : 1.0\n",
      "[697/1000]\n",
      "- [TRAIN] LOSS : 1.3129148646839894e-05 [SCORE] : 0.6\n",
      "[697/1000]\n",
      "- [VAL] LOSS : 1.85334611160215e-05 [SCORE] : 1.0\n",
      "[698/1000]\n",
      "- [TRAIN] LOSS : 1.3056237973311606e-05 [SCORE] : 0.6\n",
      "[698/1000]\n",
      "- [VAL] LOSS : 1.8435888705425896e-05 [SCORE] : 1.0\n",
      "[699/1000]\n",
      "- [TRAIN] LOSS : 1.2985127038215675e-05 [SCORE] : 0.6\n",
      "[699/1000]\n",
      "- [VAL] LOSS : 1.833456553868018e-05 [SCORE] : 1.0\n",
      "[700/1000]\n",
      "- [TRAIN] LOSS : 1.2910204835255476e-05 [SCORE] : 0.6\n",
      "[700/1000]\n",
      "- [VAL] LOSS : 1.8237873518955894e-05 [SCORE] : 1.0\n",
      "[701/1000]\n",
      "- [TRAIN] LOSS : 1.2839231506707923e-05 [SCORE] : 0.6\n",
      "[701/1000]\n",
      "- [VAL] LOSS : 1.813298513297923e-05 [SCORE] : 1.0\n",
      "[702/1000]\n",
      "- [TRAIN] LOSS : 1.276851447376733e-05 [SCORE] : 0.6\n",
      "[702/1000]\n",
      "- [VAL] LOSS : 1.80241131602088e-05 [SCORE] : 1.0\n",
      "[703/1000]\n",
      "- [TRAIN] LOSS : 1.2698838903209738e-05 [SCORE] : 0.6\n",
      "[703/1000]\n",
      "- [VAL] LOSS : 1.7936832591658458e-05 [SCORE] : 1.0\n",
      "[704/1000]\n",
      "- [TRAIN] LOSS : 1.2625817180378363e-05 [SCORE] : 0.6\n",
      "[704/1000]\n",
      "- [VAL] LOSS : 1.7828549971454777e-05 [SCORE] : 1.0\n",
      "[705/1000]\n",
      "- [TRAIN] LOSS : 1.2558196006769625e-05 [SCORE] : 0.6\n",
      "[705/1000]\n",
      "- [VAL] LOSS : 1.7737553207552992e-05 [SCORE] : 1.0\n",
      "[706/1000]\n",
      "- [TRAIN] LOSS : 1.2486024540218446e-05 [SCORE] : 0.6\n",
      "[706/1000]\n",
      "- [VAL] LOSS : 1.763826367096044e-05 [SCORE] : 1.0\n",
      "[707/1000]\n",
      "- [TRAIN] LOSS : 1.2418934117401174e-05 [SCORE] : 0.6\n",
      "[707/1000]\n",
      "- [VAL] LOSS : 1.7542623027111404e-05 [SCORE] : 1.0\n",
      "[708/1000]\n",
      "- [TRAIN] LOSS : 1.2349561438895762e-05 [SCORE] : 0.6\n",
      "[708/1000]\n",
      "- [VAL] LOSS : 1.7458904039813206e-05 [SCORE] : 1.0\n",
      "[709/1000]\n",
      "- [TRAIN] LOSS : 1.2281407089176355e-05 [SCORE] : 0.6\n",
      "[709/1000]\n",
      "- [VAL] LOSS : 1.7359603589284234e-05 [SCORE] : 1.0\n",
      "[710/1000]\n",
      "- [TRAIN] LOSS : 1.2212854926474392e-05 [SCORE] : 0.6\n",
      "[710/1000]\n",
      "- [VAL] LOSS : 1.7261048924410716e-05 [SCORE] : 1.0\n",
      "[711/1000]\n",
      "- [TRAIN] LOSS : 1.2144098764110823e-05 [SCORE] : 0.6\n",
      "[711/1000]\n",
      "- [VAL] LOSS : 1.717576196824666e-05 [SCORE] : 1.0\n",
      "[712/1000]\n",
      "- [TRAIN] LOSS : 1.207951772812521e-05 [SCORE] : 0.6\n",
      "[712/1000]\n",
      "- [VAL] LOSS : 1.708661329757888e-05 [SCORE] : 1.0\n",
      "[713/1000]\n",
      "- [TRAIN] LOSS : 1.2012203872776203e-05 [SCORE] : 0.6\n",
      "[713/1000]\n",
      "- [VAL] LOSS : 1.6989271898637526e-05 [SCORE] : 1.0\n",
      "[714/1000]\n",
      "- [TRAIN] LOSS : 1.1944822532920323e-05 [SCORE] : 0.6\n",
      "[714/1000]\n",
      "- [VAL] LOSS : 1.6896496163099073e-05 [SCORE] : 1.0\n",
      "[715/1000]\n",
      "- [TRAIN] LOSS : 1.1878155055455863e-05 [SCORE] : 0.6\n",
      "[715/1000]\n",
      "- [VAL] LOSS : 1.6812511603347957e-05 [SCORE] : 1.0\n",
      "[716/1000]\n",
      "- [TRAIN] LOSS : 1.1812535043039436e-05 [SCORE] : 0.6\n",
      "[716/1000]\n",
      "- [VAL] LOSS : 1.671601967245806e-05 [SCORE] : 1.0\n",
      "[717/1000]\n",
      "- [TRAIN] LOSS : 1.17487564542292e-05 [SCORE] : 0.6\n",
      "[717/1000]\n",
      "- [VAL] LOSS : 1.6631944163236767e-05 [SCORE] : 1.0\n",
      "[718/1000]\n",
      "- [TRAIN] LOSS : 1.1682709494683271e-05 [SCORE] : 0.6\n",
      "[718/1000]\n",
      "- [VAL] LOSS : 1.654283369134646e-05 [SCORE] : 1.0\n",
      "[719/1000]\n",
      "- [TRAIN] LOSS : 1.1616992257283224e-05 [SCORE] : 0.6\n",
      "[719/1000]\n",
      "- [VAL] LOSS : 1.6450878320029005e-05 [SCORE] : 1.0\n",
      "[720/1000]\n",
      "- [TRAIN] LOSS : 1.1554812802690624e-05 [SCORE] : 0.6\n",
      "[720/1000]\n",
      "- [VAL] LOSS : 1.635963963053655e-05 [SCORE] : 1.0\n",
      "[721/1000]\n",
      "- [TRAIN] LOSS : 1.1493190868350212e-05 [SCORE] : 0.6\n",
      "[721/1000]\n",
      "- [VAL] LOSS : 1.627737219678238e-05 [SCORE] : 1.0\n",
      "[722/1000]\n",
      "- [TRAIN] LOSS : 1.142458753141303e-05 [SCORE] : 0.6\n",
      "[722/1000]\n",
      "- [VAL] LOSS : 1.6195450371014886e-05 [SCORE] : 1.0\n",
      "[723/1000]\n",
      "- [TRAIN] LOSS : 1.1364267569054695e-05 [SCORE] : 0.6\n",
      "[723/1000]\n",
      "- [VAL] LOSS : 1.6105275790323503e-05 [SCORE] : 1.0\n",
      "[724/1000]\n",
      "- [TRAIN] LOSS : 1.1301803927684281e-05 [SCORE] : 0.6\n",
      "[724/1000]\n",
      "- [VAL] LOSS : 1.6015361325116828e-05 [SCORE] : 1.0\n",
      "[725/1000]\n",
      "- [TRAIN] LOSS : 1.1237604424726062e-05 [SCORE] : 0.6\n",
      "[725/1000]\n",
      "- [VAL] LOSS : 1.592997068655677e-05 [SCORE] : 1.0\n",
      "[726/1000]\n",
      "- [TRAIN] LOSS : 1.117641407593813e-05 [SCORE] : 0.6\n",
      "[726/1000]\n",
      "- [VAL] LOSS : 1.5844194422243163e-05 [SCORE] : 1.0\n",
      "[727/1000]\n",
      "- [TRAIN] LOSS : 1.111729661715799e-05 [SCORE] : 0.6\n",
      "[727/1000]\n",
      "- [VAL] LOSS : 1.5757650544401258e-05 [SCORE] : 1.0\n",
      "[728/1000]\n",
      "- [TRAIN] LOSS : 1.1055739772321734e-05 [SCORE] : 0.6\n",
      "[728/1000]\n",
      "- [VAL] LOSS : 1.5676718248869292e-05 [SCORE] : 1.0\n",
      "[729/1000]\n",
      "- [TRAIN] LOSS : 1.0991672570526135e-05 [SCORE] : 0.6\n",
      "[729/1000]\n",
      "- [VAL] LOSS : 1.5592204363201745e-05 [SCORE] : 1.0\n",
      "[730/1000]\n",
      "- [TRAIN] LOSS : 1.0932836660989172e-05 [SCORE] : 0.6\n",
      "[730/1000]\n",
      "- [VAL] LOSS : 1.5508083379245363e-05 [SCORE] : 1.0\n",
      "[731/1000]\n",
      "- [TRAIN] LOSS : 1.0871258958407755e-05 [SCORE] : 0.6\n",
      "[731/1000]\n",
      "- [VAL] LOSS : 1.5424260709551163e-05 [SCORE] : 1.0\n",
      "[732/1000]\n",
      "- [TRAIN] LOSS : 1.0815556803815222e-05 [SCORE] : 0.6\n",
      "[732/1000]\n",
      "- [VAL] LOSS : 1.5336469004978426e-05 [SCORE] : 1.0\n",
      "[733/1000]\n",
      "- [TRAIN] LOSS : 1.0754557691446582e-05 [SCORE] : 0.6\n",
      "[733/1000]\n",
      "- [VAL] LOSS : 1.526170308352448e-05 [SCORE] : 1.0\n",
      "[734/1000]\n",
      "- [TRAIN] LOSS : 1.0693005303134365e-05 [SCORE] : 0.6\n",
      "[734/1000]\n",
      "- [VAL] LOSS : 1.5178636203927454e-05 [SCORE] : 1.0\n",
      "[735/1000]\n",
      "- [TRAIN] LOSS : 1.0636359487155763e-05 [SCORE] : 0.6\n",
      "[735/1000]\n",
      "- [VAL] LOSS : 1.509943376731826e-05 [SCORE] : 1.0\n",
      "[736/1000]\n",
      "- [TRAIN] LOSS : 1.0581002091688182e-05 [SCORE] : 0.6\n",
      "[736/1000]\n",
      "- [VAL] LOSS : 1.5019511920399964e-05 [SCORE] : 1.0\n",
      "[737/1000]\n",
      "- [TRAIN] LOSS : 1.0521272057909907e-05 [SCORE] : 0.6\n",
      "[737/1000]\n",
      "- [VAL] LOSS : 1.492807950853603e-05 [SCORE] : 1.0\n",
      "[738/1000]\n",
      "- [TRAIN] LOSS : 1.046212119035772e-05 [SCORE] : 0.6\n",
      "[738/1000]\n",
      "- [VAL] LOSS : 1.4858602298772894e-05 [SCORE] : 1.0\n",
      "[739/1000]\n",
      "- [TRAIN] LOSS : 1.040617718596574e-05 [SCORE] : 0.6\n",
      "[739/1000]\n",
      "- [VAL] LOSS : 1.4768193977943156e-05 [SCORE] : 1.0\n",
      "[740/1000]\n",
      "- [TRAIN] LOSS : 1.0346655153625761e-05 [SCORE] : 0.6\n",
      "[740/1000]\n",
      "- [VAL] LOSS : 1.4690803254779894e-05 [SCORE] : 1.0\n",
      "[741/1000]\n",
      "- [TRAIN] LOSS : 1.0290948921465315e-05 [SCORE] : 0.6\n",
      "[741/1000]\n",
      "- [VAL] LOSS : 1.4613681742048357e-05 [SCORE] : 1.0\n",
      "[742/1000]\n",
      "- [TRAIN] LOSS : 1.0235072143890042e-05 [SCORE] : 0.6\n",
      "[742/1000]\n",
      "- [VAL] LOSS : 1.4536794878949877e-05 [SCORE] : 1.0\n",
      "[743/1000]\n",
      "- [TRAIN] LOSS : 1.018096209008945e-05 [SCORE] : 0.6\n",
      "[743/1000]\n",
      "- [VAL] LOSS : 1.4464390005741734e-05 [SCORE] : 1.0\n",
      "[744/1000]\n",
      "- [TRAIN] LOSS : 1.0126252376115492e-05 [SCORE] : 0.6\n",
      "[744/1000]\n",
      "- [VAL] LOSS : 1.4378837477124762e-05 [SCORE] : 1.0\n",
      "[745/1000]\n",
      "- [TRAIN] LOSS : 1.0067750220817592e-05 [SCORE] : 0.6\n",
      "[745/1000]\n",
      "- [VAL] LOSS : 1.4309615835372824e-05 [SCORE] : 1.0\n",
      "[746/1000]\n",
      "- [TRAIN] LOSS : 1.0015978902326121e-05 [SCORE] : 0.6\n",
      "[746/1000]\n",
      "- [VAL] LOSS : 1.4233062756829895e-05 [SCORE] : 1.0\n",
      "[747/1000]\n",
      "- [TRAIN] LOSS : 9.95792864462904e-06 [SCORE] : 0.6\n",
      "[747/1000]\n",
      "- [VAL] LOSS : 1.4157138139125891e-05 [SCORE] : 1.0\n",
      "[748/1000]\n",
      "- [TRAIN] LOSS : 9.905415451309333e-06 [SCORE] : 0.6\n",
      "[748/1000]\n",
      "- [VAL] LOSS : 1.4073058082431089e-05 [SCORE] : 1.0\n",
      "[749/1000]\n",
      "- [TRAIN] LOSS : 9.851732465904206e-06 [SCORE] : 0.6\n",
      "[749/1000]\n",
      "- [VAL] LOSS : 1.400204018864315e-05 [SCORE] : 1.0\n",
      "[750/1000]\n",
      "- [TRAIN] LOSS : 9.79393848865584e-06 [SCORE] : 0.6\n",
      "[750/1000]\n",
      "- [VAL] LOSS : 1.3918463082518429e-05 [SCORE] : 1.0\n",
      "[751/1000]\n",
      "- [TRAIN] LOSS : 9.742287617579375e-06 [SCORE] : 0.6\n",
      "[751/1000]\n",
      "- [VAL] LOSS : 1.3847871741745621e-05 [SCORE] : 1.0\n",
      "[752/1000]\n",
      "- [TRAIN] LOSS : 9.68920608102053e-06 [SCORE] : 0.6\n",
      "[752/1000]\n",
      "- [VAL] LOSS : 1.3781745110463817e-05 [SCORE] : 1.0\n",
      "[753/1000]\n",
      "- [TRAIN] LOSS : 9.637090139828311e-06 [SCORE] : 0.6\n",
      "[753/1000]\n",
      "- [VAL] LOSS : 1.3698807379114442e-05 [SCORE] : 1.0\n",
      "[754/1000]\n",
      "- [TRAIN] LOSS : 9.584736487037541e-06 [SCORE] : 0.6\n",
      "[754/1000]\n",
      "- [VAL] LOSS : 1.3636774383485317e-05 [SCORE] : 1.0\n",
      "[755/1000]\n",
      "- [TRAIN] LOSS : 9.533397542327293e-06 [SCORE] : 0.6\n",
      "[755/1000]\n",
      "- [VAL] LOSS : 1.3557043530454393e-05 [SCORE] : 1.0\n",
      "[756/1000]\n",
      "- [TRAIN] LOSS : 9.481281934616466e-06 [SCORE] : 0.6\n",
      "[756/1000]\n",
      "- [VAL] LOSS : 1.349549802398542e-05 [SCORE] : 1.0\n",
      "[757/1000]\n",
      "- [TRAIN] LOSS : 9.42915391230296e-06 [SCORE] : 0.6\n",
      "[757/1000]\n",
      "- [VAL] LOSS : 1.3417507943813689e-05 [SCORE] : 1.0\n",
      "[758/1000]\n",
      "- [TRAIN] LOSS : 9.38015282372362e-06 [SCORE] : 0.6\n",
      "[758/1000]\n",
      "- [VAL] LOSS : 1.3344127182790544e-05 [SCORE] : 1.0\n",
      "[759/1000]\n",
      "- [TRAIN] LOSS : 9.327178698489055e-06 [SCORE] : 0.6\n",
      "[759/1000]\n",
      "- [VAL] LOSS : 1.3275249330035876e-05 [SCORE] : 1.0\n",
      "[760/1000]\n",
      "- [TRAIN] LOSS : 9.276435806289858e-06 [SCORE] : 0.6\n",
      "[760/1000]\n",
      "- [VAL] LOSS : 1.3202348782215267e-05 [SCORE] : 1.0\n",
      "[761/1000]\n",
      "- [TRAIN] LOSS : 9.225083249475575e-06 [SCORE] : 0.6\n",
      "[761/1000]\n",
      "- [VAL] LOSS : 1.3133883840055205e-05 [SCORE] : 1.0\n",
      "[762/1000]\n",
      "- [TRAIN] LOSS : 9.174654663487065e-06 [SCORE] : 0.6\n",
      "[762/1000]\n",
      "- [VAL] LOSS : 1.3061346180620603e-05 [SCORE] : 1.0\n",
      "[763/1000]\n",
      "- [TRAIN] LOSS : 9.125952389391994e-06 [SCORE] : 0.6\n",
      "[763/1000]\n",
      "- [VAL] LOSS : 1.2988467460672837e-05 [SCORE] : 1.0\n",
      "[764/1000]\n",
      "- [TRAIN] LOSS : 9.074332638192573e-06 [SCORE] : 0.6\n",
      "[764/1000]\n",
      "- [VAL] LOSS : 1.2919203982164618e-05 [SCORE] : 1.0\n",
      "[765/1000]\n",
      "- [TRAIN] LOSS : 9.027124709367248e-06 [SCORE] : 0.6\n",
      "[765/1000]\n",
      "- [VAL] LOSS : 1.285954476770712e-05 [SCORE] : 1.0\n",
      "[766/1000]\n",
      "- [TRAIN] LOSS : 8.977451140405416e-06 [SCORE] : 0.6\n",
      "[766/1000]\n",
      "- [VAL] LOSS : 1.27876646729419e-05 [SCORE] : 1.0\n",
      "[767/1000]\n",
      "- [TRAIN] LOSS : 8.929266247529691e-06 [SCORE] : 0.6\n",
      "[767/1000]\n",
      "- [VAL] LOSS : 1.2716112905764021e-05 [SCORE] : 1.0\n",
      "[768/1000]\n",
      "- [TRAIN] LOSS : 8.879860797605942e-06 [SCORE] : 0.6\n",
      "[768/1000]\n",
      "- [VAL] LOSS : 1.2649054951907601e-05 [SCORE] : 1.0\n",
      "[769/1000]\n",
      "- [TRAIN] LOSS : 8.831076138449135e-06 [SCORE] : 0.6\n",
      "[769/1000]\n",
      "- [VAL] LOSS : 1.2586462617036887e-05 [SCORE] : 1.0\n",
      "[770/1000]\n",
      "- [TRAIN] LOSS : 8.784450953195725e-06 [SCORE] : 0.6\n",
      "[770/1000]\n",
      "- [VAL] LOSS : 1.2519800293375738e-05 [SCORE] : 1.0\n",
      "[771/1000]\n",
      "- [TRAIN] LOSS : 8.735592700759298e-06 [SCORE] : 0.6\n",
      "[771/1000]\n",
      "- [VAL] LOSS : 1.2444809726730455e-05 [SCORE] : 1.0\n",
      "[772/1000]\n",
      "- [TRAIN] LOSS : 8.690838725063561e-06 [SCORE] : 0.6\n",
      "[772/1000]\n",
      "- [VAL] LOSS : 1.2390795745886862e-05 [SCORE] : 1.0\n",
      "[773/1000]\n",
      "- [TRAIN] LOSS : 8.644410293830636e-06 [SCORE] : 0.6\n",
      "[773/1000]\n",
      "- [VAL] LOSS : 1.2314849300310016e-05 [SCORE] : 1.0\n",
      "[774/1000]\n",
      "- [TRAIN] LOSS : 8.59725046211679e-06 [SCORE] : 0.6\n",
      "[774/1000]\n",
      "- [VAL] LOSS : 1.2252728993189521e-05 [SCORE] : 1.0\n",
      "[775/1000]\n",
      "- [TRAIN] LOSS : 8.549552133748268e-06 [SCORE] : 0.6\n",
      "[775/1000]\n",
      "- [VAL] LOSS : 1.2199650882394053e-05 [SCORE] : 1.0\n",
      "[776/1000]\n",
      "- [TRAIN] LOSS : 8.503708007386498e-06 [SCORE] : 0.6\n",
      "[776/1000]\n",
      "- [VAL] LOSS : 1.2125591638323385e-05 [SCORE] : 1.0\n",
      "[777/1000]\n",
      "- [TRAIN] LOSS : 8.455817654369943e-06 [SCORE] : 0.6\n",
      "[777/1000]\n",
      "- [VAL] LOSS : 1.2056016203132458e-05 [SCORE] : 1.0\n",
      "[778/1000]\n",
      "- [TRAIN] LOSS : 8.409708016188233e-06 [SCORE] : 0.6\n",
      "[778/1000]\n",
      "- [VAL] LOSS : 1.1986624485871289e-05 [SCORE] : 1.0\n",
      "[779/1000]\n",
      "- [TRAIN] LOSS : 8.366139081772416e-06 [SCORE] : 0.6\n",
      "[779/1000]\n",
      "- [VAL] LOSS : 1.1930193068110384e-05 [SCORE] : 1.0\n",
      "[780/1000]\n",
      "- [TRAIN] LOSS : 8.317553511005827e-06 [SCORE] : 0.6\n",
      "[780/1000]\n",
      "- [VAL] LOSS : 1.1865419764944818e-05 [SCORE] : 1.0\n",
      "[781/1000]\n",
      "- [TRAIN] LOSS : 8.274261411618984e-06 [SCORE] : 0.6\n",
      "[781/1000]\n",
      "- [VAL] LOSS : 1.1800832908193115e-05 [SCORE] : 1.0\n",
      "[782/1000]\n",
      "- [TRAIN] LOSS : 8.22950596557348e-06 [SCORE] : 0.6\n",
      "[782/1000]\n",
      "- [VAL] LOSS : 1.1748673387046438e-05 [SCORE] : 1.0\n",
      "[783/1000]\n",
      "- [TRAIN] LOSS : 8.189441723516211e-06 [SCORE] : 0.6\n",
      "[783/1000]\n",
      "- [VAL] LOSS : 1.1687427104334347e-05 [SCORE] : 1.0\n",
      "[784/1000]\n",
      "- [TRAIN] LOSS : 8.142370522061052e-06 [SCORE] : 0.6\n",
      "[784/1000]\n",
      "- [VAL] LOSS : 1.1618661119427998e-05 [SCORE] : 1.0\n",
      "[785/1000]\n",
      "- [TRAIN] LOSS : 8.0974618261583e-06 [SCORE] : 0.6\n",
      "[785/1000]\n",
      "- [VAL] LOSS : 1.1558910955500323e-05 [SCORE] : 1.0\n",
      "[786/1000]\n",
      "- [TRAIN] LOSS : 8.052772955124965e-06 [SCORE] : 0.6\n",
      "[786/1000]\n",
      "- [VAL] LOSS : 1.1495192666188814e-05 [SCORE] : 1.0\n",
      "[787/1000]\n",
      "- [TRAIN] LOSS : 8.010391184143373e-06 [SCORE] : 0.6\n",
      "[787/1000]\n",
      "- [VAL] LOSS : 1.144019825005671e-05 [SCORE] : 1.0\n",
      "[788/1000]\n",
      "- [TRAIN] LOSS : 7.968200391890907e-06 [SCORE] : 0.6\n",
      "[788/1000]\n",
      "- [VAL] LOSS : 1.1372625522199087e-05 [SCORE] : 1.0\n",
      "[789/1000]\n",
      "- [TRAIN] LOSS : 7.925389960898125e-06 [SCORE] : 0.6\n",
      "[789/1000]\n",
      "- [VAL] LOSS : 1.131800399889471e-05 [SCORE] : 1.0\n",
      "[790/1000]\n",
      "- [TRAIN] LOSS : 7.882710012078557e-06 [SCORE] : 0.6\n",
      "[790/1000]\n",
      "- [VAL] LOSS : 1.1250775969529059e-05 [SCORE] : 1.0\n",
      "[791/1000]\n",
      "- [TRAIN] LOSS : 7.841754419738814e-06 [SCORE] : 0.6\n",
      "[791/1000]\n",
      "- [VAL] LOSS : 1.1196031664439943e-05 [SCORE] : 1.0\n",
      "[792/1000]\n",
      "- [TRAIN] LOSS : 7.798796771870304e-06 [SCORE] : 0.6\n",
      "[792/1000]\n",
      "- [VAL] LOSS : 1.1136432476632763e-05 [SCORE] : 1.0\n",
      "[793/1000]\n",
      "- [TRAIN] LOSS : 7.753175805191858e-06 [SCORE] : 0.6\n",
      "[793/1000]\n",
      "- [VAL] LOSS : 1.1077770068368409e-05 [SCORE] : 1.0\n",
      "[794/1000]\n",
      "- [TRAIN] LOSS : 7.713593034471462e-06 [SCORE] : 0.6\n",
      "[794/1000]\n",
      "- [VAL] LOSS : 1.1019591511285398e-05 [SCORE] : 1.0\n",
      "[795/1000]\n",
      "- [TRAIN] LOSS : 7.670635811033815e-06 [SCORE] : 0.6\n",
      "[795/1000]\n",
      "- [VAL] LOSS : 1.0961676707665902e-05 [SCORE] : 1.0\n",
      "[796/1000]\n",
      "- [TRAIN] LOSS : 7.631160345529982e-06 [SCORE] : 0.6\n",
      "[796/1000]\n",
      "- [VAL] LOSS : 1.0899728295044042e-05 [SCORE] : 1.0\n",
      "[797/1000]\n",
      "- [TRAIN] LOSS : 7.590300629090052e-06 [SCORE] : 0.6\n",
      "[797/1000]\n",
      "- [VAL] LOSS : 1.0837953595910221e-05 [SCORE] : 1.0\n",
      "[798/1000]\n",
      "- [TRAIN] LOSS : 7.5484012389400355e-06 [SCORE] : 0.6\n",
      "[798/1000]\n",
      "- [VAL] LOSS : 1.0784860933199525e-05 [SCORE] : 1.0\n",
      "[799/1000]\n",
      "- [TRAIN] LOSS : 7.50781067229885e-06 [SCORE] : 0.6\n",
      "[799/1000]\n",
      "- [VAL] LOSS : 1.0736161129898392e-05 [SCORE] : 1.0\n",
      "[800/1000]\n",
      "- [TRAIN] LOSS : 7.467325895049726e-06 [SCORE] : 0.6\n",
      "[800/1000]\n",
      "- [VAL] LOSS : 1.0683374966902193e-05 [SCORE] : 1.0\n",
      "[801/1000]\n",
      "- [TRAIN] LOSS : 7.4261612553527815e-06 [SCORE] : 0.6\n",
      "[801/1000]\n",
      "- [VAL] LOSS : 1.0613242011459079e-05 [SCORE] : 1.0\n",
      "[802/1000]\n",
      "- [TRAIN] LOSS : 7.3881593531647616e-06 [SCORE] : 0.6\n",
      "[802/1000]\n",
      "- [VAL] LOSS : 1.055532629834488e-05 [SCORE] : 1.0\n",
      "[803/1000]\n",
      "- [TRAIN] LOSS : 7.348727149292245e-06 [SCORE] : 0.6\n",
      "[803/1000]\n",
      "- [VAL] LOSS : 1.0506849321245681e-05 [SCORE] : 1.0\n",
      "[804/1000]\n",
      "- [TRAIN] LOSS : 7.3089709530904655e-06 [SCORE] : 0.6\n",
      "[804/1000]\n",
      "- [VAL] LOSS : 1.0446061423863284e-05 [SCORE] : 1.0\n",
      "[805/1000]\n",
      "- [TRAIN] LOSS : 7.26940346188106e-06 [SCORE] : 0.6\n",
      "[805/1000]\n",
      "- [VAL] LOSS : 1.0389793715148699e-05 [SCORE] : 1.0\n",
      "[806/1000]\n",
      "- [TRAIN] LOSS : 7.230527474651656e-06 [SCORE] : 0.6\n",
      "[806/1000]\n",
      "- [VAL] LOSS : 1.0346493581891991e-05 [SCORE] : 1.0\n",
      "[807/1000]\n",
      "- [TRAIN] LOSS : 7.1926181438660326e-06 [SCORE] : 0.6\n",
      "[807/1000]\n",
      "- [VAL] LOSS : 1.0286344149790239e-05 [SCORE] : 1.0\n",
      "[808/1000]\n",
      "- [TRAIN] LOSS : 7.153256365199922e-06 [SCORE] : 0.6\n",
      "[808/1000]\n",
      "- [VAL] LOSS : 1.0230583939119242e-05 [SCORE] : 1.0\n",
      "[809/1000]\n",
      "- [TRAIN] LOSS : 7.114798321102474e-06 [SCORE] : 0.6\n",
      "[809/1000]\n",
      "- [VAL] LOSS : 1.0183481208514422e-05 [SCORE] : 1.0\n",
      "[810/1000]\n",
      "- [TRAIN] LOSS : 7.076444580889074e-06 [SCORE] : 0.6\n",
      "[810/1000]\n",
      "- [VAL] LOSS : 1.0127571840712335e-05 [SCORE] : 1.0\n",
      "[811/1000]\n",
      "- [TRAIN] LOSS : 7.038127766160566e-06 [SCORE] : 0.6\n",
      "[811/1000]\n",
      "- [VAL] LOSS : 1.0075390491692815e-05 [SCORE] : 1.0\n",
      "[812/1000]\n",
      "- [TRAIN] LOSS : 6.999579712404132e-06 [SCORE] : 0.6\n",
      "[812/1000]\n",
      "- [VAL] LOSS : 1.002407316263998e-05 [SCORE] : 1.0\n",
      "[813/1000]\n",
      "- [TRAIN] LOSS : 6.960227650173086e-06 [SCORE] : 0.6\n",
      "[813/1000]\n",
      "- [VAL] LOSS : 9.973177839128766e-06 [SCORE] : 1.0\n",
      "[814/1000]\n",
      "- [TRAIN] LOSS : 6.925372933134592e-06 [SCORE] : 0.6\n",
      "[814/1000]\n",
      "- [VAL] LOSS : 9.918301657307893e-06 [SCORE] : 1.0\n",
      "[815/1000]\n",
      "- [TRAIN] LOSS : 6.888433366232978e-06 [SCORE] : 0.6\n",
      "[815/1000]\n",
      "- [VAL] LOSS : 9.863622835837305e-06 [SCORE] : 1.0\n",
      "[816/1000]\n",
      "- [TRAIN] LOSS : 6.851671772286257e-06 [SCORE] : 0.6\n",
      "[816/1000]\n",
      "- [VAL] LOSS : 9.813346878217999e-06 [SCORE] : 1.0\n",
      "[817/1000]\n",
      "- [TRAIN] LOSS : 6.816636656973666e-06 [SCORE] : 0.6\n",
      "[817/1000]\n",
      "- [VAL] LOSS : 9.75897546595661e-06 [SCORE] : 1.0\n",
      "[818/1000]\n",
      "- [TRAIN] LOSS : 6.780143818711319e-06 [SCORE] : 0.6\n",
      "[818/1000]\n",
      "- [VAL] LOSS : 9.717507964523975e-06 [SCORE] : 1.0\n",
      "[819/1000]\n",
      "- [TRAIN] LOSS : 6.742570743275186e-06 [SCORE] : 0.6\n",
      "[819/1000]\n",
      "- [VAL] LOSS : 9.663419405114837e-06 [SCORE] : 1.0\n",
      "[820/1000]\n",
      "- [TRAIN] LOSS : 6.7039097909097714e-06 [SCORE] : 0.6\n",
      "[820/1000]\n",
      "- [VAL] LOSS : 9.6090234364965e-06 [SCORE] : 1.0\n",
      "[821/1000]\n",
      "- [TRAIN] LOSS : 6.669253434665734e-06 [SCORE] : 0.6\n",
      "[821/1000]\n",
      "- [VAL] LOSS : 9.554098141961731e-06 [SCORE] : 1.0\n",
      "[822/1000]\n",
      "- [TRAIN] LOSS : 6.635559081284251e-06 [SCORE] : 0.6\n",
      "[822/1000]\n",
      "- [VAL] LOSS : 9.5085288194241e-06 [SCORE] : 1.0\n",
      "[823/1000]\n",
      "- [TRAIN] LOSS : 6.598262022331861e-06 [SCORE] : 0.6\n",
      "[823/1000]\n",
      "- [VAL] LOSS : 9.463388778385706e-06 [SCORE] : 1.0\n",
      "[824/1000]\n",
      "- [TRAIN] LOSS : 6.565463672814076e-06 [SCORE] : 0.6\n",
      "[824/1000]\n",
      "- [VAL] LOSS : 9.409991434949916e-06 [SCORE] : 1.0\n",
      "[825/1000]\n",
      "- [TRAIN] LOSS : 6.528970955817689e-06 [SCORE] : 0.6\n",
      "[825/1000]\n",
      "- [VAL] LOSS : 9.352511369797867e-06 [SCORE] : 1.0\n",
      "[826/1000]\n",
      "- [TRAIN] LOSS : 6.495036268461263e-06 [SCORE] : 0.6\n",
      "[826/1000]\n",
      "- [VAL] LOSS : 9.3079497673898e-06 [SCORE] : 1.0\n",
      "[827/1000]\n",
      "- [TRAIN] LOSS : 6.459239299753487e-06 [SCORE] : 0.6\n",
      "[827/1000]\n",
      "- [VAL] LOSS : 9.267794666811824e-06 [SCORE] : 1.0\n",
      "[828/1000]\n",
      "- [TRAIN] LOSS : 6.423950677951022e-06 [SCORE] : 0.6\n",
      "[828/1000]\n",
      "- [VAL] LOSS : 9.214979399985168e-06 [SCORE] : 1.0\n",
      "[829/1000]\n",
      "- [TRAIN] LOSS : 6.391902919252364e-06 [SCORE] : 0.6\n",
      "[829/1000]\n",
      "- [VAL] LOSS : 9.174661499855574e-06 [SCORE] : 1.0\n",
      "[830/1000]\n",
      "- [TRAIN] LOSS : 6.358374518337466e-06 [SCORE] : 0.6\n",
      "[830/1000]\n",
      "- [VAL] LOSS : 9.121086804952938e-06 [SCORE] : 1.0\n",
      "[831/1000]\n",
      "- [TRAIN] LOSS : 6.324292507997598e-06 [SCORE] : 0.6\n",
      "[831/1000]\n",
      "- [VAL] LOSS : 9.076819878828246e-06 [SCORE] : 1.0\n",
      "[832/1000]\n",
      "- [TRAIN] LOSS : 6.288905433393666e-06 [SCORE] : 0.6\n",
      "[832/1000]\n",
      "- [VAL] LOSS : 9.01592466107104e-06 [SCORE] : 1.0\n",
      "[833/1000]\n",
      "- [TRAIN] LOSS : 6.2563988649344536e-06 [SCORE] : 0.6\n",
      "[833/1000]\n",
      "- [VAL] LOSS : 8.976550816441886e-06 [SCORE] : 1.0\n",
      "[834/1000]\n",
      "- [TRAIN] LOSS : 6.224940337536585e-06 [SCORE] : 0.6\n",
      "[834/1000]\n",
      "- [VAL] LOSS : 8.92883417691337e-06 [SCORE] : 1.0\n",
      "[835/1000]\n",
      "- [TRAIN] LOSS : 6.190064459588029e-06 [SCORE] : 0.6\n",
      "[835/1000]\n",
      "- [VAL] LOSS : 8.881267604010645e-06 [SCORE] : 1.0\n",
      "[836/1000]\n",
      "- [TRAIN] LOSS : 6.154136159845317e-06 [SCORE] : 0.6\n",
      "[836/1000]\n",
      "- [VAL] LOSS : 8.833811079966836e-06 [SCORE] : 1.0\n",
      "[837/1000]\n",
      "- [TRAIN] LOSS : 6.120643668812894e-06 [SCORE] : 0.6\n",
      "[837/1000]\n",
      "- [VAL] LOSS : 8.794986570137553e-06 [SCORE] : 1.0\n",
      "[838/1000]\n",
      "- [TRAIN] LOSS : 6.09118845507813e-06 [SCORE] : 0.6\n",
      "[838/1000]\n",
      "- [VAL] LOSS : 8.75203204486752e-06 [SCORE] : 1.0\n",
      "[839/1000]\n",
      "- [TRAIN] LOSS : 6.057070125583171e-06 [SCORE] : 0.6\n",
      "[839/1000]\n",
      "- [VAL] LOSS : 8.696047189005185e-06 [SCORE] : 1.0\n",
      "[840/1000]\n",
      "- [TRAIN] LOSS : 6.027052252951156e-06 [SCORE] : 0.6\n",
      "[840/1000]\n",
      "- [VAL] LOSS : 8.652350516058505e-06 [SCORE] : 1.0\n",
      "[841/1000]\n",
      "- [TRAIN] LOSS : 5.995703971469387e-06 [SCORE] : 0.6\n",
      "[841/1000]\n",
      "- [VAL] LOSS : 8.609445103502367e-06 [SCORE] : 1.0\n",
      "[842/1000]\n",
      "- [TRAIN] LOSS : 5.961434089840622e-06 [SCORE] : 0.6\n",
      "[842/1000]\n",
      "- [VAL] LOSS : 8.566908036300447e-06 [SCORE] : 1.0\n",
      "[843/1000]\n",
      "- [TRAIN] LOSS : 5.929230079952201e-06 [SCORE] : 0.6\n",
      "[843/1000]\n",
      "- [VAL] LOSS : 8.516063644492533e-06 [SCORE] : 1.0\n",
      "[844/1000]\n",
      "- [TRAIN] LOSS : 5.90002541684953e-06 [SCORE] : 0.6\n",
      "[844/1000]\n",
      "- [VAL] LOSS : 8.473908565065358e-06 [SCORE] : 1.0\n",
      "[845/1000]\n",
      "- [TRAIN] LOSS : 5.863441090999307e-06 [SCORE] : 0.6\n",
      "[845/1000]\n",
      "- [VAL] LOSS : 8.436131793132517e-06 [SCORE] : 1.0\n",
      "[846/1000]\n",
      "- [TRAIN] LOSS : 5.834894818690373e-06 [SCORE] : 0.6\n",
      "[846/1000]\n",
      "- [VAL] LOSS : 8.38995856611291e-06 [SCORE] : 1.0\n",
      "[847/1000]\n",
      "- [TRAIN] LOSS : 5.805619412058149e-06 [SCORE] : 0.6\n",
      "[847/1000]\n",
      "- [VAL] LOSS : 8.335392521985341e-06 [SCORE] : 1.0\n",
      "[848/1000]\n",
      "- [TRAIN] LOSS : 5.773268200452245e-06 [SCORE] : 0.6\n",
      "[848/1000]\n",
      "- [VAL] LOSS : 8.293724022223614e-06 [SCORE] : 1.0\n",
      "[849/1000]\n",
      "- [TRAIN] LOSS : 5.743394801053606e-06 [SCORE] : 0.6\n",
      "[849/1000]\n",
      "- [VAL] LOSS : 8.251808139903005e-06 [SCORE] : 1.0\n",
      "[850/1000]\n",
      "- [TRAIN] LOSS : 5.713693144571152e-06 [SCORE] : 0.6\n",
      "[850/1000]\n",
      "- [VAL] LOSS : 8.21369576442521e-06 [SCORE] : 1.0\n",
      "[851/1000]\n",
      "- [TRAIN] LOSS : 5.684280078336694e-06 [SCORE] : 0.6\n",
      "[851/1000]\n",
      "- [VAL] LOSS : 8.167806299752556e-06 [SCORE] : 1.0\n",
      "[852/1000]\n",
      "- [TRAIN] LOSS : 5.6534649502282265e-06 [SCORE] : 0.6\n",
      "[852/1000]\n",
      "- [VAL] LOSS : 8.135050848068204e-06 [SCORE] : 1.0\n",
      "[853/1000]\n",
      "- [TRAIN] LOSS : 5.62191285098379e-06 [SCORE] : 0.6\n",
      "[853/1000]\n",
      "- [VAL] LOSS : 8.089727089100052e-06 [SCORE] : 1.0\n",
      "[854/1000]\n",
      "- [TRAIN] LOSS : 5.592571718201119e-06 [SCORE] : 0.6\n",
      "[854/1000]\n",
      "- [VAL] LOSS : 8.053061719692778e-06 [SCORE] : 1.0\n",
      "[855/1000]\n",
      "- [TRAIN] LOSS : 5.561770543257202e-06 [SCORE] : 0.6\n",
      "[855/1000]\n",
      "- [VAL] LOSS : 7.995242413016967e-06 [SCORE] : 1.0\n",
      "[856/1000]\n",
      "- [TRAIN] LOSS : 5.532656859941198e-06 [SCORE] : 0.6\n",
      "[856/1000]\n",
      "- [VAL] LOSS : 7.958808964758646e-06 [SCORE] : 1.0\n",
      "[857/1000]\n",
      "- [TRAIN] LOSS : 5.502820113179041e-06 [SCORE] : 0.6\n",
      "[857/1000]\n",
      "- [VAL] LOSS : 7.922493750811554e-06 [SCORE] : 1.0\n",
      "[858/1000]\n",
      "- [TRAIN] LOSS : 5.477022098906067e-06 [SCORE] : 0.6\n",
      "[858/1000]\n",
      "- [VAL] LOSS : 7.881683814048301e-06 [SCORE] : 1.0\n",
      "[859/1000]\n",
      "- [TRAIN] LOSS : 5.448261291955229e-06 [SCORE] : 0.6\n",
      "[859/1000]\n",
      "- [VAL] LOSS : 7.844705578463618e-06 [SCORE] : 1.0\n",
      "[860/1000]\n",
      "- [TRAIN] LOSS : 5.418231861161379e-06 [SCORE] : 0.6\n",
      "[860/1000]\n",
      "- [VAL] LOSS : 7.795651981723495e-06 [SCORE] : 1.0\n",
      "[861/1000]\n",
      "- [TRAIN] LOSS : 5.389930311139324e-06 [SCORE] : 0.6\n",
      "[861/1000]\n",
      "- [VAL] LOSS : 7.759716027067043e-06 [SCORE] : 1.0\n",
      "[862/1000]\n",
      "- [TRAIN] LOSS : 5.362070328374102e-06 [SCORE] : 0.6\n",
      "[862/1000]\n",
      "- [VAL] LOSS : 7.723997441644315e-06 [SCORE] : 1.0\n",
      "[863/1000]\n",
      "- [TRAIN] LOSS : 5.330859812602284e-06 [SCORE] : 0.6\n",
      "[863/1000]\n",
      "- [VAL] LOSS : 7.675642336835153e-06 [SCORE] : 1.0\n",
      "[864/1000]\n",
      "- [TRAIN] LOSS : 5.30255072893245e-06 [SCORE] : 0.6\n",
      "[864/1000]\n",
      "- [VAL] LOSS : 7.631652806594502e-06 [SCORE] : 1.0\n",
      "[865/1000]\n",
      "- [TRAIN] LOSS : 5.2766959773483295e-06 [SCORE] : 0.6\n",
      "[865/1000]\n",
      "- [VAL] LOSS : 7.6005421760783065e-06 [SCORE] : 1.0\n",
      "[866/1000]\n",
      "- [TRAIN] LOSS : 5.246162269637959e-06 [SCORE] : 0.6\n",
      "[866/1000]\n",
      "- [VAL] LOSS : 7.561031907243887e-06 [SCORE] : 1.0\n",
      "[867/1000]\n",
      "- [TRAIN] LOSS : 5.220470908777012e-06 [SCORE] : 0.6\n",
      "[867/1000]\n",
      "- [VAL] LOSS : 7.521623501816066e-06 [SCORE] : 1.0\n",
      "[868/1000]\n",
      "- [TRAIN] LOSS : 5.191683885641396e-06 [SCORE] : 0.6\n",
      "[868/1000]\n",
      "- [VAL] LOSS : 7.481985903723398e-06 [SCORE] : 1.0\n",
      "[869/1000]\n",
      "- [TRAIN] LOSS : 5.166291483268045e-06 [SCORE] : 0.6\n",
      "[869/1000]\n",
      "- [VAL] LOSS : 7.437673048116267e-06 [SCORE] : 1.0\n",
      "[870/1000]\n",
      "- [TRAIN] LOSS : 5.137246398589923e-06 [SCORE] : 0.6\n",
      "[870/1000]\n",
      "- [VAL] LOSS : 7.4025433605129365e-06 [SCORE] : 1.0\n",
      "[871/1000]\n",
      "- [TRAIN] LOSS : 5.109889373973904e-06 [SCORE] : 0.6\n",
      "[871/1000]\n",
      "- [VAL] LOSS : 7.371987067017471e-06 [SCORE] : 1.0\n",
      "[872/1000]\n",
      "- [TRAIN] LOSS : 5.085316721912628e-06 [SCORE] : 0.6\n",
      "[872/1000]\n",
      "- [VAL] LOSS : 7.324606940528611e-06 [SCORE] : 1.0\n",
      "[873/1000]\n",
      "- [TRAIN] LOSS : 5.055801436052813e-06 [SCORE] : 0.6\n",
      "[873/1000]\n",
      "- [VAL] LOSS : 7.290137546078768e-06 [SCORE] : 1.0\n",
      "[874/1000]\n",
      "- [TRAIN] LOSS : 5.029191584071668e-06 [SCORE] : 0.6\n",
      "[874/1000]\n",
      "- [VAL] LOSS : 7.247187568282243e-06 [SCORE] : 1.0\n",
      "[875/1000]\n",
      "- [TRAIN] LOSS : 5.004795411878149e-06 [SCORE] : 0.6\n",
      "[875/1000]\n",
      "- [VAL] LOSS : 7.212838681880385e-06 [SCORE] : 1.0\n",
      "[876/1000]\n",
      "- [TRAIN] LOSS : 4.978803978398597e-06 [SCORE] : 0.6\n",
      "[876/1000]\n",
      "- [VAL] LOSS : 7.1828594627731945e-06 [SCORE] : 1.0\n",
      "[877/1000]\n",
      "- [TRAIN] LOSS : 4.949717125176297e-06 [SCORE] : 0.6\n",
      "[877/1000]\n",
      "- [VAL] LOSS : 7.144463779695798e-06 [SCORE] : 1.0\n",
      "[878/1000]\n",
      "- [TRAIN] LOSS : 4.924676598723939e-06 [SCORE] : 0.6\n",
      "[878/1000]\n",
      "- [VAL] LOSS : 7.110108526831027e-06 [SCORE] : 1.0\n",
      "[879/1000]\n",
      "- [TRAIN] LOSS : 4.899885038867069e-06 [SCORE] : 0.6\n",
      "[879/1000]\n",
      "- [VAL] LOSS : 7.071110303513706e-06 [SCORE] : 1.0\n",
      "[880/1000]\n",
      "- [TRAIN] LOSS : 4.872292750709069e-06 [SCORE] : 0.6\n",
      "[880/1000]\n",
      "- [VAL] LOSS : 7.037015620880993e-06 [SCORE] : 1.0\n",
      "[881/1000]\n",
      "- [TRAIN] LOSS : 4.847959947558896e-06 [SCORE] : 0.6\n",
      "[881/1000]\n",
      "- [VAL] LOSS : 6.99473321219557e-06 [SCORE] : 1.0\n",
      "[882/1000]\n",
      "- [TRAIN] LOSS : 4.821661915836254e-06 [SCORE] : 0.6\n",
      "[882/1000]\n",
      "- [VAL] LOSS : 6.956896413612412e-06 [SCORE] : 1.0\n",
      "[883/1000]\n",
      "- [TRAIN] LOSS : 4.795578486967619e-06 [SCORE] : 0.6\n",
      "[883/1000]\n",
      "- [VAL] LOSS : 6.927702088432852e-06 [SCORE] : 1.0\n",
      "[884/1000]\n",
      "- [TRAIN] LOSS : 4.772008310283127e-06 [SCORE] : 0.6\n",
      "[884/1000]\n",
      "- [VAL] LOSS : 6.8816034399787895e-06 [SCORE] : 1.0\n",
      "[885/1000]\n",
      "- [TRAIN] LOSS : 4.744981386769116e-06 [SCORE] : 0.6\n",
      "[885/1000]\n",
      "- [VAL] LOSS : 6.852651040389901e-06 [SCORE] : 1.0\n",
      "[886/1000]\n",
      "- [TRAIN] LOSS : 4.719246650590018e-06 [SCORE] : 0.6\n",
      "[886/1000]\n",
      "- [VAL] LOSS : 6.819522695877822e-06 [SCORE] : 1.0\n",
      "[887/1000]\n",
      "- [TRAIN] LOSS : 4.695147322308913e-06 [SCORE] : 0.6\n",
      "[887/1000]\n",
      "- [VAL] LOSS : 6.786184258089634e-06 [SCORE] : 1.0\n",
      "[888/1000]\n",
      "- [TRAIN] LOSS : 4.6713326052364815e-06 [SCORE] : 0.6\n",
      "[888/1000]\n",
      "- [VAL] LOSS : 6.756724815204507e-06 [SCORE] : 1.0\n",
      "[889/1000]\n",
      "- [TRAIN] LOSS : 4.645503956150302e-06 [SCORE] : 0.6\n",
      "[889/1000]\n",
      "- [VAL] LOSS : 6.7150986069464125e-06 [SCORE] : 1.0\n",
      "[890/1000]\n",
      "- [TRAIN] LOSS : 4.6228760841889505e-06 [SCORE] : 0.6\n",
      "[890/1000]\n",
      "- [VAL] LOSS : 6.69080736770411e-06 [SCORE] : 1.0\n",
      "[891/1000]\n",
      "- [TRAIN] LOSS : 4.598255751867934e-06 [SCORE] : 0.6\n",
      "[891/1000]\n",
      "- [VAL] LOSS : 6.645409030170413e-06 [SCORE] : 1.0\n",
      "[892/1000]\n",
      "- [TRAIN] LOSS : 4.5746356363451925e-06 [SCORE] : 0.6\n",
      "[892/1000]\n",
      "- [VAL] LOSS : 6.6129300648754e-06 [SCORE] : 1.0\n",
      "[893/1000]\n",
      "- [TRAIN] LOSS : 4.5519480257401785e-06 [SCORE] : 0.6\n",
      "[893/1000]\n",
      "- [VAL] LOSS : 6.580557055713143e-06 [SCORE] : 1.0\n",
      "[894/1000]\n",
      "- [TRAIN] LOSS : 4.527775786300481e-06 [SCORE] : 0.6\n",
      "[894/1000]\n",
      "- [VAL] LOSS : 6.552538252435625e-06 [SCORE] : 1.0\n",
      "[895/1000]\n",
      "- [TRAIN] LOSS : 4.502896649682952e-06 [SCORE] : 0.6\n",
      "[895/1000]\n",
      "- [VAL] LOSS : 6.516103894682601e-06 [SCORE] : 1.0\n",
      "[896/1000]\n",
      "- [TRAIN] LOSS : 4.479670307470466e-06 [SCORE] : 0.6\n",
      "[896/1000]\n",
      "- [VAL] LOSS : 6.487984592240537e-06 [SCORE] : 1.0\n",
      "[897/1000]\n",
      "- [TRAIN] LOSS : 4.452376560948323e-06 [SCORE] : 0.6\n",
      "[897/1000]\n",
      "- [VAL] LOSS : 6.450962246162817e-06 [SCORE] : 1.0\n",
      "[898/1000]\n",
      "- [TRAIN] LOSS : 4.429804107530799e-06 [SCORE] : 0.6\n",
      "[898/1000]\n",
      "- [VAL] LOSS : 6.418773409677669e-06 [SCORE] : 1.0\n",
      "[899/1000]\n",
      "- [TRAIN] LOSS : 4.407990081745083e-06 [SCORE] : 0.6\n",
      "[899/1000]\n",
      "- [VAL] LOSS : 6.386885161191458e-06 [SCORE] : 1.0\n",
      "[900/1000]\n",
      "- [TRAIN] LOSS : 4.383368695926037e-06 [SCORE] : 0.6\n",
      "[900/1000]\n",
      "- [VAL] LOSS : 6.350891908368794e-06 [SCORE] : 1.0\n",
      "[901/1000]\n",
      "- [TRAIN] LOSS : 4.361304604572069e-06 [SCORE] : 0.6\n",
      "[901/1000]\n",
      "- [VAL] LOSS : 6.315040081972256e-06 [SCORE] : 1.0\n",
      "[902/1000]\n",
      "- [TRAIN] LOSS : 4.338570715844981e-06 [SCORE] : 0.6\n",
      "[902/1000]\n",
      "- [VAL] LOSS : 6.279272383835632e-06 [SCORE] : 1.0\n",
      "[903/1000]\n",
      "- [TRAIN] LOSS : 4.315122805564897e-06 [SCORE] : 0.6\n",
      "[903/1000]\n",
      "- [VAL] LOSS : 6.247857527341694e-06 [SCORE] : 1.0\n",
      "[904/1000]\n",
      "- [TRAIN] LOSS : 4.291740166687911e-06 [SCORE] : 0.6\n",
      "[904/1000]\n",
      "- [VAL] LOSS : 6.216229394340189e-06 [SCORE] : 1.0\n",
      "[905/1000]\n",
      "- [TRAIN] LOSS : 4.271834571530538e-06 [SCORE] : 0.6\n",
      "[905/1000]\n",
      "- [VAL] LOSS : 6.188505267346045e-06 [SCORE] : 1.0\n",
      "[906/1000]\n",
      "- [TRAIN] LOSS : 4.248351676020926e-06 [SCORE] : 0.6\n",
      "[906/1000]\n",
      "- [VAL] LOSS : 6.144318376755109e-06 [SCORE] : 1.0\n",
      "[907/1000]\n",
      "- [TRAIN] LOSS : 4.227225781505695e-06 [SCORE] : 0.6\n",
      "[907/1000]\n",
      "- [VAL] LOSS : 6.117450539022684e-06 [SCORE] : 1.0\n",
      "[908/1000]\n",
      "- [TRAIN] LOSS : 4.2064507624672846e-06 [SCORE] : 0.6\n",
      "[908/1000]\n",
      "- [VAL] LOSS : 6.0864958868478425e-06 [SCORE] : 1.0\n",
      "[909/1000]\n",
      "- [TRAIN] LOSS : 4.18348054154194e-06 [SCORE] : 0.6\n",
      "[909/1000]\n",
      "- [VAL] LOSS : 6.059919996914687e-06 [SCORE] : 1.0\n",
      "[910/1000]\n",
      "- [TRAIN] LOSS : 4.162610563677542e-06 [SCORE] : 0.6\n",
      "[910/1000]\n",
      "- [VAL] LOSS : 6.029184532962972e-06 [SCORE] : 1.0\n",
      "[911/1000]\n",
      "- [TRAIN] LOSS : 4.138260775713813e-06 [SCORE] : 0.6\n",
      "[911/1000]\n",
      "- [VAL] LOSS : 6.007040155964205e-06 [SCORE] : 1.0\n",
      "[912/1000]\n",
      "- [TRAIN] LOSS : 4.11712698375292e-06 [SCORE] : 0.6\n",
      "[912/1000]\n",
      "- [VAL] LOSS : 5.971917289571138e-06 [SCORE] : 1.0\n",
      "[913/1000]\n",
      "- [TRAIN] LOSS : 4.0947094779160885e-06 [SCORE] : 0.6\n",
      "[913/1000]\n",
      "- [VAL] LOSS : 5.940690698480466e-06 [SCORE] : 1.0\n",
      "[914/1000]\n",
      "- [TRAIN] LOSS : 4.0726821832019295e-06 [SCORE] : 0.6\n",
      "[914/1000]\n",
      "- [VAL] LOSS : 5.905749276280403e-06 [SCORE] : 1.0\n",
      "[915/1000]\n",
      "- [TRAIN] LOSS : 4.0529471410385065e-06 [SCORE] : 0.6\n",
      "[915/1000]\n",
      "- [VAL] LOSS : 5.875337137695169e-06 [SCORE] : 1.0\n",
      "[916/1000]\n",
      "- [TRAIN] LOSS : 4.028777713453261e-06 [SCORE] : 0.6\n",
      "[916/1000]\n",
      "- [VAL] LOSS : 5.849331046192674e-06 [SCORE] : 1.0\n",
      "[917/1000]\n",
      "- [TRAIN] LOSS : 4.0103334337497165e-06 [SCORE] : 0.6\n",
      "[917/1000]\n",
      "- [VAL] LOSS : 5.819187208544463e-06 [SCORE] : 1.0\n",
      "[918/1000]\n",
      "- [TRAIN] LOSS : 3.990410383873192e-06 [SCORE] : 0.6\n",
      "[918/1000]\n",
      "- [VAL] LOSS : 5.793400760012446e-06 [SCORE] : 1.0\n",
      "[919/1000]\n",
      "- [TRAIN] LOSS : 3.968987425650994e-06 [SCORE] : 0.6\n",
      "[919/1000]\n",
      "- [VAL] LOSS : 5.7634429140307475e-06 [SCORE] : 1.0\n",
      "[920/1000]\n",
      "- [TRAIN] LOSS : 3.949225523077379e-06 [SCORE] : 0.6\n",
      "[920/1000]\n",
      "- [VAL] LOSS : 5.729039003199432e-06 [SCORE] : 1.0\n",
      "[921/1000]\n",
      "- [TRAIN] LOSS : 3.926632424130124e-06 [SCORE] : 0.6\n",
      "[921/1000]\n",
      "- [VAL] LOSS : 5.698538643628126e-06 [SCORE] : 1.0\n",
      "[922/1000]\n",
      "- [TRAIN] LOSS : 3.906817490436273e-06 [SCORE] : 0.6\n",
      "[922/1000]\n",
      "- [VAL] LOSS : 5.677083208865952e-06 [SCORE] : 1.0\n",
      "[923/1000]\n",
      "- [TRAIN] LOSS : 3.887686580128502e-06 [SCORE] : 0.6\n",
      "[923/1000]\n",
      "- [VAL] LOSS : 5.647377747663995e-06 [SCORE] : 1.0\n",
      "[924/1000]\n",
      "- [TRAIN] LOSS : 3.866503698191082e-06 [SCORE] : 0.6\n",
      "[924/1000]\n",
      "- [VAL] LOSS : 5.622070148092462e-06 [SCORE] : 1.0\n",
      "[925/1000]\n",
      "- [TRAIN] LOSS : 3.844285735491818e-06 [SCORE] : 0.6\n",
      "[925/1000]\n",
      "- [VAL] LOSS : 5.584090558841126e-06 [SCORE] : 1.0\n",
      "[926/1000]\n",
      "- [TRAIN] LOSS : 3.823333865208649e-06 [SCORE] : 0.6\n",
      "[926/1000]\n",
      "- [VAL] LOSS : 5.550443347601686e-06 [SCORE] : 1.0\n",
      "[927/1000]\n",
      "- [TRAIN] LOSS : 3.805603766219671e-06 [SCORE] : 0.6\n",
      "[927/1000]\n",
      "- [VAL] LOSS : 5.525381766346982e-06 [SCORE] : 1.0\n",
      "[928/1000]\n",
      "- [TRAIN] LOSS : 3.786337159302396e-06 [SCORE] : 0.6\n",
      "[928/1000]\n",
      "- [VAL] LOSS : 5.500144197867485e-06 [SCORE] : 1.0\n",
      "[929/1000]\n",
      "- [TRAIN] LOSS : 3.7658509199900436e-06 [SCORE] : 0.6\n",
      "[929/1000]\n",
      "- [VAL] LOSS : 5.470315954880789e-06 [SCORE] : 1.0\n",
      "[930/1000]\n",
      "- [TRAIN] LOSS : 3.7473800451455946e-06 [SCORE] : 0.6\n",
      "[930/1000]\n",
      "- [VAL] LOSS : 5.4495062613568734e-06 [SCORE] : 1.0\n",
      "[931/1000]\n",
      "- [TRAIN] LOSS : 3.727988117437538e-06 [SCORE] : 0.6\n",
      "[931/1000]\n",
      "- [VAL] LOSS : 5.420445631898474e-06 [SCORE] : 1.0\n",
      "[932/1000]\n",
      "- [TRAIN] LOSS : 3.706531894446622e-06 [SCORE] : 0.6\n",
      "[932/1000]\n",
      "- [VAL] LOSS : 5.387265446188394e-06 [SCORE] : 1.0\n",
      "[933/1000]\n",
      "- [TRAIN] LOSS : 3.6899805688032452e-06 [SCORE] : 0.6\n",
      "[933/1000]\n",
      "- [VAL] LOSS : 5.362699994293507e-06 [SCORE] : 1.0\n",
      "[934/1000]\n",
      "- [TRAIN] LOSS : 3.6695521581956806e-06 [SCORE] : 0.6\n",
      "[934/1000]\n",
      "- [VAL] LOSS : 5.3339686019171495e-06 [SCORE] : 1.0\n",
      "[935/1000]\n",
      "- [TRAIN] LOSS : 3.649200236092535e-06 [SCORE] : 0.6\n",
      "[935/1000]\n",
      "- [VAL] LOSS : 5.31381874679937e-06 [SCORE] : 1.0\n",
      "[936/1000]\n",
      "- [TRAIN] LOSS : 3.6328539560296727e-06 [SCORE] : 0.6\n",
      "[936/1000]\n",
      "- [VAL] LOSS : 5.284982762532309e-06 [SCORE] : 1.0\n",
      "[937/1000]\n",
      "- [TRAIN] LOSS : 3.613723174566985e-06 [SCORE] : 0.6\n",
      "[937/1000]\n",
      "- [VAL] LOSS : 5.260093985270942e-06 [SCORE] : 1.0\n",
      "[938/1000]\n",
      "- [TRAIN] LOSS : 3.5950412211605e-06 [SCORE] : 0.6\n",
      "[938/1000]\n",
      "- [VAL] LOSS : 5.231430350249866e-06 [SCORE] : 1.0\n",
      "[939/1000]\n",
      "- [TRAIN] LOSS : 3.5746180856222053e-06 [SCORE] : 0.6\n",
      "[939/1000]\n",
      "- [VAL] LOSS : 5.198746748646954e-06 [SCORE] : 1.0\n",
      "[940/1000]\n",
      "- [TRAIN] LOSS : 3.555272405719734e-06 [SCORE] : 0.6\n",
      "[940/1000]\n",
      "- [VAL] LOSS : 5.174702437216183e-06 [SCORE] : 1.0\n",
      "[941/1000]\n",
      "- [TRAIN] LOSS : 3.535644388345342e-06 [SCORE] : 0.6\n",
      "[941/1000]\n",
      "- [VAL] LOSS : 5.150755441718502e-06 [SCORE] : 1.0\n",
      "[942/1000]\n",
      "- [TRAIN] LOSS : 3.516487807549614e-06 [SCORE] : 0.6\n",
      "[942/1000]\n",
      "- [VAL] LOSS : 5.1268616516608745e-06 [SCORE] : 1.0\n",
      "[943/1000]\n",
      "- [TRAIN] LOSS : 3.498950278905492e-06 [SCORE] : 0.6\n",
      "[943/1000]\n",
      "- [VAL] LOSS : 5.103039711684687e-06 [SCORE] : 1.0\n",
      "[944/1000]\n",
      "- [TRAIN] LOSS : 3.4814619993994713e-06 [SCORE] : 0.6\n",
      "[944/1000]\n",
      "- [VAL] LOSS : 5.074799901194638e-06 [SCORE] : 1.0\n",
      "[945/1000]\n",
      "- [TRAIN] LOSS : 3.4635878288706106e-06 [SCORE] : 0.6\n",
      "[945/1000]\n",
      "- [VAL] LOSS : 5.0505122999311425e-06 [SCORE] : 1.0\n",
      "[946/1000]\n",
      "- [TRAIN] LOSS : 3.4445809963775295e-06 [SCORE] : 0.6\n",
      "[946/1000]\n",
      "- [VAL] LOSS : 5.022438472224167e-06 [SCORE] : 1.0\n",
      "[947/1000]\n",
      "- [TRAIN] LOSS : 3.426982758962064e-06 [SCORE] : 0.6\n",
      "[947/1000]\n",
      "- [VAL] LOSS : 4.994606570107862e-06 [SCORE] : 1.0\n",
      "[948/1000]\n",
      "- [TRAIN] LOSS : 3.4088798050409727e-06 [SCORE] : 0.6\n",
      "[948/1000]\n",
      "- [VAL] LOSS : 4.96264601679286e-06 [SCORE] : 1.0\n",
      "[949/1000]\n",
      "- [TRAIN] LOSS : 3.390912775103061e-06 [SCORE] : 0.6\n",
      "[949/1000]\n",
      "- [VAL] LOSS : 4.9392888286092784e-06 [SCORE] : 1.0\n",
      "[950/1000]\n",
      "- [TRAIN] LOSS : 3.3714227811287854e-06 [SCORE] : 0.6\n",
      "[950/1000]\n",
      "- [VAL] LOSS : 4.915990757581312e-06 [SCORE] : 1.0\n",
      "[951/1000]\n",
      "- [TRAIN] LOSS : 3.3543607059982606e-06 [SCORE] : 0.6\n",
      "[951/1000]\n",
      "- [VAL] LOSS : 4.892760898655979e-06 [SCORE] : 1.0\n",
      "[952/1000]\n",
      "- [TRAIN] LOSS : 3.3373305162361553e-06 [SCORE] : 0.6\n",
      "[952/1000]\n",
      "- [VAL] LOSS : 4.869602435064735e-06 [SCORE] : 1.0\n",
      "[953/1000]\n",
      "- [TRAIN] LOSS : 3.321146209600556e-06 [SCORE] : 0.6\n",
      "[953/1000]\n",
      "- [VAL] LOSS : 4.84201655126526e-06 [SCORE] : 1.0\n",
      "[954/1000]\n",
      "- [TRAIN] LOSS : 3.3045817114422485e-06 [SCORE] : 0.6\n",
      "[954/1000]\n",
      "- [VAL] LOSS : 4.809875008504605e-06 [SCORE] : 1.0\n",
      "[955/1000]\n",
      "- [TRAIN] LOSS : 3.28768824905031e-06 [SCORE] : 0.6\n",
      "[955/1000]\n",
      "- [VAL] LOSS : 4.786712906934554e-06 [SCORE] : 1.0\n",
      "[956/1000]\n",
      "- [TRAIN] LOSS : 3.2706159572626347e-06 [SCORE] : 0.6\n",
      "[956/1000]\n",
      "- [VAL] LOSS : 4.763765900861472e-06 [SCORE] : 1.0\n",
      "[957/1000]\n",
      "- [TRAIN] LOSS : 3.2546095326324575e-06 [SCORE] : 0.6\n",
      "[957/1000]\n",
      "- [VAL] LOSS : 4.736707069241675e-06 [SCORE] : 1.0\n",
      "[958/1000]\n",
      "- [TRAIN] LOSS : 3.2379588977467697e-06 [SCORE] : 0.6\n",
      "[958/1000]\n",
      "- [VAL] LOSS : 4.713995622296352e-06 [SCORE] : 1.0\n",
      "[959/1000]\n",
      "- [TRAIN] LOSS : 3.2214026380946354e-06 [SCORE] : 0.6\n",
      "[959/1000]\n",
      "- [VAL] LOSS : 4.695622465078486e-06 [SCORE] : 1.0\n",
      "[960/1000]\n",
      "- [TRAIN] LOSS : 3.2013315717449587e-06 [SCORE] : 0.6\n",
      "[960/1000]\n",
      "- [VAL] LOSS : 4.668793735618237e-06 [SCORE] : 1.0\n",
      "[961/1000]\n",
      "- [TRAIN] LOSS : 3.1840767708975665e-06 [SCORE] : 0.6\n",
      "[961/1000]\n",
      "- [VAL] LOSS : 4.646045908884844e-06 [SCORE] : 1.0\n",
      "[962/1000]\n",
      "- [TRAIN] LOSS : 3.1671993838244815e-06 [SCORE] : 0.6\n",
      "[962/1000]\n",
      "- [VAL] LOSS : 4.622991582436953e-06 [SCORE] : 1.0\n",
      "[963/1000]\n",
      "- [TRAIN] LOSS : 3.1523607314435747e-06 [SCORE] : 0.6\n",
      "[963/1000]\n",
      "- [VAL] LOSS : 4.600385636877036e-06 [SCORE] : 1.0\n",
      "[964/1000]\n",
      "- [TRAIN] LOSS : 3.1349208332661267e-06 [SCORE] : 0.6\n",
      "[964/1000]\n",
      "- [VAL] LOSS : 4.577988420351176e-06 [SCORE] : 1.0\n",
      "[965/1000]\n",
      "- [TRAIN] LOSS : 3.120124385228943e-06 [SCORE] : 0.6\n",
      "[965/1000]\n",
      "- [VAL] LOSS : 4.555717168841511e-06 [SCORE] : 1.0\n",
      "[966/1000]\n",
      "- [TRAIN] LOSS : 3.105460586994013e-06 [SCORE] : 0.6\n",
      "[966/1000]\n",
      "- [VAL] LOSS : 4.537793302006321e-06 [SCORE] : 1.0\n",
      "[967/1000]\n",
      "- [TRAIN] LOSS : 3.0893017841056766e-06 [SCORE] : 0.6\n",
      "[967/1000]\n",
      "- [VAL] LOSS : 4.515691216511186e-06 [SCORE] : 1.0\n",
      "[968/1000]\n",
      "- [TRAIN] LOSS : 3.070827335704962e-06 [SCORE] : 0.6\n",
      "[968/1000]\n",
      "- [VAL] LOSS : 4.489389539230615e-06 [SCORE] : 1.0\n",
      "[969/1000]\n",
      "- [TRAIN] LOSS : 3.0563592872567826e-06 [SCORE] : 0.6\n",
      "[969/1000]\n",
      "- [VAL] LOSS : 4.467191502044443e-06 [SCORE] : 1.0\n",
      "[970/1000]\n",
      "- [TRAIN] LOSS : 3.0423239195442874e-06 [SCORE] : 0.6\n",
      "[970/1000]\n",
      "- [VAL] LOSS : 4.440459633769933e-06 [SCORE] : 1.0\n",
      "[971/1000]\n",
      "- [TRAIN] LOSS : 3.0248138803775266e-06 [SCORE] : 0.6\n",
      "[971/1000]\n",
      "- [VAL] LOSS : 4.418408479978098e-06 [SCORE] : 1.0\n",
      "[972/1000]\n",
      "- [TRAIN] LOSS : 3.009436390281432e-06 [SCORE] : 0.6\n",
      "[972/1000]\n",
      "- [VAL] LOSS : 4.3923059820372146e-06 [SCORE] : 1.0\n",
      "[973/1000]\n",
      "- [TRAIN] LOSS : 2.9943020081191207e-06 [SCORE] : 0.6\n",
      "[973/1000]\n",
      "- [VAL] LOSS : 4.370584520074772e-06 [SCORE] : 1.0\n",
      "[974/1000]\n",
      "- [TRAIN] LOSS : 2.9785094814845553e-06 [SCORE] : 0.6\n",
      "[974/1000]\n",
      "- [VAL] LOSS : 4.348938546172576e-06 [SCORE] : 1.0\n",
      "[975/1000]\n",
      "- [TRAIN] LOSS : 2.961191084220142e-06 [SCORE] : 0.6\n",
      "[975/1000]\n",
      "- [VAL] LOSS : 4.323087978264084e-06 [SCORE] : 1.0\n",
      "[976/1000]\n",
      "- [TRAIN] LOSS : 2.944694968694724e-06 [SCORE] : 0.6\n",
      "[976/1000]\n",
      "- [VAL] LOSS : 4.305800302972784e-06 [SCORE] : 1.0\n",
      "[977/1000]\n",
      "- [TRAIN] LOSS : 2.930596228149322e-06 [SCORE] : 0.6\n",
      "[977/1000]\n",
      "- [VAL] LOSS : 4.2885685616056435e-06 [SCORE] : 1.0\n",
      "[978/1000]\n",
      "- [TRAIN] LOSS : 2.915737043925522e-06 [SCORE] : 0.6\n",
      "[978/1000]\n",
      "- [VAL] LOSS : 4.2669357753766235e-06 [SCORE] : 1.0\n",
      "[979/1000]\n",
      "- [TRAIN] LOSS : 2.902124560932862e-06 [SCORE] : 0.6\n",
      "[979/1000]\n",
      "- [VAL] LOSS : 4.245045602147002e-06 [SCORE] : 1.0\n",
      "[980/1000]\n",
      "- [TRAIN] LOSS : 2.8858502370591546e-06 [SCORE] : 0.6\n",
      "[980/1000]\n",
      "- [VAL] LOSS : 4.223553787596757e-06 [SCORE] : 1.0\n",
      "[981/1000]\n",
      "- [TRAIN] LOSS : 2.869702609586966e-06 [SCORE] : 0.6\n",
      "[981/1000]\n",
      "- [VAL] LOSS : 4.2022661546070594e-06 [SCORE] : 1.0\n",
      "[982/1000]\n",
      "- [TRAIN] LOSS : 2.8549836959731087e-06 [SCORE] : 0.6\n",
      "[982/1000]\n",
      "- [VAL] LOSS : 4.18107993027661e-06 [SCORE] : 1.0\n",
      "[983/1000]\n",
      "- [TRAIN] LOSS : 2.841166606989039e-06 [SCORE] : 0.6\n",
      "[983/1000]\n",
      "- [VAL] LOSS : 4.159973286732566e-06 [SCORE] : 1.0\n",
      "[984/1000]\n",
      "- [TRAIN] LOSS : 2.828216493829435e-06 [SCORE] : 0.6\n",
      "[984/1000]\n",
      "- [VAL] LOSS : 4.138931217312347e-06 [SCORE] : 1.0\n",
      "[985/1000]\n",
      "- [TRAIN] LOSS : 2.811349501522879e-06 [SCORE] : 0.6\n",
      "[985/1000]\n",
      "- [VAL] LOSS : 4.122208792978199e-06 [SCORE] : 1.0\n",
      "[986/1000]\n",
      "- [TRAIN] LOSS : 2.79770194235122e-06 [SCORE] : 0.6\n",
      "[986/1000]\n",
      "- [VAL] LOSS : 4.105331299797399e-06 [SCORE] : 1.0\n",
      "[987/1000]\n",
      "- [TRAIN] LOSS : 2.784510240871896e-06 [SCORE] : 0.6\n",
      "[987/1000]\n",
      "- [VAL] LOSS : 4.088199148100102e-06 [SCORE] : 1.0\n",
      "[988/1000]\n",
      "- [TRAIN] LOSS : 2.7694459049598664e-06 [SCORE] : 0.6\n",
      "[988/1000]\n",
      "- [VAL] LOSS : 4.06294338972657e-06 [SCORE] : 1.0\n",
      "[989/1000]\n",
      "- [TRAIN] LOSS : 2.7525111969832022e-06 [SCORE] : 0.6\n",
      "[989/1000]\n",
      "- [VAL] LOSS : 4.042130512971198e-06 [SCORE] : 1.0\n",
      "[990/1000]\n",
      "- [TRAIN] LOSS : 2.7389655997467343e-06 [SCORE] : 0.6\n",
      "[990/1000]\n",
      "- [VAL] LOSS : 4.017166702396935e-06 [SCORE] : 1.0\n",
      "[991/1000]\n",
      "- [TRAIN] LOSS : 2.727111670234687e-06 [SCORE] : 0.6\n",
      "[991/1000]\n",
      "- [VAL] LOSS : 3.992285655840533e-06 [SCORE] : 1.0\n",
      "[992/1000]\n",
      "- [TRAIN] LOSS : 2.7113754147952326e-06 [SCORE] : 0.6\n",
      "[992/1000]\n",
      "- [VAL] LOSS : 3.967474640376167e-06 [SCORE] : 1.0\n",
      "[993/1000]\n",
      "- [TRAIN] LOSS : 2.6980771205368606e-06 [SCORE] : 0.6\n",
      "[993/1000]\n",
      "- [VAL] LOSS : 3.951229246013099e-06 [SCORE] : 1.0\n",
      "[994/1000]\n",
      "- [TRAIN] LOSS : 2.6848059026936727e-06 [SCORE] : 0.6\n",
      "[994/1000]\n",
      "- [VAL] LOSS : 3.926526915165596e-06 [SCORE] : 1.0\n",
      "[995/1000]\n",
      "- [TRAIN] LOSS : 2.6699900521028516e-06 [SCORE] : 0.6\n",
      "[995/1000]\n",
      "- [VAL] LOSS : 3.9101983020373154e-06 [SCORE] : 1.0\n",
      "[996/1000]\n",
      "- [TRAIN] LOSS : 2.658029969400862e-06 [SCORE] : 0.6\n",
      "[996/1000]\n",
      "- [VAL] LOSS : 3.897881015291205e-06 [SCORE] : 1.0\n",
      "[997/1000]\n",
      "- [TRAIN] LOSS : 2.6442180796948377e-06 [SCORE] : 0.6\n",
      "[997/1000]\n",
      "- [VAL] LOSS : 3.877436938637402e-06 [SCORE] : 1.0\n",
      "[998/1000]\n",
      "- [TRAIN] LOSS : 2.631697763414801e-06 [SCORE] : 0.6\n",
      "[998/1000]\n",
      "- [VAL] LOSS : 3.852917416224955e-06 [SCORE] : 1.0\n",
      "[999/1000]\n",
      "- [TRAIN] LOSS : 2.6170200840169857e-06 [SCORE] : 0.6\n",
      "[999/1000]\n",
      "- [VAL] LOSS : 3.837013537122402e-06 [SCORE] : 1.0\n",
      "[1000/1000]\n",
      "- [TRAIN] LOSS : 2.603237165506774e-06 [SCORE] : 0.6\n",
      "[1000/1000]\n",
      "- [VAL] LOSS : 3.8211678656807635e-06 [SCORE] : 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습의 효과 확인 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTROY=[[],[]], [[],[]]\n",
    "\n",
    "for epoch in range(1,EPOCH+1):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "    # 배치크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0, 0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss=regLoss(pre_y, targetTS)\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능평가 계산\n",
    "        score=F1Score(task='binary')(pre_y, targetTS)\n",
    "        score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "        # 추론/평가\n",
    "        pre_val=model(val_featureTS)\n",
    "\n",
    "        # 손실\n",
    "        loss_val=regLoss(pre_val, val_targetTS)\n",
    "\n",
    "        # 성능평가\n",
    "        score_val=F1Score(task='binary')(pre_val, val_targetTS)\n",
    "    \n",
    "    # 에포크 당 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/BATCH_CNT)\n",
    "    SCORE_HISTROY[0].append(score_total/BATCH_CNT)\n",
    "\n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTROY[1].append(score_val)\n",
    "\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [TRAIN] LOSS : {LOSS_HISTORY[0][-1]} [SCORE] : {SCORE_HISTROY[0][-1]}')\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [VAL] LOSS : {LOSS_HISTORY[1][-1]} [SCORE] : {SCORE_HISTROY[1][-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습결과 체크 => 학습과 검증의 Loss 변화, 성능 변화 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
