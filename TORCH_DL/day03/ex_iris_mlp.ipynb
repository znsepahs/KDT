{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iris 데이터셋 활용 꽃잎 너비 예측 모델\n",
    "- 데이터셋 : iris.csv에서 2개 Feature 사용\n",
    "- 구현프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] 모듈 로딩 및 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch                                # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn                       # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F             # 손실, 거래 등 함수 관련 모듈\n",
    "import torch.optim as optimizer             # 최적화 기법 관련 모듈\n",
    "from torchmetrics.regression import R2Score # 성능지표 관련 모듈 - 추가 설치\n",
    "from torchinfo import summary               # 모델 정보 관련 모듈 - 추가 설치\n",
    "\n",
    "import pandas as pd                         # 데이터 파일 분석 관련 모듈\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE => cpu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 가중치 및 절편 값 고정 설정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 저장 및 실행 위치 설정\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'DEVICE => {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로딩 : CSV => DataFrame\n",
    "DATA_FILE=pd.read_csv('../data/iris.csv',usecols=[0,1,2,3])\n",
    "irisDF=pd.DataFrame(DATA_FILE)\n",
    "\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 준비\n",
    "- 학습방법 : 지도학습 > 회귀\n",
    "- 알고리즘 : 선형관계 >> 선형모델 nn.Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "# 입력층의 입력값/피쳐 => sepal.length, sepal.width, petal.length 3개\n",
    "# 출력층의 출력값/타겟 => petal.width 1개\n",
    "# 입력층 : 입력 피쳐3, 출력 입력층에 존재하는 퍼셉트론 개수 10, AF ReLU\n",
    "# 은닉층 : 입력 10, 출력 은닉층에 존재하는 퍼셉트론 개수 5, AF ReLU\n",
    "# 출력층 : 입력 5, 출력 타겟/라벨 개수 1 , AF None\n",
    "model=nn.Sequential(nn.Linear(3,50),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(50,30),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(30,1))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=50, out_features=30, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [200000, 1]               --\n",
       "├─Linear: 1-1                            [200000, 50]              200\n",
       "├─ReLU: 1-2                              [200000, 50]              --\n",
       "├─Linear: 1-3                            [200000, 30]              1,530\n",
       "├─ReLU: 1-4                              [200000, 30]              --\n",
       "├─Linear: 1-5                            [200000, 1]               31\n",
       "==========================================================================================\n",
       "Total params: 1,761\n",
       "Trainable params: 1,761\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 352.20\n",
       "==========================================================================================\n",
       "Input size (MB): 2.40\n",
       "Forward/backward pass size (MB): 129.60\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 132.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "print(model)\n",
    "summary(model, input_size=(200000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.weight] Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119],\n",
      "        [ 0.2710, -0.5435,  0.3462],\n",
      "        [-0.1188,  0.2937,  0.0803],\n",
      "        [-0.0707,  0.1601,  0.0285],\n",
      "        [ 0.2109, -0.2250, -0.0421],\n",
      "        [-0.0520,  0.0837, -0.0023],\n",
      "        [ 0.5047,  0.1797, -0.2150],\n",
      "        [-0.3487, -0.0968, -0.2490],\n",
      "        [-0.1850,  0.0276,  0.3442],\n",
      "        [ 0.3138, -0.5644,  0.3579],\n",
      "        [ 0.1613,  0.5476,  0.3811],\n",
      "        [-0.5260, -0.5489, -0.2785],\n",
      "        [ 0.5070, -0.0962,  0.2471],\n",
      "        [-0.2683,  0.5665, -0.2443],\n",
      "        [ 0.4330,  0.0068, -0.3042],\n",
      "        [ 0.2968, -0.3065,  0.1698],\n",
      "        [-0.1667, -0.0633, -0.5551],\n",
      "        [-0.2753,  0.3133, -0.1403],\n",
      "        [ 0.5751,  0.4628, -0.0270],\n",
      "        [-0.3854,  0.3516,  0.1792],\n",
      "        [-0.3732,  0.3750,  0.3505],\n",
      "        [ 0.5120, -0.3236, -0.0950],\n",
      "        [-0.0112,  0.0843, -0.4382],\n",
      "        [-0.4097,  0.3141, -0.1354],\n",
      "        [ 0.2820,  0.0329,  0.1896],\n",
      "        [ 0.1270,  0.2099,  0.2862],\n",
      "        [-0.5347,  0.2906, -0.4059],\n",
      "        [-0.4356,  0.0351, -0.0984],\n",
      "        [ 0.3391, -0.3344, -0.5133],\n",
      "        [ 0.4202, -0.0856,  0.3247],\n",
      "        [ 0.1856, -0.4329,  0.1160],\n",
      "        [ 0.1387, -0.3866, -0.2739],\n",
      "        [ 0.1969,  0.1034, -0.2456],\n",
      "        [-0.1748,  0.5288, -0.1068],\n",
      "        [ 0.3255,  0.2500, -0.3732],\n",
      "        [-0.4910,  0.5542,  0.0301],\n",
      "        [ 0.3957,  0.1196,  0.1857],\n",
      "        [ 0.4313,  0.5475, -0.3831],\n",
      "        [ 0.0722,  0.4309,  0.4183],\n",
      "        [ 0.3587, -0.4178, -0.4158],\n",
      "        [-0.3492,  0.0725,  0.5754],\n",
      "        [-0.3647,  0.3077, -0.3196],\n",
      "        [-0.5428, -0.1227,  0.3327],\n",
      "        [ 0.5360, -0.3586,  0.1253],\n",
      "        [ 0.4982,  0.3826,  0.3598],\n",
      "        [ 0.4103,  0.3652,  0.1491],\n",
      "        [-0.3948, -0.4848, -0.2646],\n",
      "        [-0.0672, -0.3539,  0.2112],\n",
      "        [ 0.1787, -0.1307,  0.2219],\n",
      "        [ 0.1866,  0.3525,  0.3888]], requires_grad=True)\n",
      "\n",
      "[0.bias] Parameter containing:\n",
      "tensor([-0.1955,  0.5641, -0.0667, -0.0198, -0.5449, -0.3716, -0.3373, -0.2469,\n",
      "         0.4105, -0.1887, -0.4314,  0.2221,  0.1848,  0.3739, -0.2988,  0.1252,\n",
      "        -0.2102, -0.1297, -0.4601, -0.2631, -0.1768,  0.2469,  0.1055,  0.1426,\n",
      "         0.5763,  0.5627,  0.3938,  0.0184, -0.3994,  0.4512, -0.1444, -0.0467,\n",
      "        -0.4974, -0.1140, -0.3724,  0.5305, -0.4991, -0.4500, -0.0196, -0.3122,\n",
      "         0.2066, -0.2222, -0.2712,  0.0327,  0.4179, -0.4061,  0.2711,  0.3709,\n",
      "         0.5648, -0.4041], requires_grad=True)\n",
      "\n",
      "[2.weight] Parameter containing:\n",
      "tensor([[ 0.0343, -0.1046,  0.1207,  ..., -0.1000, -0.0941,  0.1165],\n",
      "        [ 0.1247, -0.0480,  0.0063,  ...,  0.0019, -0.0808, -0.0789],\n",
      "        [-0.0211, -0.0407,  0.0347,  ..., -0.0707, -0.1293, -0.0830],\n",
      "        ...,\n",
      "        [-0.1337,  0.0817, -0.0323,  ...,  0.0144,  0.1333, -0.0939],\n",
      "        [-0.0207,  0.0017, -0.0842,  ...,  0.0175,  0.0594,  0.0292],\n",
      "        [-0.0814,  0.0773,  0.1298,  ..., -0.0934, -0.1362,  0.0787]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[2.bias] Parameter containing:\n",
      "tensor([-0.1214, -0.0171,  0.1214, -0.0521, -0.0935,  0.0378,  0.1234, -0.0156,\n",
      "        -0.0083,  0.0661,  0.0177,  0.0271,  0.0748,  0.0643, -0.1013, -0.0558,\n",
      "         0.0966,  0.0218,  0.0329,  0.1358,  0.0875,  0.0564,  0.1353, -0.1244,\n",
      "         0.0219,  0.0369, -0.0246, -0.0664,  0.0261, -0.1169],\n",
      "       requires_grad=True)\n",
      "\n",
      "[4.weight] Parameter containing:\n",
      "tensor([[-0.0778,  0.1387, -0.0671, -0.0526,  0.0819, -0.0462,  0.0268, -0.1825,\n",
      "          0.1040, -0.1624,  0.0243, -0.1811, -0.1567,  0.1469, -0.1005, -0.0063,\n",
      "          0.0081,  0.1680,  0.0583,  0.0891, -0.0781, -0.0626,  0.1328,  0.0669,\n",
      "          0.0458, -0.1377, -0.1457,  0.0369, -0.1370,  0.1280]],\n",
      "       requires_grad=True)\n",
      "\n",
      "[4.bias] Parameter containing:\n",
      "tensor([0.1521], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 절편 확인\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'[{name}] {param}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 최적화 인스턴스 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 가중치와 절편을 최적화 => 인스턴스에 전달\n",
    "adam_optim=optimizer.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 => 개발자가 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [4-1] 데이터셋 Tensor화 진행 : 데이터준비 시 진행하거나 학습 전 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length'], dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3) (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐와 타겟 분리\n",
    "featureDF=irisDF[irisDF.columns[:-1]]\n",
    "targetDF=irisDF[['petal.width']]\n",
    "print(featureDF.shape, targetDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN (96, 3), TEST (30, 3), VAL (24, 3)\n",
      "TRAIN (96, 1), TEST (30, 1), VAL (24, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test=train_test_split(featureDF, targetDF, test_size=0.2, random_state=5)\n",
    "\n",
    "# Train & Valid\n",
    "X_train, X_val, y_train, y_val=train_test_split(X_train, y_train, test_size=0.2, random_state=5)\n",
    "\n",
    "print(f'TRAIN {X_train.shape}, TEST {X_test.shape}, VAL {X_val.shape}')\n",
    "print(f'TRAIN {y_train.shape}, TEST {y_test.shape}, VAL {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [4-2] 학습진행\n",
    "    * 학습횟수 결정 => 에포크 설정\n",
    "    * 배치크기 결정\n",
    "    * 배치개수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 100, DP_SIZE: 12, DP_CNT: 8\n"
     ]
    }
   ],
   "source": [
    "EPOCH=100                                                       # 처음~끝까지 공부하는 횟수\n",
    "DP_SIZE=12                                                    # 1에포크에서 한 번 학습 할 분량 크기\n",
    "DP_CNT=X_train.shape[0]//DP_SIZE                              # 1에포크에서 총 학습 횟수이자 업데이트 횟수\n",
    "\n",
    "print(f'EPOCH: {EPOCH}, DP_SIZE: {DP_SIZE}, DP_CNT: {DP_CNT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트/검증 함수\n",
    "# => 가중치, 절편 업데이트 X, 최적화 미진행\n",
    "# => 현재 가중치와 절편값으로 테스트 진행\n",
    "# 모델 학습 함수\n",
    "def testing(testDF, targetDF, kind='Val'):\n",
    "    # Tensor화\n",
    "    testTS=torch.FloatTensor(testDF.values).to(DEVICE)\n",
    "    targetTS=torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad(): # 가중치 및 절편 업데이트 진행 X\n",
    "        # (1) 학습진행 : forward\n",
    "        pre_y=model(testTS)\n",
    "\n",
    "        # (2) 오차계산 : 손실함수\n",
    "        loss=F.mse_loss(pre_y, targetTS)\n",
    "        \n",
    "        # (3) 성능평가 - R2\n",
    "        r2=R2Score()(pre_y, targetTS)\n",
    "\n",
    "        # (4) 학습결과 출력 및 저장\n",
    "        print(f'[{kind}] LOSS : {loss}, R2 : {r2}')\n",
    "    \n",
    "    return loss, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def training(featureTS, targetTS, valTS, valTargetTS):\n",
    "    # [[],[]] <= [train, val]\n",
    "    loss_history=[[],[]]\n",
    "    r2_history=[[],[]]\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        # 배치 손실 저장 변수\n",
    "        ds_loss, ds_r2=0, 0\n",
    "\n",
    "        # 배치크기 만큼 학습 진행\n",
    "        for i in range(DP_CNT):\n",
    "            start=i*DP_SIZE\n",
    "            end=start + DP_SIZE\n",
    "            print(start, end)\n",
    "            # DP_SIZE 크기만큼만 데이터 추출해서 Tensor화 진행\n",
    "            DSX_train=torch.FloatTensor(X_train[start:end].values).to(DEVICE)\n",
    "            DSy_train=torch.FloatTensor(y_train[start:end].values).to(DEVICE)\n",
    "\n",
    "            # print(DSX_train.shape, DSX_train.device, DSX_train.dtype)\n",
    "            # print(DSy_train.shape, DSy_train.device, DSy_train.dtype)\n",
    "\n",
    "            # (1) 학습진행 : forward\n",
    "            pre_y=model(DSX_train)\n",
    "            # print(f'pre_y.shape : {pre_y.shape}')\n",
    "\n",
    "            # (2) 오차계산 : 손실함수\n",
    "            loss=F.mse_loss(pre_y, DSy_train)\n",
    "            ds_loss += loss.item()\n",
    "            ds_r2 += R2Score()(pre_y, DSy_train).item()\n",
    "\n",
    "            # (3) 최적화 : 가중치, 절편 업데이트 backward\n",
    "            adam_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            adam_optim.step()\n",
    "            \n",
    "        # (4) 검증 : 모델이 제대로 만들어 지는지 검사용\n",
    "        val_loss, val_r2=testing(valTS, valTargetTS)\n",
    "        loss_history[1].append(val_loss.item())\n",
    "        r2_history[1].append(val_r2.item())\n",
    "\n",
    "        # 에포크 단위 손실과 성능지표\n",
    "        loss_history[0].append(ds_loss/DP_CNT)\n",
    "        r2_history[0].append(ds_r2/DP_CNT)\n",
    "\n",
    "        # (5) 학습결과 출력 및 저장\n",
    "        print(f'[{epoch}/{EPOCH}]\\n-TRAIN LOSS : {loss_history[0][-1]} R2 : {r2_history[0][-1]}')\n",
    "        print(f'-VALID LOSS : {loss_history[1][-1]} R2 : {r2_history[1][-1]}')\n",
    "        \n",
    "    return loss_history, r2_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 1.5711978673934937, R2 : -2.764756202697754\n",
      "[0/100]\n",
      "-TRAIN LOSS : 14.527392819523811 R2 : -21.821533054113388\n",
      "-VALID LOSS : 1.5711978673934937 R2 : -2.764756202697754\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.7309722900390625, R2 : -0.7514868974685669\n",
      "[1/100]\n",
      "-TRAIN LOSS : 1.224500272423029 R2 : -1.064141646027565\n",
      "-VALID LOSS : 0.7309722900390625 R2 : -0.7514868974685669\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.08642277121543884, R2 : 0.7929219007492065\n",
      "[2/100]\n",
      "-TRAIN LOSS : 0.43255666084587574 R2 : 0.29043734073638916\n",
      "-VALID LOSS : 0.08642277121543884 R2 : 0.7929219007492065\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.05174844339489937, R2 : 0.876005232334137\n",
      "[3/100]\n",
      "-TRAIN LOSS : 0.11140783922746778 R2 : 0.811126321554184\n",
      "-VALID LOSS : 0.05174844339489937 R2 : 0.876005232334137\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.08655818551778793, R2 : 0.7925974130630493\n",
      "[4/100]\n",
      "-TRAIN LOSS : 0.07829784927889705 R2 : 0.8641990199685097\n",
      "-VALID LOSS : 0.08655818551778793 R2 : 0.7925974130630493\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.05359596386551857, R2 : 0.8715783953666687\n",
      "[5/100]\n",
      "-TRAIN LOSS : 0.08569355821236968 R2 : 0.8519433289766312\n",
      "-VALID LOSS : 0.05359596386551857 R2 : 0.8715783953666687\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04737718403339386, R2 : 0.8864792585372925\n",
      "[6/100]\n",
      "-TRAIN LOSS : 0.0710749626159668 R2 : 0.8779571652412415\n",
      "-VALID LOSS : 0.04737718403339386 R2 : 0.8864792585372925\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04988197609782219, R2 : 0.8804775476455688\n",
      "[7/100]\n",
      "-TRAIN LOSS : 0.061940026469528675 R2 : 0.8932779654860497\n",
      "-VALID LOSS : 0.04988197609782219 R2 : 0.8804775476455688\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03749232366681099, R2 : 0.9101644158363342\n",
      "[8/100]\n",
      "-TRAIN LOSS : 0.06444828398525715 R2 : 0.8893158957362175\n",
      "-VALID LOSS : 0.03749232366681099 R2 : 0.9101644158363342\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03742382302880287, R2 : 0.9103285670280457\n",
      "[9/100]\n",
      "-TRAIN LOSS : 0.060143192764371634 R2 : 0.8966885730624199\n",
      "-VALID LOSS : 0.03742382302880287 R2 : 0.9103285670280457\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.040123116225004196, R2 : 0.9038608074188232\n",
      "[10/100]\n",
      "-TRAIN LOSS : 0.058016669703647494 R2 : 0.9005089774727821\n",
      "-VALID LOSS : 0.040123116225004196 R2 : 0.9038608074188232\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03665751963853836, R2 : 0.9121646881103516\n",
      "[11/100]\n",
      "-TRAIN LOSS : 0.05866894708015025 R2 : 0.8995158821344376\n",
      "-VALID LOSS : 0.03665751963853836 R2 : 0.9121646881103516\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03789972513914108, R2 : 0.9091882705688477\n",
      "[12/100]\n",
      "-TRAIN LOSS : 0.055701436242088675 R2 : 0.904789499938488\n",
      "-VALID LOSS : 0.03789972513914108 R2 : 0.9091882705688477\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03518711403012276, R2 : 0.9156879186630249\n",
      "[13/100]\n",
      "-TRAIN LOSS : 0.0559170818887651 R2 : 0.9045530334115028\n",
      "-VALID LOSS : 0.03518711403012276 R2 : 0.9156879186630249\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03601492568850517, R2 : 0.9137044548988342\n",
      "[14/100]\n",
      "-TRAIN LOSS : 0.053857737919315696 R2 : 0.9082253202795982\n",
      "-VALID LOSS : 0.03601492568850517 R2 : 0.9137044548988342\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.0346422903239727, R2 : 0.9169933795928955\n",
      "[15/100]\n",
      "-TRAIN LOSS : 0.053534789476543665 R2 : 0.9088576883077621\n",
      "-VALID LOSS : 0.0346422903239727 R2 : 0.9169933795928955\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03505479171872139, R2 : 0.91600501537323\n",
      "[16/100]\n",
      "-TRAIN LOSS : 0.05202544969506562 R2 : 0.9115753099322319\n",
      "-VALID LOSS : 0.03505479171872139 R2 : 0.91600501537323\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03366437554359436, R2 : 0.9193366169929504\n",
      "[17/100]\n",
      "-TRAIN LOSS : 0.051606097957119346 R2 : 0.91234090924263\n",
      "-VALID LOSS : 0.03366437554359436 R2 : 0.9193366169929504\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03401302918791771, R2 : 0.9185011982917786\n",
      "[18/100]\n",
      "-TRAIN LOSS : 0.050188732566311955 R2 : 0.91490288823843\n",
      "-VALID LOSS : 0.03401302918791771 R2 : 0.9185011982917786\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.0325244702398777, R2 : 0.9220679402351379\n",
      "[19/100]\n",
      "-TRAIN LOSS : 0.04992912570014596 R2 : 0.9153513610363007\n",
      "-VALID LOSS : 0.0325244702398777 R2 : 0.9220679402351379\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03359660878777504, R2 : 0.9194989800453186\n",
      "[20/100]\n",
      "-TRAIN LOSS : 0.04842400294728577 R2 : 0.9181183278560638\n",
      "-VALID LOSS : 0.03359660878777504 R2 : 0.9194989800453186\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03158210217952728, R2 : 0.9243259429931641\n",
      "[21/100]\n",
      "-TRAIN LOSS : 0.04866127506829798 R2 : 0.9175908416509628\n",
      "-VALID LOSS : 0.03158210217952728 R2 : 0.9243259429931641\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03462370112538338, R2 : 0.9170379638671875\n",
      "[22/100]\n",
      "-TRAIN LOSS : 0.04662062251009047 R2 : 0.9213628247380257\n",
      "-VALID LOSS : 0.03462370112538338 R2 : 0.9170379638671875\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03130276873707771, R2 : 0.9249952435493469\n",
      "[23/100]\n",
      "-TRAIN LOSS : 0.047931619454175234 R2 : 0.9188296869397163\n",
      "-VALID LOSS : 0.03130276873707771 R2 : 0.9249952435493469\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.035112906247377396, R2 : 0.9158657789230347\n",
      "[24/100]\n",
      "-TRAIN LOSS : 0.04498243238776922 R2 : 0.9244111999869347\n",
      "-VALID LOSS : 0.035112906247377396 R2 : 0.9158657789230347\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03029320389032364, R2 : 0.9274142980575562\n",
      "[25/100]\n",
      "-TRAIN LOSS : 0.04742701700888574 R2 : 0.9196141511201859\n",
      "-VALID LOSS : 0.03029320389032364 R2 : 0.9274142980575562\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03629405423998833, R2 : 0.9130356311798096\n",
      "[26/100]\n",
      "-TRAIN LOSS : 0.04359684209339321 R2 : 0.9270089492201805\n",
      "-VALID LOSS : 0.03629405423998833 R2 : 0.9130356311798096\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.028057647868990898, R2 : 0.9327709078788757\n",
      "[27/100]\n",
      "-TRAIN LOSS : 0.04879406071268022 R2 : 0.9167487323284149\n",
      "-VALID LOSS : 0.028057647868990898 R2 : 0.9327709078788757\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.040331657975912094, R2 : 0.9033610820770264\n",
      "[28/100]\n",
      "-TRAIN LOSS : 0.04321528226137161 R2 : 0.9278622418642044\n",
      "-VALID LOSS : 0.040331657975912094 R2 : 0.9033610820770264\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.025305652990937233, R2 : 0.9393649697303772\n",
      "[29/100]\n",
      "-TRAIN LOSS : 0.053638676879927516 R2 : 0.9073491841554642\n",
      "-VALID LOSS : 0.025305652990937233 R2 : 0.9393649697303772\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.052162349224090576, R2 : 0.8750134706497192\n",
      "[30/100]\n",
      "-TRAIN LOSS : 0.04545819014310837 R2 : 0.9242979884147644\n",
      "-VALID LOSS : 0.052162349224090576 R2 : 0.8750134706497192\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.02175232768058777, R2 : 0.9478791356086731\n",
      "[31/100]\n",
      "-TRAIN LOSS : 0.06278054509311914 R2 : 0.8903990909457207\n",
      "-VALID LOSS : 0.02175232768058777 R2 : 0.9478791356086731\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.07711255550384521, R2 : 0.815230131149292\n",
      "[32/100]\n",
      "-TRAIN LOSS : 0.048947349889203906 R2 : 0.919372521340847\n",
      "-VALID LOSS : 0.07711255550384521 R2 : 0.815230131149292\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.02191934548318386, R2 : 0.9474789500236511\n",
      "[33/100]\n",
      "-TRAIN LOSS : 0.06401276192627847 R2 : 0.8894953429698944\n",
      "-VALID LOSS : 0.02191934548318386 R2 : 0.9474789500236511\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.06311117857694626, R2 : 0.8487789630889893\n",
      "[34/100]\n",
      "-TRAIN LOSS : 0.041418920271098614 R2 : 0.9318934828042984\n",
      "-VALID LOSS : 0.06311117857694626 R2 : 0.8487789630889893\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.024273142218589783, R2 : 0.9418389797210693\n",
      "[35/100]\n",
      "-TRAIN LOSS : 0.0493205226957798 R2 : 0.9157845675945282\n",
      "-VALID LOSS : 0.024273142218589783 R2 : 0.9418389797210693\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04084775969386101, R2 : 0.9021244645118713\n",
      "[36/100]\n",
      "-TRAIN LOSS : 0.037440433632582426 R2 : 0.937176302075386\n",
      "-VALID LOSS : 0.04084775969386101 R2 : 0.9021244645118713\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03250855207443237, R2 : 0.9221060872077942\n",
      "[37/100]\n",
      "-TRAIN LOSS : 0.040476036723703146 R2 : 0.9313008487224579\n",
      "-VALID LOSS : 0.03250855207443237 R2 : 0.9221060872077942\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03508618846535683, R2 : 0.9159297943115234\n",
      "[38/100]\n",
      "-TRAIN LOSS : 0.03860008087940514 R2 : 0.9344280436635017\n",
      "-VALID LOSS : 0.03508618846535683 R2 : 0.9159297943115234\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.037529025226831436, R2 : 0.9100764989852905\n",
      "[39/100]\n",
      "-TRAIN LOSS : 0.03842917876318097 R2 : 0.934935562312603\n",
      "-VALID LOSS : 0.037529025226831436 R2 : 0.9100764989852905\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03542986139655113, R2 : 0.9151062965393066\n",
      "[40/100]\n",
      "-TRAIN LOSS : 0.038324740482494235 R2 : 0.9345792084932327\n",
      "-VALID LOSS : 0.03542986139655113 R2 : 0.9151062965393066\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.037380147725343704, R2 : 0.9104332327842712\n",
      "[41/100]\n",
      "-TRAIN LOSS : 0.03939657169394195 R2 : 0.9328315556049347\n",
      "-VALID LOSS : 0.037380147725343704 R2 : 0.9104332327842712\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03920803591609001, R2 : 0.9060534238815308\n",
      "[42/100]\n",
      "-TRAIN LOSS : 0.03910797997377813 R2 : 0.9331065788865089\n",
      "-VALID LOSS : 0.03920803591609001 R2 : 0.9060534238815308\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.0414804108440876, R2 : 0.9006085395812988\n",
      "[43/100]\n",
      "-TRAIN LOSS : 0.038168568164110184 R2 : 0.9350436106324196\n",
      "-VALID LOSS : 0.0414804108440876 R2 : 0.9006085395812988\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03895680606365204, R2 : 0.9066553711891174\n",
      "[44/100]\n",
      "-TRAIN LOSS : 0.03798983490560204 R2 : 0.9350345432758331\n",
      "-VALID LOSS : 0.03895680606365204 R2 : 0.9066553711891174\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.039364881813526154, R2 : 0.9056775569915771\n",
      "[45/100]\n",
      "-TRAIN LOSS : 0.0381818562746048 R2 : 0.9346937611699104\n",
      "-VALID LOSS : 0.039364881813526154 R2 : 0.9056775569915771\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04093056544661522, R2 : 0.9019260406494141\n",
      "[46/100]\n",
      "-TRAIN LOSS : 0.03827140270732343 R2 : 0.9345213994383812\n",
      "-VALID LOSS : 0.04093056544661522 R2 : 0.9019260406494141\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04212168976664543, R2 : 0.899071991443634\n",
      "[47/100]\n",
      "-TRAIN LOSS : 0.03830399049911648 R2 : 0.9345012605190277\n",
      "-VALID LOSS : 0.04212168976664543 R2 : 0.899071991443634\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041503362357616425, R2 : 0.9005535840988159\n",
      "[48/100]\n",
      "-TRAIN LOSS : 0.038732436718419194 R2 : 0.933586522936821\n",
      "-VALID LOSS : 0.041503362357616425 R2 : 0.9005535840988159\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041741807013750076, R2 : 0.899982213973999\n",
      "[49/100]\n",
      "-TRAIN LOSS : 0.038582881446927786 R2 : 0.9340016394853592\n",
      "-VALID LOSS : 0.041741807013750076 R2 : 0.899982213973999\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04209945723414421, R2 : 0.8991252779960632\n",
      "[50/100]\n",
      "-TRAIN LOSS : 0.03869511967059225 R2 : 0.9337265938520432\n",
      "-VALID LOSS : 0.04209945723414421 R2 : 0.8991252779960632\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.03910287842154503, R2 : 0.9063053727149963\n",
      "[51/100]\n",
      "-TRAIN LOSS : 0.038558224332518876 R2 : 0.9339690804481506\n",
      "-VALID LOSS : 0.03910287842154503 R2 : 0.9063053727149963\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04070373252034187, R2 : 0.9024695754051208\n",
      "[52/100]\n",
      "-TRAIN LOSS : 0.038082643412053585 R2 : 0.934995710849762\n",
      "-VALID LOSS : 0.04070373252034187 R2 : 0.9024695754051208\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04040847718715668, R2 : 0.90317702293396\n",
      "[53/100]\n",
      "-TRAIN LOSS : 0.038447562023065984 R2 : 0.9342616200447083\n",
      "-VALID LOSS : 0.04040847718715668 R2 : 0.90317702293396\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041051965206861496, R2 : 0.9016351699829102\n",
      "[54/100]\n",
      "-TRAIN LOSS : 0.03824436420109123 R2 : 0.9346243888139725\n",
      "-VALID LOSS : 0.041051965206861496 R2 : 0.9016351699829102\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04179423674941063, R2 : 0.8998565673828125\n",
      "[55/100]\n",
      "-TRAIN LOSS : 0.0383231540909037 R2 : 0.9345051199197769\n",
      "-VALID LOSS : 0.04179423674941063 R2 : 0.8998565673828125\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04174089804291725, R2 : 0.8999843597412109\n",
      "[56/100]\n",
      "-TRAIN LOSS : 0.03838485467713326 R2 : 0.9344021752476692\n",
      "-VALID LOSS : 0.04174089804291725 R2 : 0.8999843597412109\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04182647541165352, R2 : 0.8997793197631836\n",
      "[57/100]\n",
      "-TRAIN LOSS : 0.03835477237589657 R2 : 0.9344748631119728\n",
      "-VALID LOSS : 0.04182647541165352 R2 : 0.8997793197631836\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04173719510436058, R2 : 0.8999933004379272\n",
      "[58/100]\n",
      "-TRAIN LOSS : 0.03841822873800993 R2 : 0.9343082830309868\n",
      "-VALID LOSS : 0.04173719510436058 R2 : 0.8999933004379272\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04207674041390419, R2 : 0.8991796970367432\n",
      "[59/100]\n",
      "-TRAIN LOSS : 0.038295310572721064 R2 : 0.9345831573009491\n",
      "-VALID LOSS : 0.04207674041390419 R2 : 0.8991796970367432\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04221685603260994, R2 : 0.8988439440727234\n",
      "[60/100]\n",
      "-TRAIN LOSS : 0.03844676387961954 R2 : 0.9343043118715286\n",
      "-VALID LOSS : 0.04221685603260994 R2 : 0.8988439440727234\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041738271713256836, R2 : 0.8999906778335571\n",
      "[61/100]\n",
      "-TRAIN LOSS : 0.03838476072996855 R2 : 0.9343886524438858\n",
      "-VALID LOSS : 0.041738271713256836 R2 : 0.8999906778335571\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.042064499109983444, R2 : 0.8992090225219727\n",
      "[62/100]\n",
      "-TRAIN LOSS : 0.038319632643833756 R2 : 0.9345215633511543\n",
      "-VALID LOSS : 0.042064499109983444 R2 : 0.8992090225219727\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04221547767519951, R2 : 0.898847222328186\n",
      "[63/100]\n",
      "-TRAIN LOSS : 0.038359987433068454 R2 : 0.9344837516546249\n",
      "-VALID LOSS : 0.04221547767519951 R2 : 0.898847222328186\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04193372651934624, R2 : 0.8995223641395569\n",
      "[64/100]\n",
      "-TRAIN LOSS : 0.03841405059210956 R2 : 0.9343493655323982\n",
      "-VALID LOSS : 0.04193372651934624 R2 : 0.8995223641395569\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04189644381403923, R2 : 0.8996117115020752\n",
      "[65/100]\n",
      "-TRAIN LOSS : 0.03829672571737319 R2 : 0.9345718622207642\n",
      "-VALID LOSS : 0.04189644381403923 R2 : 0.8996117115020752\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04217502102255821, R2 : 0.8989441990852356\n",
      "[66/100]\n",
      "-TRAIN LOSS : 0.0383918829029426 R2 : 0.9344073161482811\n",
      "-VALID LOSS : 0.04217502102255821 R2 : 0.8989441990852356\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041767582297325134, R2 : 0.8999204635620117\n",
      "[67/100]\n",
      "-TRAIN LOSS : 0.038311482523567975 R2 : 0.9345457032322884\n",
      "-VALID LOSS : 0.041767582297325134 R2 : 0.8999204635620117\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.042178284376859665, R2 : 0.89893639087677\n",
      "[68/100]\n",
      "-TRAIN LOSS : 0.03830347175244242 R2 : 0.9345726445317268\n",
      "-VALID LOSS : 0.042178284376859665 R2 : 0.89893639087677\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04204806312918663, R2 : 0.8992484211921692\n",
      "[69/100]\n",
      "-TRAIN LOSS : 0.0383841993752867 R2 : 0.9344255030155182\n",
      "-VALID LOSS : 0.04204806312918663 R2 : 0.8992484211921692\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041885048151016235, R2 : 0.8996390104293823\n",
      "[70/100]\n",
      "-TRAIN LOSS : 0.03827543021179736 R2 : 0.9346287399530411\n",
      "-VALID LOSS : 0.041885048151016235 R2 : 0.8996390104293823\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04213397577404976, R2 : 0.899042546749115\n",
      "[71/100]\n",
      "-TRAIN LOSS : 0.03831121290568262 R2 : 0.9345631077885628\n",
      "-VALID LOSS : 0.04213397577404976 R2 : 0.899042546749115\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041938066482543945, R2 : 0.8995119333267212\n",
      "[72/100]\n",
      "-TRAIN LOSS : 0.03829633700661361 R2 : 0.9345906749367714\n",
      "-VALID LOSS : 0.041938066482543945 R2 : 0.8995119333267212\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04200514033436775, R2 : 0.8993512392044067\n",
      "[73/100]\n",
      "-TRAIN LOSS : 0.038273745332844555 R2 : 0.9346418902277946\n",
      "-VALID LOSS : 0.04200514033436775 R2 : 0.8993512392044067\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04199928417801857, R2 : 0.899365246295929\n",
      "[74/100]\n",
      "-TRAIN LOSS : 0.03832939954008907 R2 : 0.93454360216856\n",
      "-VALID LOSS : 0.04199928417801857 R2 : 0.899365246295929\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04178452491760254, R2 : 0.8998798727989197\n",
      "[75/100]\n",
      "-TRAIN LOSS : 0.03824702580459416 R2 : 0.9346891194581985\n",
      "-VALID LOSS : 0.04178452491760254 R2 : 0.8998798727989197\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04207815229892731, R2 : 0.899176299571991\n",
      "[76/100]\n",
      "-TRAIN LOSS : 0.03826017677783966 R2 : 0.9346686378121376\n",
      "-VALID LOSS : 0.04207815229892731 R2 : 0.899176299571991\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04197046533226967, R2 : 0.8994343280792236\n",
      "[77/100]\n",
      "-TRAIN LOSS : 0.03830850659869611 R2 : 0.9345832169055939\n",
      "-VALID LOSS : 0.04197046533226967 R2 : 0.8994343280792236\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04179241135716438, R2 : 0.8998609781265259\n",
      "[78/100]\n",
      "-TRAIN LOSS : 0.038221392198465765 R2 : 0.9347435384988785\n",
      "-VALID LOSS : 0.04179241135716438 R2 : 0.8998609781265259\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04201231896877289, R2 : 0.8993340730667114\n",
      "[79/100]\n",
      "-TRAIN LOSS : 0.038243703776970506 R2 : 0.9347029030323029\n",
      "-VALID LOSS : 0.04201231896877289 R2 : 0.8993340730667114\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04185377061367035, R2 : 0.899713933467865\n",
      "[80/100]\n",
      "-TRAIN LOSS : 0.03823679860215634 R2 : 0.9347136914730072\n",
      "-VALID LOSS : 0.04185377061367035 R2 : 0.899713933467865\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041953910142183304, R2 : 0.899474024772644\n",
      "[81/100]\n",
      "-TRAIN LOSS : 0.038186965393833816 R2 : 0.9348175674676895\n",
      "-VALID LOSS : 0.041953910142183304 R2 : 0.899474024772644\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04188435897231102, R2 : 0.899640679359436\n",
      "[82/100]\n",
      "-TRAIN LOSS : 0.03827022749464959 R2 : 0.9346680864691734\n",
      "-VALID LOSS : 0.04188435897231102 R2 : 0.899640679359436\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041767418384552, R2 : 0.8999208211898804\n",
      "[83/100]\n",
      "-TRAIN LOSS : 0.03820811316836625 R2 : 0.9347823560237885\n",
      "-VALID LOSS : 0.041767418384552 R2 : 0.8999208211898804\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04184651002287865, R2 : 0.8997313380241394\n",
      "[84/100]\n",
      "-TRAIN LOSS : 0.0382150310324505 R2 : 0.9347698166966438\n",
      "-VALID LOSS : 0.04184651002287865 R2 : 0.8997313380241394\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041738685220479965, R2 : 0.8999897241592407\n",
      "[85/100]\n",
      "-TRAIN LOSS : 0.03819945873692632 R2 : 0.9347963035106659\n",
      "-VALID LOSS : 0.041738685220479965 R2 : 0.8999897241592407\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04173631966114044, R2 : 0.8999953866004944\n",
      "[86/100]\n",
      "-TRAIN LOSS : 0.03818062273785472 R2 : 0.934831440448761\n",
      "-VALID LOSS : 0.04173631966114044 R2 : 0.8999953866004944\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.0417184941470623, R2 : 0.9000380635261536\n",
      "[87/100]\n",
      "-TRAIN LOSS : 0.0381682658335194 R2 : 0.9348589330911636\n",
      "-VALID LOSS : 0.0417184941470623 R2 : 0.9000380635261536\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04170140624046326, R2 : 0.9000790119171143\n",
      "[88/100]\n",
      "-TRAIN LOSS : 0.03816834685858339 R2 : 0.9348562434315681\n",
      "-VALID LOSS : 0.04170140624046326 R2 : 0.9000790119171143\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04167376458644867, R2 : 0.9001452326774597\n",
      "[89/100]\n",
      "-TRAIN LOSS : 0.03815239772666246 R2 : 0.9348834976553917\n",
      "-VALID LOSS : 0.04167376458644867 R2 : 0.9001452326774597\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04167754575610161, R2 : 0.9001361727714539\n",
      "[90/100]\n",
      "-TRAIN LOSS : 0.038144963909871876 R2 : 0.934895284473896\n",
      "-VALID LOSS : 0.04167754575610161 R2 : 0.9001361727714539\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041647061705589294, R2 : 0.9002092480659485\n",
      "[91/100]\n",
      "-TRAIN LOSS : 0.03813465347047895 R2 : 0.9349125102162361\n",
      "-VALID LOSS : 0.041647061705589294 R2 : 0.9002092480659485\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04163337126374245, R2 : 0.900242030620575\n",
      "[92/100]\n",
      "-TRAIN LOSS : 0.038124139653518796 R2 : 0.9349306523799896\n",
      "-VALID LOSS : 0.04163337126374245 R2 : 0.900242030620575\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041608575731515884, R2 : 0.900301456451416\n",
      "[93/100]\n",
      "-TRAIN LOSS : 0.038115139584988356 R2 : 0.9349452778697014\n",
      "-VALID LOSS : 0.041608575731515884 R2 : 0.900301456451416\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041591577231884, R2 : 0.9003421664237976\n",
      "[94/100]\n",
      "-TRAIN LOSS : 0.03810441284440458 R2 : 0.9349633231759071\n",
      "-VALID LOSS : 0.041591577231884 R2 : 0.9003421664237976\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04157242923974991, R2 : 0.9003880620002747\n",
      "[95/100]\n",
      "-TRAIN LOSS : 0.038095139898359776 R2 : 0.9349784851074219\n",
      "-VALID LOSS : 0.04157242923974991 R2 : 0.9003880620002747\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04149642586708069, R2 : 0.9005701541900635\n",
      "[96/100]\n",
      "-TRAIN LOSS : 0.03809304384049028 R2 : 0.9349717348814011\n",
      "-VALID LOSS : 0.04149642586708069 R2 : 0.9005701541900635\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04147877171635628, R2 : 0.900612473487854\n",
      "[97/100]\n",
      "-TRAIN LOSS : 0.03805744519922882 R2 : 0.9350408241152763\n",
      "-VALID LOSS : 0.04147877171635628 R2 : 0.900612473487854\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.04148771986365318, R2 : 0.9005910158157349\n",
      "[98/100]\n",
      "-TRAIN LOSS : 0.03806695167440921 R2 : 0.9350197538733482\n",
      "-VALID LOSS : 0.04148771986365318 R2 : 0.9005910158157349\n",
      "0 12\n",
      "12 24\n",
      "24 36\n",
      "36 48\n",
      "48 60\n",
      "60 72\n",
      "72 84\n",
      "84 96\n",
      "[Val] LOSS : 0.041458193212747574, R2 : 0.9006617665290833\n",
      "[99/100]\n",
      "-TRAIN LOSS : 0.03805030125658959 R2 : 0.9350488185882568\n",
      "-VALID LOSS : 0.041458193212747574 R2 : 0.9006617665290833\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 진행\n",
    "loss, r2=training(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 후 loss 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "THRESHOLD=100\n",
    "fg, axes=plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].plot(range(1,THRESHOLD+1),loss[0][:THRESHOLD], label='Train')\n",
    "axes[0].plot(range(1,THRESHOLD+1),loss[1][:THRESHOLD], label='Val')\n",
    "axes[0].set_title('LOSS')\n",
    "axes[0].grid()\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(range(1,THRESHOLD+1),r2[0][:THRESHOLD], label='Train')\n",
    "axes[1].plot(range(1,THRESHOLD+1),r2[1][:THRESHOLD], label='Val')\n",
    "axes[1].set_title('R2')\n",
    "axes[1].grid()\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('R2')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
