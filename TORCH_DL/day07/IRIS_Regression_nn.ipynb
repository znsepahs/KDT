{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  DNN기반 회귀 모델 구현 + 학습 스케줄링\n",
    "- 데이터 셋 : iris.csv\n",
    "- 피쳐/속성 : 3개 Sepal_Length, Sepal_Width, Petal_Length\n",
    "- 타겟/라벨 : 1개 Petal_Width\n",
    "- 학습-방법 : 지도학습 > 회귀\n",
    "- 알고 리즘 : 인공신경망(ANN) -> MLP, DNN : 은닉층이 많은 구성 \n",
    "- 프레임워크 : \n",
    "***\n",
    "- 학습스케줄링\n",
    "    * 학습 시 동적으로 lr 값을 조절해주는 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모듈 로딩\n",
    "# - Model관련\n",
    "import torch              \n",
    "import torch.nn as nn              \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.optim as optim                             # 최적화 관련 모듈\n",
    "import torch.optim.lr_scheduler as lr_scheduler         # 최적화 스케줄링 관련 모듈\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError \n",
    "from torchinfo import summary \n",
    "\n",
    "#- Data 및 시각화 관련\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt              \n",
    "from sklearn.preprocessing import * \n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch v.2.4.1\n",
      "Pandas  v.2.0.3\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크 ==> 사용자 정의함수로 구현하세요~!!\n",
    "print(f'Pytorch v.{torch.__version__}')\n",
    "print(f'Pandas  v.{pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width\n",
       "0           5.1          3.5           1.4          0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  데이터 로딩\n",
    "DATA_FILE='../data/iris.csv' \n",
    "\n",
    "### CSV >>> DataFrame\n",
    "irisDF = pd.read_csv(DATA_FILE, usecols=[0,1,2,3])\n",
    "\n",
    "### 확인\n",
    "irisDF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의 <hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론 목적\n",
    "- 클래스이름 : IrisRegModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개__변수 : 층별 입출력 개수 고정하기때문에 필요 없음!\n",
    "- 속성__필드 : \n",
    "- 기능__역할 : __init__() : 모델 구조 설정 ,  forward() : 순방향 학습 <= 오바라이딩(overriding)\n",
    "- 클래스구조 \n",
    "    * 입력층 : 입력 3개(피쳐)      출력   10개(퍼셉트론/뉴런 10개 존재)\n",
    "    * 은닉층 : 입력 10개           출력   30개(퍼셉트론/뉴런 30개 존재)\n",
    "    * 출력층 : 입력 30개           출력   1개(너비값)\n",
    "\n",
    "- 활성화함수\n",
    "    * 클래스 형태 ==> nn.MESLoss, nn.ReLU ==> __init__() 메서드 \n",
    "    * 함수 형태 ==> torch.nn.functional 아래에  ==> forward()메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisRegModel(nn.Module):\n",
    "    \n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_layer=nn.Linear(3, 10)\n",
    "        self.hd_layer=nn.Linear(10, 30)\n",
    "        self.out_layer=nn.Linear(30, 1)\n",
    "        \n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, input_data):\n",
    "        #- 입력층\n",
    "        y=self.in_layer(input_data)   # fi1W11+f12W12+f13W13+b, ... , fi101W101+f102W102+fi103W103+b\n",
    "        y=F.relu(y)                   # relu => y 값의 범위 : 0 <= y\n",
    "        \n",
    "        # - 은닉층 : 10개의 숫자 값(>=0)\n",
    "        y=self.hd_layer(y)            # f21W11+f22W12...+f210W210+b, ... , f230W201+...+f230W210+b\n",
    "        y=F.relu(y)                   # relu => y 값의 범위 : 0 <= y\n",
    "        \n",
    "        #- 출력층 : 30개의 숫자 값(>=0) 회귀이므로 바로 반환(return)\n",
    "        return self.out_layer(y)              # f31W31+.....+f330W330+b  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisRegModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (hd_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### 모델 인스턴스 생성\n",
    "model = IrisRegModel()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "IrisRegModel                             [1000000, 1]              --\n",
       "├─Linear: 1-1                            [1000000, 10]             40\n",
       "├─Linear: 1-2                            [1000000, 30]             330\n",
       "├─Linear: 1-3                            [1000000, 1]              31\n",
       "==========================================================================================\n",
       "Total params: 401\n",
       "Trainable params: 401\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 401\n",
       "==========================================================================================\n",
       "Input size (MB): 12.00\n",
       "Forward/backward pass size (MB): 328.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 340.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(1000000,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>\n",
    "- 데이터_셋 : iris.csv\n",
    "- 피쳐_개수 : 3개\n",
    "- 타겟_개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성__필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드 \n",
    "    * _ _init_ _(self) : 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    * _ _len_ _(self) : 데이터의 개수 반환\n",
    "    * _ _getItem_ _(self, index) : 특정 인덱스의 피쳐와 타겟 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF=featureDF \n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]\n",
    "        self.n_features=featureDF.shape[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 텐서화\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values) \n",
    "        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 인스턴스 생성\n",
    "\n",
    "# - DataFram에서 피쳐와 타겟 추출\n",
    "featureDF = irisDF[irisDF.columns[:-1]]   # 2D (150, 3)\n",
    "targetDF = irisDF[irisDF.columns[-1:]]    # 2D (150, 1)\n",
    "\n",
    "# - 커스텀데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF, targetDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비 \n",
    "- 학습_횟수 : EPOCH         <- 처음~끝까지 공부하는 단위\n",
    "- 배치_크기 : BATCH_SIZE    <- 한번에 학습할 데이터셋 양 \n",
    "- 위치_지정 : DEVICE    <- 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학_습_률 : LR 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_CNT : 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### 학습 진행 관련 설정\n",
    "EPOPCH = 1000\n",
    "BATCH_SIZE = 10\n",
    "BATCH_CNT = irisDF.shape[0]//BATCH_SIZE\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001\n",
    "\n",
    "print(f'BATCH_CNT : {BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화 (, 손실함수, 성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 3) (38, 3) (28, 3)\n",
      "(84, 1) (38, 1) (28, 1)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 인스턴스\n",
    "model=IrisRegModel() \n",
    "\n",
    "# 데이터셋 인스턴스\n",
    "X_train, X_test, y_train, y_test =train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val =train_test_split(X_train, y_train, random_state=1)\n",
    "print(f'{X_train.shape} {X_test.shape} {X_val.shape}')\n",
    "print(f'{y_train.shape} {y_test.shape} {y_val.shape}')\n",
    "print(f'{type(X_train)} {type(X_test)} {type(X_val)}')\n",
    "\n",
    "trainDS=IrisDataset(X_train, y_train)\n",
    "valDS=IrisDataset(X_val, y_val)\n",
    "testDS=IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터로더 인스턴스\n",
    "trainDL=DataLoader(trainDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "## [테스트]데이터로더와 데이터셋 체크\n",
    "for feature, target in trainDL: \n",
    "    print(feature.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LG\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 최적화 스케줄링 인스턴스 생성 => lr 조절 및 성능 개선여부 체크\n",
    "scheduler=lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
    "\n",
    "# 손실함수 인스턴스 => 회귀, MSE, MAE, RMSE ....\n",
    "reqLoss=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT => 15.0\n",
      "5EPOCH 성능 개선이 없어서 조기종료함!\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTORY=[[],[]], [[],[]]\n",
    "CNT=irisDS.n_rows/BATCH_SIZE\n",
    "print(f'CNT => {CNT}')\n",
    "\n",
    "for epoch in range(EPOPCH):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    \n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0,0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "        \n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss=reqLoss(pre_y, targetTS)\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        # 성능평가 계산\n",
    "        score=R2Score()(pre_y, targetTS)\n",
    "        score_total += score.item()\n",
    "        \n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featrueTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "        # 추론/평가\n",
    "        pre_val=model(val_featrueTS)\n",
    "        # 손실\n",
    "        loss_val=reqLoss(pre_val, val_targetTS)\n",
    "        # 성능평가\n",
    "        score_val=R2Score()(pre_val, val_targetTS)\n",
    "    \n",
    "    # 에포크 당 손실값과 성능평가값 저장    \n",
    "    LOSS_HISTORY[0].append(loss_total/CNT)\n",
    "    SCORE_HISTORY[0].append(score_total/CNT)\n",
    "    \n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTORY[1].append(score_val)\n",
    "\n",
    "    # 최적화 스케줄러 인스턴스 업데이트\n",
    "    scheduler.step(score_val)\n",
    "    # print(f'scheduler.num_bad_epochs => {scheduler.num_bad_epochs}', end=' ')\n",
    "    # print(f'scheduler.num_bad_epochs => {scheduler.patience}')\n",
    "\n",
    "    # 손실 감소(또는 성능 개선)이 안되는 경우 조기종료\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience:\n",
    "        print(f'{scheduler.patience}EPOCH 성능 개선이 없어서 조기종료함!')\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 3]), torch.Size([28, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_featrueTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "val_featrueTS.shape, val_targetTS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT => 15.0\n",
      "LOSS_HISTORY => [[1.2504398425420125, 1.0226715246836344, 0.8413142999013264, 0.6896210471789043, 0.5540767470995586, 0.43645829558372495, 0.3408009151617686, 0.2724236249923706, 0.23070291082064312, 0.20675999720891317, 0.18919426202774048, 0.17226582765579224, 0.1559454490741094, 0.140682914853096, 0.12692466775576275, 0.1142720212539037, 0.10249302685260772, 0.09170929392178853, 0.0818999061981837, 0.07309527893861135, 0.0652972345550855, 0.05844845622777939, 0.05253114824493726, 0.04752337858080864, 0.04334290226300557, 0.03991117502252261, 0.03713669429222743, 0.03493031337857246, 0.033198582877715425, 0.03185521525641282, 0.030805954585472743, 0.0299984830742081, 0.029438404987255733, 0.029028932315607867, 0.028703188275297484, 0.028439682597915333, 0.028225240732232728, 0.028044292330741884, 0.027882243258257708, 0.027730969587961833, 0.02749159708619118, 0.027476133902867635, 0.027461356793840725, 0.027447101660072803, 0.027433060482144354, 0.02741902309159438, 0.027395947153369585, 0.027394489943981172, 0.027393026898304623, 0.02739154684046904, 0.02739006814857324, 0.027388563317557176, 0.027386131510138512, 0.027385984485348066, 0.027385826346774896, 0.02738567814230919, 0.02738551323612531, 0.02738535813987255, 0.027385099542637667, 0.027385081040362518, 0.027385074645280838, 0.027385054466625054, 0.0273850425456961, 0.027385033232470355, 0.027385010508199532, 0.027385011253257593, 0.027385011749962964, 0.027385011998315653, 0.027385011998315653, 0.027385011998315653, 0.02738501224666834, 0.02738501224666834, 0.02738501224666834, 0.027385012743373714, 0.02738501224666834, 0.02738501150161028, 0.027385010632375875, 0.027385010632375875, 0.027385010632375875, 0.02738501038402319, 0.02738501038402319, 0.02738501038402319, 0.027385010880728564, 0.027385010880728564, 0.027385012619197367, 0.027385012619197367, 0.027385012619197367, 0.027385011998315653, 0.027385011998315653, 0.027385011749962964, 0.02738500963896513, 0.02738501044611136, 0.027385009390612444, 0.027385008335113526, 0.027385006534556548, 0.027385006782909234, 0.02738500659664472, 0.027385006348292034, 0.027385003368059792, 0.027385003119707107, 0.0273850051065286, 0.02738500405102968, 0.027385002685089907, 0.027385000015298526, 0.027385002498825393, 0.027385002995530764, 0.027385004175206024, 0.027385007590055466, 0.027385004237294196, 0.02738500349223614, 0.027385004982352256, 0.027385005044440427, 0.02738500665873289, 0.027385008210937183, 0.02738500895599524, 0.02738500920434793, 0.02738500920434793, 0.027385006720821062, 0.027385007590055466, 0.02738500845928987, 0.027385007962584494, 0.027385005727410316, 0.02738500355432431, 0.027385006099939345, 0.027385009018083415, 0.027385006969173748, 0.02738500274717808, 0.02738500026365121, 0.02738500057409207, 0.027385003802676996, 0.027385004609823228, 0.027385006410380205, 0.0273850051065286, 0.02738500727961461, 0.027385006534556548, 0.027385006099939345, 0.027385001070797443, 0.027385002498825393, 0.027385002312560875, 0.027385000325739383, 0.027384994737803935, 0.027385000512003897, 0.027384999891122183, 0.02738499715924263, 0.027385002436737218, 0.027385002685089907, 0.027385003430147967, 0.027385002188384532, 0.02738500324388345, 0.027385004485646885, 0.02738500349223614, 0.02738500523070494, 0.027385003740588824, 0.027385001505414643, 0.027385003678500653, 0.027385002685089907, 0.027385003430147967, 0.027385001753767332, 0.02738499902188778, 0.02738499895979961, 0.02738499908397595, 0.02738499982903401, 0.02738499976694584, 0.027384998773535094, 0.02738499902188778, 0.027385000760356586, 0.02738500013947487, 0.02738499951859315, 0.027384997345507145, 0.027384996600449085, 0.027384998028477034, 0.027384998525182405, 0.02738499976694584, 0.027385001505414643, 0.027384997035066288, 0.027384998773535094, 0.027384999270240466, 0.027384999270240466, 0.027385002498825393, 0.02738499715924263, 0.027384995544950167, 0.027384997469683488, 0.02738499560703834, 0.027384993682305018, 0.027384994365274907, 0.027384996165831885, 0.027384999208152294, 0.027385002250472704, 0.0273849967867136, 0.027384990888337294, 0.027384990888337294, 0.027384989087780316, 0.027384990453720094, 0.027384991260866322, 0.027384993247687818, 0.027384992440541586, 0.027384991074601808, 0.027384992130100726, 0.027384989646573862, 0.027384990143279234, 0.027384990515808266, 0.02738499001910289, 0.02738498772184054, 0.0273849884668986, 0.027384988963603973, 0.027384988280634084, 0.027384989460309348, 0.027384989087780316, 0.02738499256471793, 0.02738498685260614, 0.027384990329543748, 0.027384988653163116, 0.027384990577896437, 0.027384988342722256, 0.027384990577896437, 0.027384989832838377, 0.02738498349984487, 0.027384983934462072, 0.027384983375668526, 0.02738498089214166, 0.02738498281687498, 0.02738498051961263, 0.02738498095422983, 0.027384981575111548, 0.02738497853279114, 0.027384976421793304, 0.02738497716685136, 0.02738497865696748, 0.027384976421793304, 0.027384978160262106, 0.027384977663556735, 0.02738497741520405, 0.027384978905320167, 0.02738497741520405, 0.027384981388847034, 0.027384978346526624, 0.027384978470702967, 0.027384978905320167, 0.027384977539380392, 0.02738497716685136, 0.027384977291027703, 0.027384975738823415, 0.027384973752001922, 0.027384972013533116, 0.027384971578915913, 0.02738497070968151, 0.02738497070968151, 0.027384972323973973, 0.027384971951444945, 0.027384975117941697, 0.027384969716270764, 0.027384969716270764, 0.02738497368991375, 0.02738497294485569, 0.02738497288276752, 0.02738497145473957, 0.02738497145473957, 0.027384970895946027, 0.027384973814090094, 0.027384965680539608, 0.027384968226154646, 0.027384968226154646, 0.02738496953000625, 0.027384971206386884, 0.027384969964623453, 0.027384967977801957, 0.027384967419008414, 0.027384967046479382, 0.027384968598683675, 0.027384971827268602, 0.027384971206386884, 0.027384969405829906, 0.027384970026711624, 0.027384968536595503, 0.027384964749217033, 0.027384962327778338, 0.027384959720075132, 0.027384958788752557, 0.02738496338327726, 0.027384961706896624, 0.02738495481510957, 0.02738495698819558, 0.027384961023926735, 0.02738496121019125, 0.02738496381789446, 0.027384960340956846, 0.027384959595898786, 0.027384961086014906, 0.027384957112371922, 0.02738495885084073, 0.027384959968427817, 0.02738496152063211, 0.027384959471722443, 0.027384957981606325, 0.027384957733253636, 0.027384957236548265, 0.027384954504668713, 0.027384957609077294, 0.0273849556222558, 0.027384949599703154, 0.02738494916508595, 0.02738495506346226, 0.027384955311814944, 0.027384953573346138, 0.02738495171070099, 0.027384948295851547, 0.02738494798541069, 0.02738494873046875, 0.027384946619470916, 0.027384948109587033, 0.02738494835793972, 0.027384951896965503, 0.027384954753021398, 0.027384951586524646, 0.027384947861234347, 0.027384947861234347, 0.027384947861234347, 0.027384944818913938, 0.027384943577150503, 0.027384942459563414, 0.027384941217799982, 0.027384946184853712, 0.02738494991014401, 0.027384948109587033, 0.02738494308044513, 0.027384946433206398, 0.02738494655738274, 0.027384945191442966, 0.027384942459563414, 0.027384941900769868, 0.027384942583739757, 0.027384940224389236, 0.027384941776593525, 0.02738494295626879, 0.027384940534830093, 0.02738494277000427, 0.02738494345297416, 0.027384945439795652, 0.02738494413594405, 0.027384936499098938, 0.027384938672184944, 0.02738493972768386, 0.027384940907359122, 0.027384939913948376, 0.027384941652417182, 0.02738493817547957, 0.027384937244156995, 0.027384937244156995, 0.027384933891395728, 0.027384929545223712, 0.027384933767219385, 0.02738493209083875, 0.027384925944109757, 0.027384929669400055, 0.027384931221604347, 0.02738493283589681, 0.027384931532045204, 0.02738493140786886, 0.02738492824137211, 0.027384927434225877, 0.027384927993019424, 0.027384929358959198, 0.0273849256336689, 0.027384926627079646, 0.02738492793093125, 0.02738492898643017, 0.02738493140786886, 0.027384929545223712, 0.027384926627079646, 0.027384926689167817, 0.02738492712378502, 0.027384924764434496, 0.027384925074875353, 0.02738492383311192, 0.02738492302596569, 0.027384923522671065, 0.02738492377102375, 0.027384924081464607, 0.027384921039144198, 0.027384921349585055, 0.027384923398494722, 0.027384919611116252, 0.027384918679793677, 0.027384917500118414, 0.027384916010002296, 0.02738491476823886, 0.027384916506707668, 0.02738491551329692, 0.027384916382531325, 0.02738491433362166, 0.027384913774828115, 0.02738491470615069, 0.027384914085268976, 0.027384913340210915, 0.027384913029770055, 0.027384914519886176, 0.027384910049537817, 0.027384912719329198, 0.027384911477565766, 0.02738491309185823, 0.027384910359978677, 0.027384911353389423, 0.027384911105036734, 0.02738490837315718, 0.02738490862150987, 0.027384906137983004, 0.027384904896219572, 0.0273849052687486, 0.027384906262159347, 0.027384910732507706, 0.02738490781436364, 0.027384903902808826, 0.027384901170929274, 0.027384905392924944, 0.02738490520666043, 0.027384905082484087, 0.027384906324247518, 0.02738490638633569, 0.02738490787645181, 0.027384902785221734, 0.027384906262159347, 0.027384907255570093, 0.02738490328192711, 0.027384902412692706, 0.02738489837696155, 0.027384901915987334, 0.027384900860488413, 0.027384903778632484, 0.027384903157750766, 0.027384903095662595, 0.027384900425871214, 0.02738489961872498, 0.027384898687402407, 0.02738489992916584, 0.027384895458817483, 0.02738489086429278, 0.027384891733527185, 0.02738489198187987, 0.027384893223643302, 0.027384893471995988, 0.027384891547262667, 0.02738488931208849, 0.02738488974670569, 0.027384889001647632, 0.027384893968701363, 0.02738489123682181, 0.027384892851114274, 0.027384888504942258, 0.027384889684617518, 0.027384888815383115, 0.027384889001647632, 0.02738488595932722, 0.02738488782197237, 0.027384888815383115, 0.027384892292320728, 0.02738488670438528, 0.027384883351624013, 0.027384885090092816, 0.02738488409668207, 0.027384883103271324, 0.027384880185127258, 0.027384882109860578, 0.027384880681832632, 0.02738488602141539, 0.027384884717563788, 0.027384881240626175, 0.027384880868097147, 0.027384877577424048, 0.02738487832248211, 0.027384878819187483, 0.027384879564245544, 0.027384877391159534, 0.027384874473015467, 0.027384873541692892, 0.02738487205157677, 0.027384876335660616, 0.027384873976310096, 0.027384874969720842, 0.02738487192740043, 0.02738487149278323, 0.02738487037519614, 0.02738487149278323, 0.02738487459719181, 0.02738487490763267, 0.02738487347960472, 0.027384874410927296, 0.027384873107075693, 0.02738486702243487, 0.027384865656495096, 0.027384867829581102, 0.02738487006475528, 0.02738486851255099, 0.027384868015845616, 0.027384861682852108, 0.02738486466308435, 0.02738486398011446, 0.027384862179557483, 0.027384865718583267, 0.027384864600996175, 0.027384861496587594, 0.027384860006471477, 0.027384862241645654, 0.027384862179557483, 0.02738486137241125, 0.027384864166378975, 0.02738485938558976, 0.02738485795756181, 0.027384858454267184, 0.027384855225682257, 0.027384855225682257, 0.027384857088327406, 0.027384857274591924, 0.02738485528777043, 0.02738485609491666, 0.027384860068559648, 0.027384858516355356, 0.027384856529533864, 0.027384854294359683, 0.027384851438303787, 0.027384849389394124, 0.027384849513570467, 0.027384849078953267, 0.02738484727839629, 0.02738485069324573, 0.02738485069324573, 0.027384851376215616, 0.02738484467069308, 0.02738484653333823, 0.02738485069324573, 0.027384849513570467, 0.027384848147630692, 0.02738484622289737, 0.027384845229486626, 0.027384844049811362, 0.02738484808554252, 0.027384844856957594, 0.027384846471250057, 0.027384844360252222, 0.02738484473278125, 0.027384845726191997, 0.027384845105310283, 0.027384840262432892, 0.027384839269022146, 0.02738484274595976, 0.027384840759138267, 0.027384835854172708, 0.027384837406376997, 0.027384839331110317, 0.0273848378409942, 0.02738483523329099, 0.027384833556910355, 0.027384828465680282, 0.027384826540946962, 0.027384826665123305, 0.02738482728600502, 0.02738482573380073, 0.027384826416770616, 0.027384829272826514, 0.027384831632177035, 0.02738482989370823, 0.02738482728600502, 0.027384829148650168, 0.02738482728600502, 0.027384825857977073, 0.027384824678301813, 0.0273848257958889, 0.02738482430577278, 0.02738482356071472, 0.02738482567171256, 0.027384827906886736, 0.02738482734809319, 0.02738482567171256, 0.027384824119508266, 0.02738482498874267, 0.02738482231895129, 0.02738482169806957, 0.027384822567303974, 0.02738482691347599, 0.027384824429949123, 0.027384823436538377, 0.027384819214542708, 0.027384817600250244, 0.027384817227721216, 0.02738481971124808, 0.027384817724426587, 0.027384816917280355, 0.027384817227721216, 0.027384813067813714, 0.02738481213649114, 0.027384814185400803, 0.02738481406122446, 0.027384814185400803, 0.027384816979368527, 0.027384815116723377, 0.027384813502430917, 0.027384810522198676, 0.02738480983922879, 0.027384808535377184, 0.027384812012314796, 0.027384812446931996, 0.027384812384843825, 0.027384809218347073, 0.02738481021175782, 0.02738481151560942, 0.027384807293613752, 0.027384806300203006, 0.02738480145732562, 0.02738480158150196, 0.027384800650179387, 0.027384803630411625, 0.027384803568323453, 0.027384802450736365, 0.027384802512824536, 0.027384802947441736, 0.02738480151941379, 0.027384799905121326, 0.02738479779412349, 0.02738479766994715, 0.027384797607858977, 0.027384796676536403, 0.027384794565538564, 0.027384795807302, 0.02738479766994715, 0.027384796800712746, 0.02738479698697726, 0.027384797607858977, 0.02738479884962241, 0.027384794068833193, 0.027384792392452558, 0.02738479475180308, 0.02738479065398375, 0.02738479319959879, 0.027384792206188044, 0.02738479288915793, 0.027384797545770802, 0.027384791895747183, 0.027384787425398828, 0.027384788480897745, 0.027384787487487, 0.027384788170456885, 0.02738478754957517, 0.027384788542985917, 0.027384790902336437, 0.027384787860016028, 0.027384785749018193, 0.02738478264460961, 0.027384786618252596, 0.02738478562484185, 0.027384780098994574, 0.027384783203403155, 0.027384781713287034, 0.027384781216581663, 0.027384776870409647, 0.027384779043495656, 0.027384777925908564, 0.02738477730502685, 0.027384779291848342, 0.02738478295505047, 0.02738477842261394, 0.027384774945676326, 0.027384775752822558, 0.02738477581491073, 0.02738477463523547, 0.027384772275884945, 0.02738477271050215, 0.027384772275884945, 0.027384771034121513, 0.027384773331383862, 0.027384771158297856, 0.02738476867477099, 0.027384768178065618, 0.02738477090994517, 0.027384764390687148, 0.027384769171476364, 0.027384771406650542, 0.027384771965444088, 0.027384772462149463, 0.02738477016488711, 0.02738476824015379, 0.02738476488739252, 0.027384762031336624, 0.027384763583540916, 0.027384763831893602, 0.027384762838482856, 0.027384765756626923, 0.027384766129155955, 0.027384764639039834, 0.027384760975837707, 0.027384760292867818, 0.027384760354955993, 0.02738475998242696, 0.027384758864839872, 0.02738475576043129, 0.027384756257136662, 0.02738475619504849, 0.02738475694010655, 0.027384754021962485, 0.02738475656757752, 0.02738475309063991, 0.027384753401080767, 0.027384755077461402, 0.0273847509175539, 0.027384750545024872, 0.027384750731289386, 0.027384750793377557, 0.02738474595050017, 0.027384744895001253, 0.027384744149943192, 0.027384743963678678, 0.027384750669201215, 0.027384747688968977, 0.027384747937321662, 0.027384744522472224, 0.027384741914769015, 0.027384737382332484, 0.027384741107622783, 0.02738473986585935, 0.027384739679594833, 0.027384744212031364, 0.027384743404885132, 0.02738473949333032, 0.02738474098344644, 0.027384737816949684, 0.027384736326833567, 0.02738473725815614, 0.02738473576804002, 0.027384734153747557, 0.027384732042749722, 0.027384729435046513, 0.027384732042749722, 0.027384730676809948, 0.02738473148395618, 0.027384730242192745, 0.027384732477366926, 0.027384733657042186, 0.02738473303616047, 0.027384732539455097, 0.027384730552633605, 0.027384731732308865, 0.027384724157551926, 0.02738472434381644, 0.027384726082285246, 0.027384726392726103, 0.027384728317459424, 0.027384731359779833, 0.027384728069106738, 0.027384727324048678, 0.027384726889431478, 0.027384724964698157, 0.02738472484052181, 0.02738472210864226, 0.02738472359875838, 0.027384718755880992, 0.02738472322622935, 0.027384724902609982, 0.027384721860289573, 0.027384715899825097, 0.027384712484975655, 0.027384710436065992, 0.027384709504743417, 0.02738471223662297, 0.027384710063536963, 0.027384709815184274, 0.02738470894594987, 0.027384712050358456, 0.027384713540474573, 0.027384709380567075, 0.027384707145392893, 0.027384708697597186, 0.02738471291959286, 0.02738471267124017, 0.02738471105694771, 0.027384711429476738, 0.027384711429476738, 0.027384709442655246, 0.027384707455833754, 0.027384707393745582, 0.02738470919430256, 0.027384707952539125, 0.02738470695912838, 0.0273847051585714, 0.027384703730543455, 0.02738470062613487, 0.027384703420102595, 0.027384703606367113, 0.02738470093657573, 0.02738470391680797, 0.027384699818988643, 0.027384699756900468, 0.027384701743721963, 0.027384701433281103, 0.02738470255086819, 0.02738469820469618, 0.027384697335461776, 0.0273847001294295, 0.02738469677666823, 0.027384695286552112, 0.027384696528315544, 0.027384693982700506, 0.027384693361818792, 0.02738469441731771, 0.027384693920612335, 0.02738469491402308, 0.027384691499173643, 0.02738469249258439, 0.027384691499173643, 0.027384689015646776, 0.027384691995879014, 0.027384689077734947, 0.027384688208500544, 0.027384689015646776, 0.027384689077734947, 0.027384687587618826, 0.027384687090913455, 0.027384685600797334, 0.02738468994696935, 0.027384690940380096, 0.02738469305137793, 0.027384687587618826, 0.027384686966737112, 0.027384684421122074, 0.027384687090913455, 0.027384688208500544, 0.02738468355188767, 0.027384682868917782, 0.027384685600797334, 0.027384687215089798, 0.02738468926399946, 0.027384683303534985, 0.02738468013703823, 0.027384681130448976, 0.02738468013703823, 0.027384677405158677, 0.02738467293481032, 0.027384674549102782, 0.027384676101307074, 0.027384673493603864, 0.027384674673279128, 0.02738467212766409, 0.027384672686457633, 0.027384674859543642, 0.027384671941399576, 0.027384670016666255, 0.027384672686457633, 0.027384678150216737, 0.02738467336942752, 0.027384670513371626, 0.027384671941399576, 0.027384671693046887, 0.02738466840237379, 0.027384668899079163, 0.027384666725993156, 0.027384667346874874, 0.027384666725993156, 0.027384671693046887, 0.027384665235877036, 0.027384667719403902, 0.027384670451283455, 0.027384666974345842, 0.027384664366642632, 0.027384662007292112, 0.027384659089148045, 0.027384661448498566, 0.02738466076552868, 0.027384657723208267, 0.02738465629518032, 0.027384657164414725, 0.027384658033649128, 0.027384657040238382, 0.027384656543533007, 0.027384656916062036, 0.027384656108915807, 0.02738465281824271, 0.027384655674298604, 0.027384657536943753, 0.027384652569890023, 0.027384651079773902, 0.027384653935829797, 0.027384653501212598, 0.027384651079773902, 0.027384651079773902, 0.027384651079773902, 0.02738464723030726, 0.02738464679569006, 0.027384646547337372, 0.02738464536766211, 0.02738464574019114, 0.02738464263578256, 0.02738464344292879, 0.027384646671513715, 0.027384643567105134, 0.02738463766872883, 0.027384636737406255, 0.02738464077313741, 0.02738464151819547, 0.02738463735828797, 0.027384639469285807, 0.02738463735828797, 0.027384636737406255, 0.027384635930260023, 0.027384635681907337, 0.027384635247290134, 0.027384634936849277, 0.02738463661322991, 0.027384633384644985, 0.027384633446733156, 0.02738463655114174, 0.027384635371466477, 0.02738462872803211, 0.02738463059067726, 0.027384633757174016, 0.027384633012115956, 0.02738463133573532, 0.027384628852208454, 0.02738462829341491, 0.027384625375270845, 0.02738462363680204, 0.027384626182417073, 0.027384626430769762, 0.027384618607660133, 0.0273846164966623, 0.02738461618622144, 0.027384622767567635, 0.027384619538982708, 0.027384621587892375, 0.02738461916645368, 0.02738461767633756, 0.027384616745014984, 0.027384614944458006, 0.027384616310397784, 0.0273846160620451, 0.027384615068634353, 0.027384615565339724, 0.02738461270928383, 0.027384614137311778, 0.02738461283346017, 0.027384612150490283, 0.027384612957636514, 0.027384611467520397, 0.027384609480698905, 0.027384606997172038, 0.02738461587578058, 0.027384611777961254, 0.027384612957636514, 0.027384612150490283, 0.027384606748819353, 0.027384606748819353, 0.027384607307612895, 0.0273846090460817, 0.02738461165378491, 0.02738460898399353, 0.027384606127937635, 0.02738460637629032, 0.02738460563123226, 0.027384606872995695, 0.027384605755408607, 0.027384603520234425, 0.027384602775176365, 0.02738460022956133, 0.027384597063064575, 0.027384596318006514, 0.027384597932298978, 0.027384604637821514, 0.027384603147705397, 0.027384602899352708, 0.027384600974619387, 0.027384598429004352, 0.027384599236150584, 0.02738459619383017, 0.02738459644218286, 0.027384596007565657, 0.027384594827890397, 0.027384595324595768, 0.027384597932298978, 0.027384594455361365, 0.027384591413040955, 0.02738459383447965, 0.027384595945477486, 0.027384593275686105, 0.02738459122677644, 0.0273845911026001, 0.027384588432808717, 0.027384586011370022, 0.027384589177866778, 0.02738458849489689, 0.02738458551466465, 0.027384587998191514, 0.02738458619763454, 0.02738458352784316, 0.027384582720696927, 0.027384582223991552, 0.027384580112993717, 0.027384579181671143, 0.027384577815731368, 0.027384578622877596, 0.027384577815731368, 0.027384577691555022, 0.027384580112993717, 0.027384580050905546, 0.0273845757668217], [tensor(1.5887), tensor(1.3002), tensor(1.0735), tensor(0.8789), tensor(0.7131), tensor(0.5809), tensor(0.4878), tensor(0.4379), tensor(0.4131), tensor(0.3911), tensor(0.3599), tensor(0.3214), tensor(0.2832), tensor(0.2493), tensor(0.2213), tensor(0.1972), tensor(0.1751), tensor(0.1541), tensor(0.1345), tensor(0.1174), tensor(0.1028), tensor(0.0903), tensor(0.0797), tensor(0.0710), tensor(0.0640), tensor(0.0586), tensor(0.0545), tensor(0.0516), tensor(0.0496), tensor(0.0483), tensor(0.0475), tensor(0.0469), tensor(0.0465), tensor(0.0464), tensor(0.0465), tensor(0.0466), tensor(0.0467), tensor(0.0467), tensor(0.0468), tensor(0.0468), tensor(0.0468), tensor(0.0467), tensor(0.0467), tensor(0.0467), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466), tensor(0.0466)]]\n",
      "SCORE_HISTORY => [[-2.0760646502176923, -1.589470100402832, -1.2011778354644775, -0.875887131690979, -0.5841521581013998, -0.329162327448527, -0.11915499369303385, 0.034210240840911864, 0.12983024915059407, 0.18442471424738566, 0.22189218997955323, 0.2557153065999349, 0.28750685453414915, 0.3169471780459086, 0.34375000397364297, 0.3688784201939901, 0.3925154209136963, 0.4140005588531494, 0.4333009719848633, 0.45057460069656374, 0.46592231194178263, 0.4794474482536316, 0.4911320964495341, 0.5010077079137166, 0.5092546145121256, 0.5160231073697408, 0.5214990496635437, 0.5258616288503011, 0.5292934497197469, 0.5319584329922994, 0.5340389013290405, 0.5356372714042663, 0.5367576718330384, 0.537593404452006, 0.5382709264755249, 0.5388322552045186, 0.5392974615097046, 0.5396929025650025, 0.540047287940979, 0.5403791785240173, 0.5408726294835409, 0.5409089883168539, 0.5409438371658325, 0.5409771243731181, 0.5410094459851583, 0.5410413265228271, 0.5410888353983562, 0.5410921255747477, 0.5410954117774963, 0.5410987456639608, 0.5411020676294963, 0.5411054571469625, 0.5411104758580526, 0.5411108016967774, 0.541111155351003, 0.5411114851633708, 0.5411118507385254, 0.5411122004191081, 0.541112732887268, 0.5411127765973409, 0.5411128004391988, 0.5411128322283427, 0.5411128679911296, 0.5411128838857014, 0.5411129395167033, 0.5411129395167033, 0.5411129395167033, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129315694173, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129395167033, 0.5411129395167033, 0.5411129395167033, 0.5411129355430603, 0.5411129355430603, 0.5411129315694173, 0.5411129315694173, 0.5411129315694173, 0.5411129355430603, 0.5411129355430603, 0.5411129355430603, 0.5411129395167033, 0.5411129395167033, 0.5411129395167033, 0.5411129474639893, 0.5411129474639893, 0.5411129434903462, 0.5411129434903462, 0.5411129434903462, 0.5411129514376323, 0.5411129514376323, 0.5411129514376323, 0.5411129474639893, 0.5411129514376323, 0.5411129593849182, 0.5411129514376323, 0.5411129514376323, 0.5411129474639893, 0.5411129395167033, 0.5411129474639893, 0.5411129514376323, 0.5411129474639893, 0.5411129474639893, 0.5411129474639893, 0.5411129434903462, 0.5411129395167033, 0.5411129355430603, 0.5411129315694173, 0.5411129395167033, 0.5411129434903462, 0.5411129434903462, 0.5411129434903462, 0.5411129474639893, 0.5411129554112752, 0.5411129514376323, 0.5411129395167033, 0.5411129395167033, 0.5411129474639893, 0.5411129554112752, 0.5411129554112752, 0.5411129514376323, 0.5411129434903462, 0.5411129395167033, 0.5411129474639893, 0.5411129434903462, 0.5411129474639893, 0.5411129474639893, 0.5411129593849182, 0.5411129554112752, 0.5411129554112752, 0.5411129593849182, 0.5411129713058471, 0.5411129554112752, 0.5411129593849182, 0.5411129673322042, 0.5411129474639893, 0.5411129514376323, 0.5411129514376323, 0.5411129554112752, 0.5411129514376323, 0.5411129434903462, 0.5411129514376323, 0.5411129395167033, 0.5411129434903462, 0.5411129514376323, 0.5411129474639893, 0.5411129474639893, 0.5411129474639893, 0.5411129554112752, 0.5411129593849182, 0.5411129633585612, 0.5411129633585612, 0.5411129593849182, 0.5411129633585612, 0.5411129593849182, 0.5411129593849182, 0.5411129554112752, 0.5411129593849182, 0.5411129593849182, 0.5411129593849182, 0.5411129554112752, 0.5411129593849182, 0.5411129593849182, 0.5411129593849182, 0.5411129514376323, 0.5411129673322042, 0.5411129593849182, 0.5411129633585612, 0.5411129514376323, 0.5411129514376323, 0.5411129673322042, 0.5411129713058471, 0.5411129593849182, 0.5411129633585612, 0.5411129713058471, 0.5411129593849182, 0.5411129633585612, 0.5411129593849182, 0.5411129514376323, 0.5411129633585612, 0.5411129673322042, 0.5411129713058471, 0.5411129752794902, 0.5411129792531332, 0.5411129792531332, 0.5411129792531332, 0.5411129752794902, 0.5411129752794902, 0.5411129752794902, 0.5411129752794902, 0.5411129752794902, 0.5411129752794902, 0.5411129832267761, 0.5411129832267761, 0.5411129792531332, 0.5411129792531332, 0.5411129792531332, 0.5411129832267761, 0.5411129832267761, 0.5411129713058471, 0.5411129792531332, 0.5411129752794902, 0.5411129713058471, 0.5411129713058471, 0.5411129752794902, 0.5411129752794902, 0.5411129792531332, 0.5411129911740621, 0.5411129832267761, 0.5411129911740621, 0.5411129951477051, 0.5411129911740621, 0.5411129911740621, 0.5411129951477051, 0.5411129951477051, 0.541113003094991, 0.5411130070686341, 0.541112999121348, 0.541112999121348, 0.541113003094991, 0.541113003094991, 0.5411130070686341, 0.5411130070686341, 0.541112999121348, 0.541112999121348, 0.541112999121348, 0.541112999121348, 0.541112999121348, 0.541112999121348, 0.5411129951477051, 0.541112999121348, 0.541113003094991, 0.5411130070686341, 0.541113011042277, 0.541113018989563, 0.541113022963206, 0.54111301501592, 0.54111301501592, 0.541113011042277, 0.5411130070686341, 0.541113003094991, 0.541113011042277, 0.54111301501592, 0.541113011042277, 0.541113011042277, 0.5411130070686341, 0.54111301501592, 0.54111301501592, 0.541113018989563, 0.541113011042277, 0.5411130269368489, 0.541113018989563, 0.54111301501592, 0.541113018989563, 0.541113011042277, 0.541113011042277, 0.541113018989563, 0.541113018989563, 0.5411130269368489, 0.541113022963206, 0.541113011042277, 0.54111301501592, 0.541113018989563, 0.541113018989563, 0.541113018989563, 0.5411130309104919, 0.541113038857778, 0.541113038857778, 0.5411130428314209, 0.5411130309104919, 0.541113034884135, 0.5411130547523498, 0.5411130468050639, 0.541113034884135, 0.541113034884135, 0.541113022963206, 0.541113038857778, 0.541113038857778, 0.5411130309104919, 0.5411130428314209, 0.5411130309104919, 0.541113038857778, 0.5411130428314209, 0.5411130468050639, 0.5411130428314209, 0.5411130428314209, 0.5411130468050639, 0.5411130507787069, 0.5411130507787069, 0.5411130507787069, 0.5411130587259928, 0.5411130626996358, 0.5411130507787069, 0.5411130507787069, 0.5411130507787069, 0.5411130547523498, 0.5411130587259928, 0.5411130587259928, 0.5411130587259928, 0.5411130587259928, 0.5411130666732789, 0.5411130666732789, 0.5411130587259928, 0.5411130468050639, 0.5411130587259928, 0.5411130666732789, 0.5411130666732789, 0.5411130626996358, 0.5411130626996358, 0.5411130706469218, 0.5411130746205648, 0.5411130746205648, 0.5411130626996358, 0.5411130587259928, 0.5411130587259928, 0.5411130746205648, 0.5411130706469218, 0.5411130626996358, 0.5411130746205648, 0.5411130785942078, 0.5411130785942078, 0.5411130706469218, 0.5411130746205648, 0.5411130706469218, 0.5411130785942078, 0.5411130746205648, 0.5411130746205648, 0.5411130706469218, 0.5411130666732789, 0.5411130706469218, 0.5411130865414937, 0.5411130825678507, 0.5411130785942078, 0.5411130746205648, 0.5411130825678507, 0.5411130785942078, 0.5411130825678507, 0.5411130905151367, 0.5411130865414937, 0.5411130905151367, 0.5411131024360657, 0.5411130865414937, 0.5411130984624227, 0.5411131064097087, 0.5411131024360657, 0.5411130984624227, 0.5411130984624227, 0.5411131024360657, 0.5411130905151367, 0.5411131024360657, 0.5411131024360657, 0.5411131064097087, 0.5411131024360657, 0.5411131064097087, 0.5411131024360657, 0.5411131024360657, 0.5411131024360657, 0.5411130905151367, 0.5411131024360657, 0.5411131143569946, 0.5411131064097087, 0.5411131103833516, 0.5411131183306376, 0.5411131143569946, 0.5411131183306376, 0.5411131223042805, 0.5411131183306376, 0.5411131103833516, 0.5411131143569946, 0.5411131262779236, 0.5411131262779236, 0.5411131143569946, 0.5411131183306376, 0.5411131223042805, 0.5411131223042805, 0.5411131302515666, 0.5411131342252096, 0.5411131381988525, 0.5411131342252096, 0.5411131342252096, 0.5411131342252096, 0.5411131342252096, 0.5411131342252096, 0.5411131381988525, 0.5411131342252096, 0.5411131381988525, 0.5411131342252096, 0.5411131461461385, 0.5411131421724955, 0.5411131461461385, 0.5411131381988525, 0.5411131501197814, 0.5411131461461385, 0.5411131461461385, 0.5411131501197814, 0.5411131461461385, 0.5411131501197814, 0.5411131580670675, 0.5411131580670675, 0.5411131580670675, 0.5411131461461385, 0.5411131461461385, 0.5411131580670675, 0.5411131580670675, 0.5411131540934245, 0.5411131540934245, 0.5411131501197814, 0.5411131501197814, 0.5411131461461385, 0.5411131461461385, 0.5411131540934245, 0.5411131540934245, 0.5411131540934245, 0.5411131580670675, 0.5411131620407105, 0.5411131660143534, 0.5411131620407105, 0.5411131580670675, 0.5411131501197814, 0.5411131540934245, 0.5411131580670675, 0.5411131660143534, 0.5411131660143534, 0.5411131699879964, 0.5411131580670675, 0.5411131739616394, 0.5411131858825684, 0.5411131858825684, 0.5411131819089253, 0.5411131779352824, 0.5411131819089253, 0.5411131858825684, 0.5411131938298543, 0.5411131858825684, 0.5411131938298543, 0.5411131819089253, 0.5411131819089253, 0.5411131739616394, 0.5411131858825684, 0.5411131819089253, 0.5411131898562114, 0.5411131938298543, 0.5411131978034973, 0.5411131978034973, 0.5411131938298543, 0.5411131898562114, 0.5411131938298543, 0.5411132017771403, 0.5411132057507833, 0.5411132017771403, 0.5411132017771403, 0.5411132097244262, 0.5411132057507833, 0.5411132097244262, 0.5411132017771403, 0.5411131978034973, 0.5411132097244262, 0.5411132097244262, 0.5411132176717123, 0.5411132136980693, 0.5411132097244262, 0.5411132017771403, 0.5411132097244262, 0.5411132176717123, 0.5411132216453552, 0.5411132256189982, 0.5411132136980693, 0.5411132136980693, 0.5411132176717123, 0.5411132295926412, 0.5411132295926412, 0.5411132295926412, 0.5411132295926412, 0.5411132256189982, 0.5411132176717123, 0.5411132256189982, 0.5411132295926412, 0.5411132256189982, 0.5411132375399271, 0.5411132375399271, 0.5411132295926412, 0.5411132335662842, 0.5411132295926412, 0.5411132335662842, 0.5411132454872132, 0.5411132415135701, 0.5411132415135701, 0.5411132415135701, 0.5411132335662842, 0.5411132375399271, 0.5411132494608561, 0.5411132494608561, 0.5411132454872132, 0.5411132454872132, 0.5411132534344991, 0.5411132375399271, 0.5411132534344991, 0.5411132613817851, 0.5411132574081421, 0.5411132613817851, 0.5411132574081421, 0.5411132534344991, 0.5411132534344991, 0.541113265355428, 0.541113269329071, 0.5411132494608561, 0.5411132534344991, 0.5411132574081421, 0.5411132613817851, 0.541113265355428, 0.5411132733027141, 0.5411132733027141, 0.5411132733027141, 0.541113285223643, 0.5411132733027141, 0.541113269329071, 0.5411132733027141, 0.5411132931709289, 0.54111328125, 0.541113269329071, 0.54111328125, 0.54111328125, 0.54111328125, 0.541113285223643, 0.54111328125, 0.5411132733027141, 0.54111328125, 0.541113277276357, 0.54111328125, 0.54111328125, 0.54111328125, 0.541113289197286, 0.5411132971445719, 0.5411132971445719, 0.541113289197286, 0.5411132931709289, 0.541113305091858, 0.5411133011182149, 0.5411132971445719, 0.5411132971445719, 0.541113305091858, 0.541113305091858, 0.5411133209864298, 0.5411133289337158, 0.5411133249600728, 0.5411133209864298, 0.5411133249600728, 0.5411133249600728, 0.5411133170127869, 0.5411133130391439, 0.5411133170127869, 0.5411133209864298, 0.5411133170127869, 0.5411133209864298, 0.5411133170127869, 0.5411133249600728, 0.5411133289337158, 0.5411133289337158, 0.5411133329073589, 0.5411133249600728, 0.5411133209864298, 0.5411133170127869, 0.5411133249600728, 0.5411133289337158, 0.5411133170127869, 0.5411133289337158, 0.5411133329073589, 0.5411133289337158, 0.5411133209864298, 0.5411133249600728, 0.5411133329073589, 0.5411133329073589, 0.5411133488019307, 0.5411133448282878, 0.5411133368810018, 0.5411133368810018, 0.5411133488019307, 0.5411133488019307, 0.5411133527755737, 0.5411133607228596, 0.5411133567492167, 0.5411133527755737, 0.5411133567492167, 0.5411133488019307, 0.5411133527755737, 0.5411133567492167, 0.5411133607228596, 0.5411133567492167, 0.5411133607228596, 0.5411133607228596, 0.5411133527755737, 0.5411133448282878, 0.5411133567492167, 0.5411133527755737, 0.5411133567492167, 0.5411133686701457, 0.5411133646965027, 0.5411133766174316, 0.5411133726437887, 0.5411133805910746, 0.5411133726437887, 0.5411133686701457, 0.5411133805910746, 0.5411133766174316, 0.5411133766174316, 0.5411133726437887, 0.5411133805910746, 0.5411133885383606, 0.5411133766174316, 0.5411133845647176, 0.5411133845647176, 0.5411133925120036, 0.5411133885383606, 0.5411133845647176, 0.5411133766174316, 0.5411133805910746, 0.5411133805910746, 0.5411133805910746, 0.5411133925120036, 0.5411133925120036, 0.5411133925120036, 0.5411134004592896, 0.5411133964856466, 0.5411134004592896, 0.5411133964856466, 0.5411133925120036, 0.5411133964856466, 0.5411134004592896, 0.5411134044329325, 0.5411134084065755, 0.5411134044329325, 0.5411134084065755, 0.5411134004592896, 0.5411134044329325, 0.5411134123802185, 0.5411134123802185, 0.5411134203275044, 0.5411134163538615, 0.5411134123802185, 0.5411134243011475, 0.5411134203275044, 0.5411134163538615, 0.5411134163538615, 0.5411134282747905, 0.5411134282747905, 0.5411134243011475, 0.5411134243011475, 0.5411134243011475, 0.5411134203275044, 0.5411134282747905, 0.5411134322484334, 0.5411134322484334, 0.5411134362220764, 0.5411134362220764, 0.5411134362220764, 0.5411134401957194, 0.5411134441693624, 0.5411134481430053, 0.5411134362220764, 0.5411134441693624, 0.5411134600639343, 0.5411134521166484, 0.5411134401957194, 0.5411134560902914, 0.5411134441693624, 0.5411134401957194, 0.5411134362220764, 0.5411134401957194, 0.5411134322484334, 0.5411134441693624, 0.5411134521166484, 0.5411134600639343, 0.5411134560902914, 0.5411134560902914, 0.5411134600639343, 0.5411134481430053, 0.5411134521166484, 0.5411134600639343, 0.5411134680112203, 0.5411134759585062, 0.5411134640375773, 0.5411134680112203, 0.5411134680112203, 0.5411134759585062, 0.5411134759585062, 0.5411134719848633, 0.5411134719848633, 0.5411134759585062, 0.5411134719848633, 0.5411134759585062, 0.5411134719848633, 0.5411134759585062, 0.5411134799321492, 0.5411134799321492, 0.5411134878794353, 0.5411134839057923, 0.5411134998003642, 0.5411134998003642, 0.5411134998003642, 0.5411134998003642, 0.5411134878794353, 0.5411134958267212, 0.5411134918530782, 0.5411134918530782, 0.5411134998003642, 0.5411135156949362, 0.5411135077476501, 0.5411135077476501, 0.5411135077476501, 0.5411134998003642, 0.5411135077476501, 0.5411135156949362, 0.5411135037740071, 0.5411135117212932, 0.5411135117212932, 0.5411135156949362, 0.5411135117212932, 0.5411135156949362, 0.5411135276158651, 0.5411135276158651, 0.5411135276158651, 0.541113531589508, 0.541113531589508, 0.541113531589508, 0.541113535563151, 0.541113531589508, 0.5411135276158651, 0.541113531589508, 0.541113531589508, 0.5411135236422221, 0.541113551457723, 0.541113551457723, 0.541113539536794, 0.5411135435104371, 0.541113535563151, 0.5411135276158651, 0.541113535563151, 0.54111354748408, 0.5411135435104371, 0.5411135435104371, 0.54111354748408, 0.5411135435104371, 0.54111354748408, 0.5411135594050089, 0.541113551457723, 0.5411135435104371, 0.54111354748408, 0.5411135594050089, 0.541113571325938, 0.5411135752995809, 0.5411135792732239, 0.5411135673522949, 0.541113571325938, 0.541113571325938, 0.541113571325938, 0.541113571325938, 0.5411135673522949, 0.5411135752995809, 0.5411135792732239, 0.5411135752995809, 0.5411135673522949, 0.5411135673522949, 0.541113571325938, 0.541113571325938, 0.541113571325938, 0.541113571325938, 0.5411135752995809, 0.5411135752995809, 0.5411135792732239, 0.5411135792732239, 0.5411135832468669, 0.5411135832468669, 0.5411135872205098, 0.5411135911941528, 0.5411135911941528, 0.5411135911941528, 0.5411135991414388, 0.5411135911941528, 0.5411135991414388, 0.5411135951677958, 0.5411135911941528, 0.5411135951677958, 0.5411135872205098, 0.5411135991414388, 0.5411136070887248, 0.5411135991414388, 0.5411136031150818, 0.5411135991414388, 0.5411136070887248, 0.5411136070887248, 0.5411136110623678, 0.5411136110623678, 0.5411136150360107, 0.5411136031150818, 0.5411136150360107, 0.5411136150360107, 0.5411136190096537, 0.5411136269569397, 0.5411136150360107, 0.5411136269569397, 0.5411136269569397, 0.5411136269569397, 0.5411136269569397, 0.5411136309305827, 0.5411136309305827, 0.5411136269569397, 0.5411136150360107, 0.5411136150360107, 0.5411136031150818, 0.5411136229832967, 0.5411136309305827, 0.5411136349042257, 0.5411136269569397, 0.5411136269569397, 0.5411136269569397, 0.5411136269569397, 0.5411136229832967, 0.5411136229832967, 0.5411136190096537, 0.5411136269569397, 0.5411136388778687, 0.5411136349042257, 0.5411136309305827, 0.5411136468251546, 0.5411136666933696, 0.5411136468251546, 0.5411136507987976, 0.5411136507987976, 0.5411136507987976, 0.5411136627197266, 0.5411136587460835, 0.5411136547724406, 0.5411136547724406, 0.5411136627197266, 0.5411136547724406, 0.5411136428515116, 0.5411136547724406, 0.5411136547724406, 0.5411136468251546, 0.5411136547724406, 0.5411136587460835, 0.5411136587460835, 0.5411136627197266, 0.5411136666933696, 0.5411136666933696, 0.5411136587460835, 0.5411136666933696, 0.5411136587460835, 0.5411136587460835, 0.5411136627197266, 0.5411136706670125, 0.5411136825879415, 0.5411136865615844, 0.5411136786142985, 0.5411136825879415, 0.5411136825879415, 0.5411136825879415, 0.5411136905352275, 0.5411136786142985, 0.5411136865615844, 0.5411136945088705, 0.5411136984825134, 0.5411136905352275, 0.5411136945088705, 0.5411136905352275, 0.5411136905352275, 0.5411136905352275, 0.5411136984825134, 0.5411136905352275, 0.5411137024561564, 0.5411136984825134, 0.5411137064297994, 0.5411137064297994, 0.5411137104034424, 0.5411137183507283, 0.5411137104034424, 0.5411137104034424, 0.5411137143770853, 0.5411137223243714, 0.5411137223243714, 0.5411137104034424, 0.5411137223243714, 0.5411137342453003, 0.5411137382189433, 0.5411137262980144, 0.5411137262980144, 0.5411137342453003, 0.5411137302716573, 0.5411137302716573, 0.5411137382189433, 0.5411137382189433, 0.5411137382189433, 0.5411137421925862, 0.5411137421925862, 0.5411137342453003, 0.5411137382189433, 0.5411137421925862, 0.5411137262980144, 0.5411137342453003, 0.5411137541135153, 0.5411137501398723, 0.5411137382189433, 0.5411137382189433, 0.5411137421925862, 0.5411137421925862, 0.5411137501398723, 0.5411137580871582, 0.5411137620608012, 0.5411137541135153, 0.5411137541135153, 0.5411137700080871, 0.5411137739817301, 0.5411137779553731, 0.5411137580871582, 0.5411137660344442, 0.5411137660344442, 0.5411137700080871, 0.5411137700080871, 0.5411137739817301, 0.5411137779553731, 0.5411137779553731, 0.5411137779553731, 0.5411137779553731, 0.5411137779553731, 0.5411137819290162, 0.5411137779553731, 0.5411137779553731, 0.5411137779553731, 0.5411137819290162, 0.5411137859026591, 0.5411137898763021, 0.541113797823588, 0.5411137739817301, 0.5411137859026591, 0.5411137819290162, 0.5411137898763021, 0.541113797823588, 0.541113801797231, 0.5411137938499451, 0.5411137898763021, 0.5411137859026591, 0.5411137938499451, 0.541113797823588, 0.541113801797231, 0.541113801797231, 0.541113801797231, 0.541113797823588, 0.541113801797231, 0.541113805770874, 0.5411138097445171, 0.54111381371816, 0.54111381371816, 0.541113821665446, 0.541113797823588, 0.541113801797231, 0.541113801797231, 0.541113805770874, 0.541113817691803, 0.54111381371816, 0.541113821665446, 0.541113817691803, 0.5411138256390889, 0.5411138256390889, 0.5411138256390889, 0.541113817691803, 0.5411138296127319, 0.5411138335863749, 0.5411138256390889, 0.541113817691803, 0.5411138256390889, 0.5411138296127319, 0.5411138296127319, 0.5411138335863749, 0.5411138375600179, 0.5411138335863749, 0.5411138335863749, 0.5411138494809469, 0.5411138415336609, 0.5411138415336609, 0.5411138455073039, 0.5411138455073039, 0.5411138494809469, 0.5411138534545898, 0.5411138574282328, 0.5411138614018758, 0.5411138574282328, 0.5411138574282328, 0.5411138653755188, 0.5411138534545898, 0.5411138574282328, 0.5411138653755188], [tensor(-1.4611), tensor(-1.0141), tensor(-0.6631), tensor(-0.3616), tensor(-0.1047), tensor(0.1000), tensor(0.2443), tensor(0.3216), tensor(0.3601), tensor(0.3941), tensor(0.4425), tensor(0.5021), tensor(0.5613), tensor(0.6137), tensor(0.6572), tensor(0.6946), tensor(0.7287), tensor(0.7613), tensor(0.7916), tensor(0.8181), tensor(0.8408), tensor(0.8601), tensor(0.8765), tensor(0.8900), tensor(0.9008), tensor(0.9093), tensor(0.9155), tensor(0.9200), tensor(0.9232), tensor(0.9252), tensor(0.9265), tensor(0.9273), tensor(0.9280), tensor(0.9281), tensor(0.9279), tensor(0.9278), tensor(0.9277), tensor(0.9276), tensor(0.9276), tensor(0.9275), tensor(0.9276), tensor(0.9276), tensor(0.9277), tensor(0.9277), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278), tensor(0.9278)]]\n"
     ]
    }
   ],
   "source": [
    "print(f'CNT => {CNT}')\n",
    "print(f'LOSS_HISTORY => {LOSS_HISTORY}')\n",
    "print(f'SCORE_HISTORY => {SCORE_HISTORY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'irisDL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mirisDL\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'irisDL' is not defined"
     ]
    }
   ],
   "source": [
    "len(irisDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
