{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 모델 클래스\n",
    "- 부모클래스 : nn.Module\n",
    "- 필수오버라이딩\n",
    "    * _ _init_ _() : 모델 층 구성 즉, 설계\n",
    "    * forward() : 순방향 학습 진행 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch                                # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn                       # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F             # 인공신경망 관련 모듈 (손실함수, 활성화함수 등등)\n",
    "import torch.optim as optimizer             # 최적화 관련 모듈 (가중치, 절편 빠르게 찾아주는 알고리즘)\n",
    "from torchmetrics.regression import R2Score # 회귀성능지표 관련 모듈\n",
    "from torchmetrics.classification import *   # 분류성능지표 관련 모듈\n",
    "from torchinfo import summary               # 모델 구조 및 정보 관련 모듈\n",
    "\n",
    "\n",
    "import pandas as pd                         # 데이터 파일 분석 관련 모듈\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(10)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 설정\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [기본] 신경망클래스 <hr>\n",
    "    * 입력층 - 입력 : 피쳐수 고정\n",
    "    * 출력증 - 출력 : 타겟수 고정\n",
    "    * 은닉층 - 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델설계\n",
    "# 데이터셋 : 피쳐 4개, 타겟 1개, 회귀\n",
    "# 입력층 : 입력   4개   출력   20개   AF ReLU\n",
    "# 은닉층 : 입력  20개   출력  100개   AF ReLU\n",
    "# 출력층 : 입력 100개   출력    1개   AF X, Sigmoid & softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    # 인스턴스/객체 생성 시 자동호출되는 메서드 (콜백함수 Callback func)\n",
    "    def __init__(self):\n",
    "        # 부모클래스 생성\n",
    "        super().__init__()\n",
    "        # 자식클래스의 인스턴스 속성 설정\n",
    "        self.input_layer=nn.Linear(4,20) # W 4 + b 1 => 1p, 5 * 20 = 100개 변수\n",
    "        self.hidden_layer=nn.Linear(20,100) # W 20 b + 1 => 21 * 100 = 2100개 변수\n",
    "        self.output_layer=nn.Linear(100,1) # W 100 b + 1 => 101 * 1 =101개 변수\n",
    "\n",
    "    # 순방향/전방향 학습 진행 시 자동호출되는 메서드 (콜백함수 callback func : 시스템에서 호출되는 함수)\n",
    "    # 전달 인자 : 학습용 데이터셋\n",
    "    def forward(self, x):\n",
    "        print('calling forward()')\n",
    "        y=self.input_layer(x) # 1개 퍼셉트론 : y=x1w1 + x2w2 + x3w3 + x4w4+b\n",
    "        y=F.relu(y) # 0 <= y ----> 죽은 relu ==> leakyReLU\n",
    "\n",
    "        y=self.hidden_layer(y) # 1개 퍼셉트론 : y=x1w1 + x2w2 +...+ x20w20 + b\n",
    "        y=F.relu(y)\n",
    "\n",
    "        return self.output_layer(y) # 1개 퍼셉트론 : y=x1w1 + x2w2 +...+ x100w100 + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 피쳐 수가 동적인 모델\n",
    "class MyModel2(nn.Module):\n",
    "    # 인스턴스/객체 생성 시 자동호출되는 메서드 (콜백함수 Callback func)\n",
    "    def __init__(self, in_feature):\n",
    "        # 부모클래스 생성\n",
    "        super().__init__()\n",
    "        # 자식클래스의 인스턴스 속성 설정\n",
    "        self.input_layer=nn.Linear(in_feature,20) # W 4 + b 1 => 1p, 5 * 20 = 100개 변수\n",
    "        self.hidden_layer=nn.Linear(20,100) # W 20 b + 1 => 21 * 100 = 2100개 변수\n",
    "        self.output_layer=nn.Linear(100,1) # W 100 b + 1 => 101 * 1 =101개 변수\n",
    "\n",
    "    # 순방향/전방향 학습 진행 시 자동호출되는 메서드 (콜백함수 callback func : 시스템에서 호출되는 함수)\n",
    "    # 전달 인자 : 학습용 데이터셋\n",
    "    def forward(self, x):\n",
    "        print('calling forward()')\n",
    "        y=self.input_layer(x) # 1개 퍼셉트론 : y=x1w1 + x2w2 + x3w3 + x4w4+b\n",
    "        y=F.relu(y) # 0 <= y ----> 죽은 relu ==> leakyReLU\n",
    "\n",
    "        y=self.hidden_layer(y) # 1개 퍼셉트론 : y=x1w1 + x2w2 +...+ x20w20 + b\n",
    "        y=F.relu(y)\n",
    "\n",
    "        return self.output_layer(y) # 1개 퍼셉트론 : y=x1w1 + x2w2 +...+ x100w100 + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 피쳐 수, 은닉층 퍼셉트론 수 동적인 모델\n",
    "class MyModel3(nn.Module):\n",
    "    # 인스턴스/객체 생성 시 자동호출되는 메서드 (콜백함수 Callback func)\n",
    "    def __init__(self, in_feature, in_out, h_out):\n",
    "        # 부모클래스 생성\n",
    "        super().__init__()\n",
    "        # 자식클래스의 인스턴스 속성 설정\n",
    "        self.input_layer=nn.Linear(in_feature,in_out)\n",
    "        self.hidden_layer=nn.Linear(in_out,h_out)\n",
    "        self.output_layer=nn.Linear(h_out,1)\n",
    "\n",
    "    # 순방향/전방향 학습 진행 시 자동호출되는 메서드 (콜백함수 callback func : 시스템에서 호출되는 함수)\n",
    "    # 전달 인자 : 학습용 데이터셋\n",
    "    def forward(self, x):\n",
    "        print('calling forward()')\n",
    "        y=self.input_layer(x) # 1개 퍼셉트론 : y=x1w1 + x2w2 + x3w3 + x4w4+b\n",
    "        y=F.relu(y) # 0 <= y ----> 죽은 relu ==> leakyReLU\n",
    "\n",
    "        y=self.hidden_layer(y) # 1개 퍼셉트론 : y=x1w1 + x2w2 +...+ x20w20 + b\n",
    "        y=F.relu(y)\n",
    "\n",
    "        return self.output_layer(y) # 1개 퍼셉트론 : y=x1w1 + x2w2 +...+ x100w100 + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel3(\n",
       "  (input_layer): Linear(in_features=4, out_features=50, bias=True)\n",
       "  (hidden_layer): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (output_layer): Linear(in_features=30, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인스턴스 생성\n",
    "m1=MyModel3(4, 50, 30)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_layer.weight', Parameter containing:\n",
      "tensor([[-0.0419, -0.0171, -0.1875,  0.1150],\n",
      "        [-0.2861, -0.0882,  0.1938,  0.4693],\n",
      "        [ 0.1178, -0.1696,  0.0479, -0.0560],\n",
      "        [ 0.2041,  0.0573,  0.1959,  0.4849],\n",
      "        [-0.2076, -0.0177,  0.1150, -0.0033],\n",
      "        [-0.0479, -0.4425, -0.4313, -0.4499],\n",
      "        [-0.4892, -0.4657, -0.3788, -0.4510],\n",
      "        [-0.4690,  0.2192,  0.3067,  0.3379],\n",
      "        [ 0.2694,  0.1694,  0.2203, -0.2765],\n",
      "        [ 0.4502, -0.0345,  0.4314,  0.1533],\n",
      "        [ 0.3914,  0.3988, -0.1045, -0.1454],\n",
      "        [ 0.0752, -0.0213,  0.0782,  0.2536],\n",
      "        [-0.3907, -0.0229, -0.3924,  0.4829],\n",
      "        [-0.3517,  0.0956, -0.1366,  0.2842],\n",
      "        [ 0.0017, -0.0503,  0.3660,  0.4567],\n",
      "        [-0.3629, -0.4823,  0.0417,  0.1575],\n",
      "        [ 0.1141,  0.4619,  0.2244, -0.2300],\n",
      "        [-0.3424,  0.3879,  0.4792, -0.2373],\n",
      "        [-0.3200,  0.1750, -0.3576, -0.1210],\n",
      "        [-0.4945,  0.1368, -0.1705, -0.2797],\n",
      "        [-0.3179, -0.1759,  0.2375,  0.0283],\n",
      "        [ 0.4306, -0.1787, -0.1463,  0.4894],\n",
      "        [-0.4769, -0.1968, -0.3102,  0.4811],\n",
      "        [ 0.2662, -0.1675, -0.2123,  0.1533],\n",
      "        [-0.1690,  0.1552, -0.2559, -0.3094],\n",
      "        [-0.0125,  0.2936,  0.4259,  0.1105],\n",
      "        [-0.2970,  0.2614,  0.1949,  0.2133],\n",
      "        [-0.1667, -0.0675,  0.2307,  0.2065],\n",
      "        [ 0.3321, -0.2999,  0.3140, -0.1945],\n",
      "        [-0.0126, -0.2353, -0.1482,  0.3371],\n",
      "        [ 0.4271,  0.1741, -0.3751, -0.1844],\n",
      "        [ 0.3468, -0.1349, -0.4084,  0.1161],\n",
      "        [-0.4439, -0.0030, -0.0615,  0.0048],\n",
      "        [-0.1190, -0.0731, -0.3023, -0.3301],\n",
      "        [ 0.1641,  0.4510, -0.3994, -0.4720],\n",
      "        [-0.2704,  0.4799,  0.4500, -0.4865],\n",
      "        [ 0.1213,  0.0674,  0.4417, -0.1499],\n",
      "        [ 0.1649, -0.2476, -0.4671,  0.0561],\n",
      "        [-0.2417, -0.0313, -0.1104, -0.4044],\n",
      "        [ 0.2927,  0.3453,  0.3823,  0.0649],\n",
      "        [-0.4721, -0.3998, -0.0525, -0.0519],\n",
      "        [-0.4538,  0.3099, -0.3728, -0.0140],\n",
      "        [-0.4769,  0.1404,  0.0023,  0.3459],\n",
      "        [ 0.0840, -0.3943,  0.4714, -0.4302],\n",
      "        [ 0.2400, -0.3482,  0.2698,  0.1248],\n",
      "        [ 0.1339, -0.1190,  0.4563,  0.4874],\n",
      "        [-0.0517, -0.1593,  0.0777,  0.3219],\n",
      "        [ 0.4652,  0.4545,  0.2324,  0.0577],\n",
      "        [-0.3673, -0.3811,  0.3381, -0.4505],\n",
      "        [-0.0222,  0.4061, -0.4320, -0.3469]], requires_grad=True))\n",
      "('input_layer.bias', Parameter containing:\n",
      "tensor([-0.4971,  0.2712,  0.1070,  0.3017, -0.0671, -0.1619,  0.4199, -0.3264,\n",
      "        -0.3210,  0.3421,  0.4623, -0.2564, -0.4784,  0.0244, -0.0038,  0.1487,\n",
      "         0.2680,  0.0555, -0.3232, -0.0344,  0.2308,  0.0820, -0.3425, -0.0300,\n",
      "        -0.0925, -0.2156,  0.2536,  0.1964,  0.4223,  0.4176, -0.0191, -0.4038,\n",
      "         0.1643,  0.2610,  0.2991,  0.3031,  0.2717,  0.1075,  0.0334,  0.2489,\n",
      "        -0.4950,  0.2465,  0.1390,  0.1332, -0.1388,  0.1436,  0.1184, -0.4868,\n",
      "        -0.2350,  0.2495], requires_grad=True))\n",
      "('hidden_layer.weight', Parameter containing:\n",
      "tensor([[-0.0980, -0.0502,  0.0822,  ...,  0.0508,  0.0799,  0.1223],\n",
      "        [ 0.0110, -0.1026,  0.0135,  ...,  0.0404,  0.0364, -0.1292],\n",
      "        [-0.0231, -0.0894, -0.1078,  ..., -0.0664,  0.1190,  0.0835],\n",
      "        ...,\n",
      "        [-0.0563, -0.1353,  0.0159,  ..., -0.0839,  0.0012, -0.1251],\n",
      "        [-0.0039,  0.0117,  0.0641,  ..., -0.0671, -0.1333, -0.0101],\n",
      "        [ 0.1094,  0.0461, -0.0826,  ...,  0.0274, -0.0015,  0.1349]],\n",
      "       requires_grad=True))\n",
      "('hidden_layer.bias', Parameter containing:\n",
      "tensor([ 0.1035,  0.1342,  0.0719,  0.0030, -0.0458,  0.1134, -0.1357, -0.0355,\n",
      "        -0.0757, -0.1311, -0.1007,  0.0766,  0.0172,  0.1000,  0.1016, -0.0850,\n",
      "        -0.0789, -0.1009, -0.1267, -0.0644, -0.1047,  0.0333,  0.0255,  0.0921,\n",
      "         0.1326,  0.0708,  0.1289,  0.1002,  0.0746, -0.0304],\n",
      "       requires_grad=True))\n",
      "('output_layer.weight', Parameter containing:\n",
      "tensor([[-0.1509,  0.1578, -0.1430,  0.0348,  0.1658,  0.0352, -0.0415, -0.0681,\n",
      "          0.1543, -0.1423, -0.0107, -0.1609,  0.0446, -0.0473, -0.1000, -0.1814,\n",
      "          0.1446,  0.0538,  0.0767, -0.1318, -0.1204, -0.0561,  0.0815, -0.0294,\n",
      "          0.0293,  0.1695, -0.0651,  0.0469,  0.0669, -0.0452]],\n",
      "       requires_grad=True))\n",
      "('output_layer.bias', Parameter containing:\n",
      "tensor([-0.1016], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 즉, W와 b 확인\n",
    "for m in m1.named_parameters(): print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling forward()\n",
      "tensor([[-0.2975],\n",
      "        [-0.3586]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 학습진행 => 모델인스턴스명(데이터)\n",
    "# 임의의 데이터\n",
    "dataTS=torch.FloatTensor([[1,3,5,7],[2,4,6,8]])\n",
    "targetTS=torch.FloatTensor([[4],[5]])\n",
    "\n",
    "# 학습\n",
    "pre_y=m1(dataTS)\n",
    "\n",
    "print(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
