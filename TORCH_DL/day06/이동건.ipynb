{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 퍼셉트론은 뉴런을 공학적인 구조로 나타낸것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 퍼셉트론 기본동작  \n",
    "각피쳐에 가중치를 곱고 절편을 더해주어 하나의 퍼셉트론을 구성\n",
    "P= w1x1+w2x2+w3x3+w4x4 + b   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \n",
    "이전 층의 결과값을 변환하여 다른 층의 뉴런으로 전달하기 위해서 필요하다.\n",
    "선형모델을 계속 층을 쌓는다하여도 많은 선형이 합쳐지면 결국 하나의 선형에 가깝게 되기때문에\n",
    "비선형함수인 활성화함수를 통하여 층을 만들어 주는 역활을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\n",
    "- Relu : 0보다 작을때 0 나머지는 그대로출력\n",
    "- leackyRelu : 0보다 작을때 0에 가까운 음수로 만들어줌\n",
    "- sigmoid : 0 ~ 1사이 값\n",
    "- step : 0과 1로 나타냄\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 함수의 기울기를 구한다음 기울기의 반대 방향으로 이동하여 기울기가 최소가 되는 지점을 찾는방법이다.\n",
    "- Batch 경사하강법 : 학습데이터를 배치크기로 나눠서 학습시키는 방식\n",
    "- 확률 경사하강법 : 학습 데이터에서 무작위로 샘플데이터를 추출하여 학습하는 방식\n",
    "- adagrad : 학습률을 자동으로 조정하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 회귀 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regression(nn.module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer=nn.Linear(3,5)   # 입력층  입력 3 (피쳐3개)         출력 5\n",
    "        self.h_layer = nn.Linear(5,10)    # 은닉층  입력  5                 출력 10\n",
    "        self.out_layer = nn.Linear(10,1)  # 출력층  입력 10                  출력 1     # 회귀니까 출력1\n",
    "\n",
    "    # 순방향 학습\n",
    "    def forward(self,x):\n",
    "        y = F.relu(self.input_layer(x))     \n",
    "        y = F.relu(self.h_layer(y))\n",
    "        return self.out_layer(y)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 이진 분류 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 만들때 은닉의 퍼셉트론을 리스트로 준다고 가정 \n",
    "class BNClassfication(nn.module):\n",
    "\n",
    "    def __init__(self,h_list=[]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(5,h_list[0])\n",
    "        self.h_layers =nn.ModuleList()\n",
    "\n",
    "        for i in range(3):      \n",
    "            self.h_layers.append(nn.Linear(h_list[i],h_list[i+1]))\n",
    "        \n",
    "        self.out_layers = nn.Linear(h_list[-1],1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y = F.relu(self.input_layer(x))  \n",
    "\n",
    "        for h_layer in self.h_layers:\n",
    "            y=F.relu(h_layer(y))   \n",
    "        \n",
    "        return F.sigmoid(self.out_layers(y))  # 이진분류는 sigmoid가 좋다다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 다중 분류 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 만들때 은닉의 퍼셉트론을 리스트로 준다고 가정 \n",
    "class MClassfication(nn.module):\n",
    "    \n",
    "    def __init__(self,h_list=[]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(5,h_list[0])  # 피쳐 5개\n",
    "        self.h_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(h_list)-1):\n",
    "            self.h_layers.append(nn.Linear(h_list[i],h_list[i+1]))\n",
    "\n",
    "        self.out_layers = nn.Linear(h_list[-1],8)     # 클래스 8개\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y = F.relu(self.input_layer(x))  \n",
    "\n",
    "        for h_layer in self.h_layers:\n",
    "            y=F.relu(h_layer(y))   \n",
    "        \n",
    "        return F.softmax(self.out_layers(y), dim=1)     # 다중분류라서 softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 기울기 소실 개념 및 해결 방법\n",
    "- 역전파 과정에서 기울기값이 매우 작아져 다음층으로 전달 될때 기울기가 거의 소실 되어 입력층 가까운층에서는 학습이 잘 되지 않는것을 말한다.\n",
    "- 해결방법 : 적절한 활성화함수를 사용하거나 가중치 초기화 등을 사용하여 기울기 소실을 해결 할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\n",
    "- model.train() 학습모드\n",
    "    * 학습과정에서 사용되는 정규화 기법들이 동작하도록 한다.\n",
    "    * 역전파를 진행하고 기울기를 계산한다.\n",
    "- model.eval() 검증모드\n",
    "    * 검증과정에서 사용하는 것으로 정규화 기법(드랍아웃)이 동작하지 않는다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
